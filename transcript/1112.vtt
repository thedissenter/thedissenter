WEBVTT

1
00:00:00.009 --> 00:00:02.930
Hello, everyone. Welcome to a new episode of the

2
00:00:02.930 --> 00:00:05.880
Center. I'm your host, as always, Ricardo Lopes and

3
00:00:05.880 --> 00:00:09.590
today I'm by Doctor Angela Potosnik. She's professor of

4
00:00:09.590 --> 00:00:12.510
philosophy and director of the Center for Public Engagement

5
00:00:12.510 --> 00:00:15.920
with Science at the University of Cincinnati. And today

6
00:00:15.920 --> 00:00:19.200
we're talking about her book Recipes for Science and

7
00:00:19.200 --> 00:00:24.549
Introduction to scientific Methods and Reasoning. So, Doctor Potosnik,

8
00:00:24.639 --> 00:00:26.840
welcome to the show. It's a huge pleasure to

9
00:00:26.840 --> 00:00:27.149
everyone.

10
00:00:27.600 --> 00:00:28.760
Thank you. Thanks for having me.

11
00:00:30.149 --> 00:00:33.950
So let me start by asking you, why should

12
00:00:33.950 --> 00:00:39.380
people care about science because, you know, most people

13
00:00:39.380 --> 00:00:44.229
are not scientists. Many people do not even tend

14
00:00:44.229 --> 00:00:49.430
to read science and related topics. So why should

15
00:00:49.750 --> 00:00:53.810
we, why should people in general care about science?

16
00:00:54.470 --> 00:00:56.669
Yeah, so maybe I have 33 answers to that.

17
00:00:56.799 --> 00:01:02.209
One is um that Science, it turns out, science

18
00:01:02.209 --> 00:01:04.440
and the institutions of science as they have developed,

19
00:01:04.569 --> 00:01:07.199
are one of our best ways to gain knowledge,

20
00:01:07.330 --> 00:01:09.290
uh, not all kinds of knowledge, right? But, but,

21
00:01:09.300 --> 00:01:12.209
uh, uh, very important kinds of knowledge and abilities

22
00:01:12.209 --> 00:01:15.040
in our world. So that makes science pretty important.

23
00:01:15.324 --> 00:01:17.934
Um, AND then beyond that, for, for people who

24
00:01:17.934 --> 00:01:21.205
are not scientists or interested to become scientists, um,

25
00:01:21.214 --> 00:01:24.175
or insiders to science, uh, there still can be

26
00:01:24.175 --> 00:01:28.324
an advantage to knowing something about how science succeeds.

27
00:01:28.334 --> 00:01:31.245
One, in that it can help you know, uh,

28
00:01:31.565 --> 00:01:34.574
when something that looks like good science should be

29
00:01:34.574 --> 00:01:37.294
trusted and, and when, in contrast, it might look

30
00:01:37.294 --> 00:01:39.254
like good science, but be deceptive in one way

31
00:01:39.254 --> 00:01:41.455
or another because unfortunately, there are lots of examples

32
00:01:41.455 --> 00:01:45.720
of that as well. And then secondly, people Um,

33
00:01:45.849 --> 00:01:49.639
in some cases can sort of approximate, and I

34
00:01:49.639 --> 00:01:51.169
think all of us do to some extent kind

35
00:01:51.169 --> 00:01:54.089
of approximate methods that are used, some methods that

36
00:01:54.089 --> 00:01:56.919
are used in science in our everyday lives, um,

37
00:01:57.050 --> 00:01:58.449
and going about our business. So it can be

38
00:01:58.449 --> 00:02:00.349
useful to know kind of how to make use

39
00:02:00.349 --> 00:02:03.480
of uh tips and tricks from science as well.

40
00:02:04.819 --> 00:02:07.860
Yeah, and perhaps, I mean, now a question that

41
00:02:07.860 --> 00:02:12.279
perhaps might might even make people more open to

42
00:02:12.639 --> 00:02:17.080
being interested in science. In what ways does science

43
00:02:17.080 --> 00:02:20.550
have practical applications? Of course, I mean, since I'm

44
00:02:20.550 --> 00:02:23.839
familiar with it, I could perhaps think about 1000

45
00:02:23.839 --> 00:02:29.440
different practical applications that science has, but what would

46
00:02:29.440 --> 00:02:31.270
you, what would be your answer?

47
00:02:31.639 --> 00:02:35.449
Well, um, Uh, so, of course, uh, medicine, right,

48
00:02:35.570 --> 00:02:37.610
and, and sort of health best practices. This is

49
00:02:37.610 --> 00:02:40.800
an important place where not only is, um, biomedical

50
00:02:40.800 --> 00:02:45.000
and other scientific research important, but also as individuals,

51
00:02:45.009 --> 00:02:47.570
we can get some benefit from knowing where the

52
00:02:47.570 --> 00:02:51.360
science stands on, on one topic or another, um,

53
00:02:51.369 --> 00:02:53.770
so that we can make evidence-based decisions about how

54
00:02:53.770 --> 00:02:55.410
to manage our own health, how to manage our

55
00:02:55.410 --> 00:02:59.820
children's health, um, etc. Uh, THAT'S one example. Um,

56
00:03:00.029 --> 00:03:02.750
WHERE else does it matter for people to, to

57
00:03:02.750 --> 00:03:07.100
know about scientific research, um, Uh, you know, quite

58
00:03:07.100 --> 00:03:10.619
broadly, uh, I think statistical tools, um, and, and

59
00:03:10.619 --> 00:03:14.589
just kind of basically statistical concepts, even if, uh,

60
00:03:14.600 --> 00:03:17.179
we're not going to be sort of, um, people

61
00:03:17.179 --> 00:03:20.690
who are using, uh, statistical tools at a level

62
00:03:20.690 --> 00:03:23.179
of sophistication, uh, that we would have like we

63
00:03:23.179 --> 00:03:25.350
had a stats class or something like that, um,

64
00:03:25.419 --> 00:03:28.339
just the very concepts behind the use of statistics

65
00:03:28.339 --> 00:03:30.729
and probabilities I think can be useful.

66
00:03:31.500 --> 00:03:34.550
Mhm. Um, AND why is it that you think

67
00:03:34.550 --> 00:03:39.800
that public opinion so commonly lags behind scientific research?

68
00:03:39.830 --> 00:03:42.470
Because, you know, sometimes when we go on the

69
00:03:42.470 --> 00:03:46.149
street and ask people about certain scientific topics, they

70
00:03:46.149 --> 00:03:50.080
either know But almost nothing about them, or they

71
00:03:50.080 --> 00:03:53.759
give answers that are already outdated. Sometimes they are

72
00:03:53.759 --> 00:03:57.039
decades old answers. So what do you think about?

73
00:03:57.160 --> 00:04:00.039
Yeah, well, so I have 3 different answers. The

74
00:04:00.039 --> 00:04:03.729
first is, um, it's pretty natural that there's a

75
00:04:03.729 --> 00:04:06.000
sort of division of expertise in our society, right?

76
00:04:06.160 --> 00:04:09.830
So, uh, even scientists ask, you know, ask, um,

77
00:04:09.839 --> 00:04:13.669
a climate scientist pointed questions about dark matter research

78
00:04:13.669 --> 00:04:17.988
and and ask and um. Astrophysics and, and they

79
00:04:17.988 --> 00:04:21.010
may not have more expertise than than somebody off

80
00:04:21.010 --> 00:04:23.260
the street, right? So there's a division of expertise

81
00:04:23.260 --> 00:04:26.709
in our society. I would expect scientists to know

82
00:04:26.709 --> 00:04:30.029
more about their area of expertise than than the

83
00:04:30.029 --> 00:04:32.410
lay population and then people who are not in

84
00:04:32.410 --> 00:04:37.230
that area. Um, uh, THEY'RE also, I think, um.

85
00:04:37.820 --> 00:04:42.820
Can be some challenges to um keeping up to

86
00:04:42.820 --> 00:04:45.820
date with scientific findings or knowing and maybe more

87
00:04:45.820 --> 00:04:48.489
to the point, more importantly, knowing how to interpret

88
00:04:48.489 --> 00:04:51.450
and put into perspective scientific findings. And I think

89
00:04:51.739 --> 00:04:53.500
part of the work to be done there is

90
00:04:53.500 --> 00:04:57.140
a better job on the part of scientists and

91
00:04:57.140 --> 00:05:00.480
those who think. Science, like philosophers of science, as

92
00:05:00.480 --> 00:05:05.320
well as science popularizers to help create avenues and

93
00:05:05.320 --> 00:05:08.839
access points, uh, into the latest scientific knowledge, but

94
00:05:08.839 --> 00:05:11.440
maybe more importantly, ways to think about and put

95
00:05:11.440 --> 00:05:14.529
into perspective scientific knowledge, um, so, so that it,

96
00:05:14.579 --> 00:05:16.720
um, sort of all adds up for people who

97
00:05:16.720 --> 00:05:19.519
are not scientists. And then the third answer I

98
00:05:19.519 --> 00:05:23.320
think, um, is that, that, um, Uh, at least

99
00:05:23.320 --> 00:05:25.230
now, I think we find ourselves at a point,

100
00:05:25.440 --> 00:05:27.040
uh, and I say at least now, because maybe

101
00:05:27.040 --> 00:05:30.000
this is not unusual, um, uh, but right now

102
00:05:30.000 --> 00:05:32.959
we find ourselves at a point where, um, scientific

103
00:05:32.959 --> 00:05:36.160
knowledge is, is politicized in certain contexts, and so

104
00:05:36.160 --> 00:05:39.649
some people have some Um, personal and social identity

105
00:05:39.649 --> 00:05:42.480
bound up in, in not knowing more about science,

106
00:05:42.519 --> 00:05:44.799
or at least certain types of science and, and

107
00:05:44.799 --> 00:05:47.070
how it functions. Um, SO that's another kind of,

108
00:05:47.119 --> 00:05:49.540
of challenge and something that I also think philosophers

109
00:05:49.540 --> 00:05:52.809
science are well positioned to, to, uh, weigh in

110
00:05:52.809 --> 00:05:53.029
on.

111
00:05:53.670 --> 00:05:56.700
Mhm. And I think that another very important thing

112
00:05:56.700 --> 00:05:59.750
for people to keep in mind is that uh

113
00:05:59.750 --> 00:06:03.750
science has certain limits. So from an from an

114
00:06:03.750 --> 00:06:07.829
epistemological perspective, what would you say are the limits

115
00:06:07.829 --> 00:06:08.779
of science?

116
00:06:09.619 --> 00:06:11.799
Yeah, um, well, what we say, and that's a

117
00:06:11.799 --> 00:06:13.540
good chance actually, this is the first time I'm

118
00:06:13.540 --> 00:06:16.279
explicitly referencing the recipes for science book, um, and

119
00:06:16.279 --> 00:06:17.279
I do want to say on the front end,

120
00:06:17.320 --> 00:06:19.000
this is of course a co-authored book, so it's

121
00:06:19.000 --> 00:06:20.910
not just me, but I worked with Corey Wright

122
00:06:20.910 --> 00:06:24.390
and Matteo Colombo, two other philosophers of science, um,

123
00:06:24.399 --> 00:06:26.640
on, on this book, um, and it now has

124
00:06:26.640 --> 00:06:28.890
two editions, and we worked together on both editions

125
00:06:28.890 --> 00:06:31.600
of the book. Um, OK, that was enough for

126
00:06:31.600 --> 00:06:34.250
me to forget the question. Uh, LIMITS of science,

127
00:06:34.359 --> 00:06:38.619
I remember, sorry, um. So, uh, the line that

128
00:06:38.619 --> 00:06:41.470
we take in that book is, um, something like,

129
00:06:41.500 --> 00:06:45.459
um, science can tell us about, um, uh, empirical

130
00:06:45.459 --> 00:06:48.420
knowledge or can help generate empirical knowledge about our

131
00:06:48.420 --> 00:06:50.970
world. And so, so this is a way of

132
00:06:50.970 --> 00:06:54.369
um cashing out the idea that Science um proceeds

133
00:06:54.369 --> 00:06:56.649
on the basis of evidence and primarily or at

134
00:06:56.649 --> 00:07:00.250
least uh including empirical evidence that is, uh, information

135
00:07:00.250 --> 00:07:02.970
from our senses, uh, that, that are then recorded

136
00:07:02.970 --> 00:07:04.929
in the form of data and shared among different

137
00:07:04.929 --> 00:07:07.049
people so that we can kind of like all

138
00:07:07.049 --> 00:07:10.420
uh work together to, to, um. Uh, COMPARE and

139
00:07:10.420 --> 00:07:12.899
contrast all of our different, uh, sense data that

140
00:07:12.899 --> 00:07:15.070
bear on, on one thing or another and, and,

141
00:07:15.299 --> 00:07:18.100
uh, formulate arguments about how the world is on

142
00:07:18.100 --> 00:07:20.420
the basis of that data. Um, SO I think

143
00:07:20.420 --> 00:07:23.140
that gives us some, uh, insight into what we

144
00:07:23.140 --> 00:07:24.859
might think of as the, the limits of science.

145
00:07:24.954 --> 00:07:27.605
IS that science is, is best positioned to tell

146
00:07:27.605 --> 00:07:31.744
us um things uh that uh or to answer

147
00:07:31.744 --> 00:07:34.704
questions that, that empirical data can bear on in

148
00:07:34.704 --> 00:07:36.265
one way or another, even if a lot of

149
00:07:36.265 --> 00:07:38.334
times it's pretty indirect, right? It's not sort of

150
00:07:38.464 --> 00:07:39.904
just looking to see what's right in front of

151
00:07:39.904 --> 00:07:40.214
us.

152
00:07:41.570 --> 00:07:45.329
And what do you think about the demarcation problem

153
00:07:45.329 --> 00:07:50.809
that is distinguishing or demarcating science from pseudoscience and

154
00:07:50.809 --> 00:07:55.209
even sometimes also people talk about anti-science. I mean,

155
00:07:55.290 --> 00:07:59.609
do you think that it is really very important

156
00:07:59.609 --> 00:08:04.279
to be able to properly demarcate science from pseudoscience

157
00:08:04.279 --> 00:08:05.200
or not?

158
00:08:05.609 --> 00:08:07.829
Yeah, um, so, so I say yes or yes

159
00:08:07.829 --> 00:08:09.149
and no, and I want to start with a

160
00:08:09.149 --> 00:08:12.510
no. I think it's uh quite natural that that

161
00:08:12.510 --> 00:08:16.429
scientific projects are continuous with other kinds of human

162
00:08:16.429 --> 00:08:19.549
projects. And so, you know, when is engineering science

163
00:08:19.549 --> 00:08:22.109
versus um the application of science. I think that

164
00:08:22.109 --> 00:08:24.070
there are going to be gray areas for questions

165
00:08:24.070 --> 00:08:27.140
like that, and I think that's really uh natural,

166
00:08:27.470 --> 00:08:29.630
sort of natural of the ways that we use

167
00:08:29.630 --> 00:08:34.330
words and And define um categories. Uh, SO that

168
00:08:34.330 --> 00:08:36.770
I think is, is, is normal and not, not

169
00:08:36.770 --> 00:08:39.409
to be concerned uh about, not something we should

170
00:08:39.409 --> 00:08:41.679
be concerned about. Uh, THE thing that starts to

171
00:08:41.679 --> 00:08:44.770
become problematic as you suggest is that because there's

172
00:08:44.770 --> 00:08:48.799
so much societal investment in science, um, and because,

173
00:08:48.840 --> 00:08:50.650
um, many of us, right, have a kind of

174
00:08:50.650 --> 00:08:54.520
implicit trust for scientific findings because we, we know

175
00:08:54.520 --> 00:08:56.929
something about the methods that, that gave rise to

176
00:08:56.929 --> 00:09:00.320
those findings. Um, WE'RE in a situation where some

177
00:09:00.320 --> 00:09:04.559
of Other projects um find it valuable or lucrative

178
00:09:04.559 --> 00:09:06.679
to sort of pretend as if they're more scientific

179
00:09:06.679 --> 00:09:09.510
than they are. And that's where demarcation, I think,

180
00:09:09.520 --> 00:09:13.830
becomes important if, um, uh, projects that don't have

181
00:09:13.830 --> 00:09:17.760
the legitimate hallmark features of science are sort of

182
00:09:17.760 --> 00:09:20.299
working after the fact to try to suggest that

183
00:09:20.299 --> 00:09:22.440
they do in order to gain the trust that

184
00:09:22.440 --> 00:09:25.960
we should reserve for, you know, well vetted scientific

185
00:09:25.960 --> 00:09:29.080
findings, um, that then we as a society need

186
00:09:29.080 --> 00:09:32.369
to be invested in. Uh, SORT of, uh, demonstrating

187
00:09:32.369 --> 00:09:34.849
the ways in which those projects fall short of

188
00:09:34.849 --> 00:09:35.280
science.

189
00:09:36.729 --> 00:09:39.409
By the way, we've been talking a lot about

190
00:09:39.409 --> 00:09:43.400
science, but what is science exactly? I mean, do

191
00:09:43.400 --> 00:09:45.890
we have a proper definition of it?

192
00:09:46.809 --> 00:09:49.030
Oh gosh, um, I wish I could tell you

193
00:09:49.030 --> 00:09:50.700
off the top of my head what the definition

194
00:09:50.700 --> 00:09:53.030
is that we use in, uh, in recipes for

195
00:09:53.030 --> 00:09:54.869
science, uh, and I don't remember off the top

196
00:09:54.869 --> 00:09:59.030
of my head. Um, BUT, um, I think I've

197
00:09:59.030 --> 00:10:01.070
given you the ingredients of what I think science

198
00:10:01.070 --> 00:10:02.580
is, uh, even if I can't give you a,

199
00:10:02.590 --> 00:10:05.349
a pithy, a single phrase in what I've said

200
00:10:05.349 --> 00:10:08.500
so far, which is, um, I think science is,

201
00:10:08.510 --> 00:10:13.604
uh, a set of methods, uh, rooted. Ultimately, uh,

202
00:10:13.614 --> 00:10:17.354
in some sense, in, in empirical data, empirical observations

203
00:10:17.354 --> 00:10:22.114
about the world, um, that's used to, uh, generate

204
00:10:22.114 --> 00:10:24.715
knowledge about our world and abilities to sort of

205
00:10:24.715 --> 00:10:27.554
act in our world effectively. Something like that.

206
00:10:28.840 --> 00:10:34.020
OK. So, and when it comes to uh scientific

207
00:10:34.020 --> 00:10:37.900
methods or the scientific method, I mean, usually, we

208
00:10:37.900 --> 00:10:42.260
tend to talk about the scientific method, but is

209
00:10:42.260 --> 00:10:45.859
there really one single scientific method out there?

210
00:10:46.369 --> 00:10:48.169
This is a point philosophers of science love to

211
00:10:48.169 --> 00:10:50.520
make. No, there's not a single scientific method out

212
00:10:50.520 --> 00:10:52.849
there. Um, AND so this is uh one of

213
00:10:52.849 --> 00:10:55.440
the reasons that we call our book recipes for

214
00:10:55.440 --> 00:10:57.729
Science. Um, I say one because there are other

215
00:10:57.729 --> 00:11:01.169
considerations in, in sort of choosing that title versus

216
00:11:01.169 --> 00:11:04.440
um. Uh, SOME other possibilities that we considered. Um,

217
00:11:04.609 --> 00:11:07.640
BUT we want to emphasize, uh, the plurality there,

218
00:11:07.770 --> 00:11:10.909
right? As well as with the metaphor with recipes,

219
00:11:11.010 --> 00:11:13.059
a kind of open-endedness, right? So even if you're

220
00:11:13.059 --> 00:11:15.250
looking at a bread recipe, you might have margin

221
00:11:15.250 --> 00:11:17.690
notes about what worked for you last time, the

222
00:11:17.690 --> 00:11:20.044
kind of flour that you like. Using it, uh,

223
00:11:20.054 --> 00:11:23.335
etc. And so there's a kind of open-endedness and

224
00:11:23.335 --> 00:11:28.215
customizability, uh, to scientific methods, um, that I think

225
00:11:28.215 --> 00:11:31.094
it's important for us outside of science to, to

226
00:11:31.094 --> 00:11:33.364
recognize about it. It helps us kind of better,

227
00:11:33.534 --> 00:11:36.255
better understand what's going on and what to anticipate.

228
00:11:37.059 --> 00:11:40.820
Mhm. So, now this is a question at the

229
00:11:40.820 --> 00:11:44.630
intersection, I think of philosophy of science and ethics.

230
00:11:45.020 --> 00:11:48.570
Is science simply descriptive or can it also be

231
00:11:48.570 --> 00:11:49.969
prescriptive? Oh,

232
00:11:50.010 --> 00:11:51.849
I think, yeah, I think science quite, quite easily

233
00:11:51.849 --> 00:11:54.450
can be prescriptive. Um, AND so I also think

234
00:11:54.450 --> 00:11:57.250
it's important and in recipes for science, my co-authors

235
00:11:57.250 --> 00:11:59.809
and I take a very broad perspective on what

236
00:11:59.809 --> 00:12:03.000
is science. I consider, uh, social science, for example,

237
00:12:03.090 --> 00:12:06.130
to be properly scientific, just as scientific as uh

238
00:12:06.130 --> 00:12:09.849
as physics and other natural sciences, um. And in

239
00:12:09.849 --> 00:12:12.130
social sciences is a is one place, I don't

240
00:12:12.130 --> 00:12:13.659
think it's the only place you get sort of

241
00:12:13.659 --> 00:12:15.849
normative claims from science by any stretch, but it's

242
00:12:15.849 --> 00:12:18.770
an easy place to look to for examples. Uh,

243
00:12:18.809 --> 00:12:23.679
IF we are using empirical methods to account for

244
00:12:24.049 --> 00:12:28.010
um features of human societies, then, then you're pretty

245
00:12:28.010 --> 00:12:31.090
naturally in a place where, um, taking on board

246
00:12:31.090 --> 00:12:34.849
certain aims for One question or another about about

247
00:12:34.849 --> 00:12:37.849
human practices and gathering data about that it puts

248
00:12:37.849 --> 00:12:40.369
you in a good position to make recommendations based

249
00:12:40.369 --> 00:12:45.239
on um what what aims um uh society might

250
00:12:45.239 --> 00:12:47.460
want to achieve that you as a scientist have

251
00:12:47.460 --> 00:12:49.320
sort of taken on board for your work.

252
00:12:50.179 --> 00:12:55.109
Mhm. In science, when we talk about hypotheses and

253
00:12:55.109 --> 00:12:59.380
theories, uh, what does each of them mean and

254
00:12:59.380 --> 00:13:03.289
how do we distinguish one from the other? Yeah,

255
00:13:03.489 --> 00:13:05.809
so, so, um, we follow, I think, a pretty,

256
00:13:05.890 --> 00:13:08.090
pretty common way of thinking about these terms in

257
00:13:08.090 --> 00:13:12.090
recipes for science. Um, HYPOTHESIS, uh, uh, we use

258
00:13:12.090 --> 00:13:14.530
a lot throughout, uh, the book, and the idea

259
00:13:14.530 --> 00:13:17.179
here is that these are conjectures about the world,

260
00:13:17.489 --> 00:13:21.549
um, whereas theories, um, Uh, first and foremost, we

261
00:13:21.549 --> 00:13:24.750
can think about, uh, scientific theories as, as being

262
00:13:24.750 --> 00:13:27.989
corroborated, as having a substantial amount of evidence to

263
00:13:27.989 --> 00:13:32.130
support them. Um, uh, A sort of scientific theory

264
00:13:32.130 --> 00:13:34.900
that is communicated as such, named as a theory,

265
00:13:35.150 --> 00:13:37.710
shows up in a, in a textbook, etc. um,

266
00:13:37.750 --> 00:13:40.140
THIS doesn't happen until there's a lot of evidence,

267
00:13:40.270 --> 00:13:43.150
uh, to sort of shift the scientific community towards

268
00:13:43.150 --> 00:13:45.869
taking that theory seriously as something that might be,

269
00:13:45.950 --> 00:13:49.320
be true about our world. Um. Uh, SO that's

270
00:13:49.320 --> 00:13:52.630
a big difference between hypotheses and theories. Hypotheses can

271
00:13:52.630 --> 00:13:54.880
be kind of open-ended conjectures, right? You might be

272
00:13:54.880 --> 00:13:56.479
out on a limb or a scientist might be

273
00:13:56.479 --> 00:13:59.599
out on a limb on, uh, a particular hypothesis

274
00:13:59.599 --> 00:14:02.679
that they're investigating, whereas a theory is kind of

275
00:14:02.679 --> 00:14:05.140
well corroborated by the time it's named a theory.

276
00:14:05.419 --> 00:14:07.239
Um, SOMETHING that lurks in the background of what

277
00:14:07.239 --> 00:14:10.479
I've already said is, um, And I don't know

278
00:14:10.479 --> 00:14:12.200
exactly how to say this well, um, but we

279
00:14:12.200 --> 00:14:14.039
also say something like this in, in the book

280
00:14:14.039 --> 00:14:18.280
that, um, uh, theories are kind of, um, Uh,

281
00:14:18.320 --> 00:14:21.440
they tend to be bigger and grander, um, kind

282
00:14:21.440 --> 00:14:24.469
of, uh, networked, uh, series of claims about how

283
00:14:24.469 --> 00:14:27.799
the world, uh, is rather than, than hypotheses tend

284
00:14:27.799 --> 00:14:32.919
to be, uh, sort of small, um, specific claims

285
00:14:32.919 --> 00:14:36.239
that can be kind of operationalized for investigation. So

286
00:14:36.239 --> 00:14:37.960
there's also a way in which theories kind of

287
00:14:37.960 --> 00:14:42.080
put together a successful hypotheses and articulate kind of

288
00:14:42.080 --> 00:14:44.520
the, uh, a framework of understanding the world on,

289
00:14:44.599 --> 00:14:45.400
on that basis.

290
00:14:46.080 --> 00:14:49.630
Mhm. And what are the different kinds of ways

291
00:14:49.630 --> 00:14:53.390
we can set up experiments in science? I mean,

292
00:14:53.429 --> 00:14:56.909
if I want to do a scientific experiment, how

293
00:14:56.909 --> 00:14:58.460
can I go about it?

294
00:14:59.309 --> 00:15:01.309
Uh, WELL, there too, right? The answer is lots

295
00:15:01.309 --> 00:15:03.630
of different ways. Um, AND this isn't, uh, I

296
00:15:03.630 --> 00:15:05.000
want to say on the front end, an area

297
00:15:05.000 --> 00:15:08.049
of philosophical expertise for me in particular. One of

298
00:15:08.049 --> 00:15:10.020
the nice things about having co-authors for this book

299
00:15:10.020 --> 00:15:12.900
is we did try to give a really even-handed,

300
00:15:13.070 --> 00:15:17.820
um, expansive treatment of um the different features, uh,

301
00:15:17.830 --> 00:15:21.650
of scientific methods and patterns of reasoning, um. Uh,

302
00:15:21.830 --> 00:15:23.520
SO, uh, so I don't work in philosophy of

303
00:15:23.520 --> 00:15:27.659
experiment in particular. Um, BUT in general, um, uh,

304
00:15:27.669 --> 00:15:31.030
experimentation in, in science is, is open-ended, as I

305
00:15:31.030 --> 00:15:34.190
suggested methods are in general in science. Um, HOW

306
00:15:34.190 --> 00:15:37.590
we talk about experiments in, in this book is

307
00:15:37.590 --> 00:15:41.059
starting with kind of a core, uh, description of,

308
00:15:41.070 --> 00:15:42.989
of, uh, what we think, and I think this,

309
00:15:43.109 --> 00:15:45.349
this follows kind of con conventional wisdom. What we

310
00:15:45.349 --> 00:15:49.336
think, um, experiments are. Designed to try to approximate,

311
00:15:49.637 --> 00:15:53.437
which is ultimately influence, you know, sort of extraneous

312
00:15:53.437 --> 00:15:57.036
influence on the independent variable, uh, control of all,

313
00:15:57.117 --> 00:16:01.317
uh, extraneous, um, variables, um, so that there aren't

314
00:16:01.317 --> 00:16:04.796
confounding variables and, and sort of, um, attention to

315
00:16:04.796 --> 00:16:07.956
or measurement of, uh, the dependent variable to see

316
00:16:07.956 --> 00:16:11.197
how it, um, how the dependent variable responds to

317
00:16:11.197 --> 00:16:14.914
a change to an intervention on the Independent variable.

318
00:16:15.244 --> 00:16:17.364
And then all of the variety that you see

319
00:16:17.364 --> 00:16:21.083
in experiments, sort of, um, uh, comes from different

320
00:16:21.083 --> 00:16:24.323
ways of trying to accomplish that goal. So one

321
00:16:24.323 --> 00:16:27.403
really basic, uh, difference is, are you in sort

322
00:16:27.403 --> 00:16:30.443
of, uh, a lab, uh, looking at a physical

323
00:16:30.443 --> 00:16:33.244
system where you can directly control most of the

324
00:16:33.244 --> 00:16:36.283
variables that aren't your independent variable or your dependent

325
00:16:36.283 --> 00:16:39.323
variable? Or are you trying to conduct an experiment

326
00:16:39.323 --> 00:16:42.091
out on, out. In the field somewhere, uh, and

327
00:16:42.091 --> 00:16:45.651
you need to indirectly control, um, variables with, for

328
00:16:45.651 --> 00:16:49.171
example, the use of statistical techniques. Um, AND, and

329
00:16:49.171 --> 00:16:51.851
then sort of differences, uh, sort of, as, as

330
00:16:51.851 --> 00:16:54.341
that suggests, differences kind of grow from there, right?

331
00:16:54.411 --> 00:16:55.851
So you might be in the field, you might

332
00:16:55.851 --> 00:16:58.200
be in the lab, depending on the types of

333
00:16:58.200 --> 00:17:01.450
uh phenomenon that you're investigating different types of techniques

334
00:17:01.450 --> 00:17:03.611
will be in order or, uh, you might be

335
00:17:03.611 --> 00:17:04.970
able to be in a lab or, or that

336
00:17:04.970 --> 00:17:07.750
might not even be possible. Um, I guess another

337
00:17:07.750 --> 00:17:12.760
difference is, um, hypotheses, uh, might be more directly

338
00:17:12.760 --> 00:17:16.589
amenable to experimental investigation or scientists might have to

339
00:17:16.589 --> 00:17:19.780
do some work before they even know what they

340
00:17:19.780 --> 00:17:22.989
would anticipate seeing, uh, and, and, and what kind

341
00:17:22.989 --> 00:17:26.150
of experimental system, uh, for some hypothesis that they

342
00:17:26.150 --> 00:17:28.479
have. Um. So that's pretty abstract, but that starts

343
00:17:28.479 --> 00:17:30.400
to gesture at some of the variety. The emphasis

344
00:17:30.400 --> 00:17:33.119
there is, I think that there is variety and

345
00:17:33.119 --> 00:17:35.400
that there's not sort of one best way to

346
00:17:35.400 --> 00:17:37.359
do it. So, so one of the things that

347
00:17:37.359 --> 00:17:40.010
sort of makes me grouchy is when, when, uh,

348
00:17:40.020 --> 00:17:42.880
scientists suggest that a certain way of doing science

349
00:17:42.880 --> 00:17:44.790
or a certain field of science is sort of

350
00:17:45.040 --> 00:17:48.739
better or more trustworthy, um. Uh, THEN another, and

351
00:17:48.739 --> 00:17:51.839
I think, I think that's not really fair. Mhm.

352
00:17:52.310 --> 00:17:55.979
Is all of science experimental in terms of its

353
00:17:55.979 --> 00:18:01.489
methodology, or are there also non-experimental methods in science?

354
00:18:01.819 --> 00:18:03.540
Yeah, so that's something we really want to emphasize

355
00:18:03.540 --> 00:18:05.140
in the book as well. Um, SO we have

356
00:18:05.140 --> 00:18:07.380
a chapter on experiment and then we follow it

357
00:18:07.380 --> 00:18:11.729
directly with a chapter on, um, non-experimental um studies.

358
00:18:11.939 --> 00:18:13.979
Um, SO there's a range of different ways of

359
00:18:13.979 --> 00:18:17.609
conducting studies in science, uh, when phenomena are not.

360
00:18:17.869 --> 00:18:20.540
I should say when phenomena or the particular hypothesis

361
00:18:20.540 --> 00:18:23.099
under investigation are not sort of well set up

362
00:18:23.099 --> 00:18:27.300
for direct uh experimental um interventions. Um, SO yeah,

363
00:18:27.400 --> 00:18:30.140
there are a range of non-experimental uh studies that

364
00:18:30.140 --> 00:18:34.300
are techniques in science, um, uh. And so in

365
00:18:34.300 --> 00:18:36.660
that chapter, sort of some of the, the easiest

366
00:18:36.660 --> 00:18:38.380
way to see that are are sort of studies

367
00:18:38.380 --> 00:18:40.380
that that in one way or another kind of

368
00:18:40.380 --> 00:18:43.219
try to approximate some of the control that experiments

369
00:18:43.219 --> 00:18:44.619
give us, but then there are different kinds of

370
00:18:44.619 --> 00:18:49.300
techniques entirely, such as a meta-analysis, right? Using existing

371
00:18:49.300 --> 00:18:52.859
data to try to sort of um Uh, draw

372
00:18:52.859 --> 00:18:55.609
conclusions from the different kinds of data received in

373
00:18:55.609 --> 00:18:58.900
different, uh, across different experiments. Um, AND then there

374
00:18:58.900 --> 00:19:02.979
are, there's also another approach, um, of non-experimental studies,

375
00:19:03.060 --> 00:19:05.770
which is, uh, for us, uh, the focus of,

376
00:19:05.900 --> 00:19:09.229
um, yet another chapter following directly on our non-experimental

377
00:19:09.229 --> 00:19:12.140
chapters, which is, uh, scientific modeling, right? So, so

378
00:19:12.140 --> 00:19:16.219
using computers, mathematical modeling techniques, etc. TO stand in

379
00:19:16.219 --> 00:19:18.469
for some of the work that's done, uh, in

380
00:19:18.469 --> 00:19:19.180
experiments.

381
00:19:20.099 --> 00:19:24.160
So you mentioned scientific modeling there. What is that?

382
00:19:24.189 --> 00:19:26.810
I mean, how do we model in science and

383
00:19:26.810 --> 00:19:28.239
what is the model?

384
00:19:29.449 --> 00:19:33.130
Yeah, so, um, scientific models, um, can take lots

385
00:19:33.130 --> 00:19:35.890
of different forms. Um, SEEMS like the sort of

386
00:19:35.890 --> 00:19:41.410
basic characteristics is, um, that, uh, scientists develop a

387
00:19:41.410 --> 00:19:44.089
system, so maybe I should use scare quotes, develop

388
00:19:44.089 --> 00:19:46.010
a system because that's where, where some of the

389
00:19:46.010 --> 00:19:47.729
difference come in. I'll say more about what I

390
00:19:47.729 --> 00:19:50.430
mean by developing a system in a second. Um,

391
00:19:50.560 --> 00:19:53.839
AND study that system in order to learn something

392
00:19:53.839 --> 00:19:55.920
about the world that they're interested to know about,

393
00:19:56.160 --> 00:20:00.030
right? So, uh, uh, maybe one kind of, um,

394
00:20:00.160 --> 00:20:02.050
well, actually I'll, I'll start with the starting point,

395
00:20:02.060 --> 00:20:03.599
uh, that we have for discussing models in the

396
00:20:03.599 --> 00:20:07.125
book, which is, um, physical scale models, right? Um,

397
00:20:07.165 --> 00:20:09.204
IN the book, we focus on, um, the San

398
00:20:09.204 --> 00:20:12.324
Francisco Bay model that was uh developed several decades

399
00:20:12.324 --> 00:20:14.435
ago by the Army Corps of Engineers. This is,

400
00:20:14.444 --> 00:20:17.685
uh, an example that philosopher of science, Michael Weisberg,

401
00:20:17.844 --> 00:20:20.405
uh, introduced, um, to the field of philosophy of

402
00:20:20.405 --> 00:20:22.604
science and sort of, um, is well recognized, I

403
00:20:22.604 --> 00:20:26.719
think, um, uh, from his work. Um, AND, uh,

404
00:20:26.729 --> 00:20:29.209
the Army Corps of Engineers literally built a scale

405
00:20:29.209 --> 00:20:31.569
model of the San Francisco Bay in order to

406
00:20:31.569 --> 00:20:36.260
study how, um, um, interventions on the real bay,

407
00:20:36.369 --> 00:20:40.000
uh, that, that, um, uh, policymakers were considering making,

408
00:20:40.329 --> 00:20:43.410
uh, would affect the bay, um, what, what the

409
00:20:43.410 --> 00:20:45.489
results would be, right? And the nice thing about

410
00:20:45.489 --> 00:20:47.579
that is that they could study this. They worked

411
00:20:47.579 --> 00:20:49.780
really hard to set up, you know, a really

412
00:20:49.780 --> 00:20:51.949
large Scale model. It's, it's more than 1 acre

413
00:20:51.949 --> 00:20:54.489
big if, if memory serves, but much smaller than

414
00:20:54.489 --> 00:20:57.170
the full San Francisco Bay in the world, um,

415
00:20:57.260 --> 00:20:59.109
and, and much quicker acting. And they were able

416
00:20:59.109 --> 00:21:01.770
to sort of make interventions on the model to

417
00:21:01.770 --> 00:21:04.449
see what would happen, because it's sort of relevantly

418
00:21:04.449 --> 00:21:07.050
similar to the real bay. Um, BEFORE, you know,

419
00:21:07.170 --> 00:21:08.689
if you had just gone in there and started

420
00:21:08.689 --> 00:21:11.500
building dams in the San Francisco Bay, then, then,

421
00:21:11.530 --> 00:21:14.410
um, you would have found out how that affected

422
00:21:14.410 --> 00:21:17.209
the system, uh, really kind of too late, right,

423
00:21:17.290 --> 00:21:19.930
after some of the damage had been done. Um,

424
00:21:20.140 --> 00:21:21.979
OK, so that's an example of a scale model

425
00:21:21.979 --> 00:21:24.140
of, of how you might be able to and

426
00:21:24.140 --> 00:21:26.329
why you might want to, to look at, um,

427
00:21:26.459 --> 00:21:28.689
sort of a sort of toy model over here

428
00:21:28.859 --> 00:21:30.530
to try to see what would happen in, uh,

429
00:21:30.540 --> 00:21:32.180
to the system in the real world that you're

430
00:21:32.180 --> 00:21:34.699
interested in. But the same basic technique I think

431
00:21:34.699 --> 00:21:39.420
is used, um, when scientists, as increasingly happen, um,

432
00:21:39.739 --> 00:21:43.250
develop computer models, right? Find variables and, and, uh,

433
00:21:43.260 --> 00:21:47.459
sort of, um, uh, dynamics in a computerized system,

434
00:21:47.540 --> 00:21:51.020
right, a computer game effectively. Um, 11 kind or

435
00:21:51.020 --> 00:21:55.619
another, um, to represent, uh, or, uh, kind of

436
00:21:55.619 --> 00:21:57.540
reflect how things would play out in the real

437
00:21:57.540 --> 00:21:59.750
world. Um, SO this is done, for example, a

438
00:21:59.750 --> 00:22:02.550
lot with climate modeling now, uh, climate modeling uses

439
00:22:02.550 --> 00:22:06.900
computer, um, modeling techniques, um, as one, as one

440
00:22:06.900 --> 00:22:09.459
example, lots of fields do. Um, AND then, and

441
00:22:09.459 --> 00:22:11.579
then we think also, I think we here is

442
00:22:11.579 --> 00:22:13.979
philosophers science in general that the same basic and

443
00:22:13.979 --> 00:22:17.569
maybe scientists as well, the same basic um practice

444
00:22:17.569 --> 00:22:21.979
is um playing out when scientists write equations, right?

445
00:22:22.000 --> 00:22:25.010
To, to, to try to represent a system, um,

446
00:22:25.060 --> 00:22:28.140
choose their variables to represent features of interest, and

447
00:22:28.140 --> 00:22:31.819
then uh solve the equations, um, uh, or see

448
00:22:31.819 --> 00:22:34.540
how, how the dynamics play out, um, in a

449
00:22:34.540 --> 00:22:38.510
way that represents, um. Uh, REAL activities in the

450
00:22:38.510 --> 00:22:40.150
world, and so those, uh, we think of as

451
00:22:40.150 --> 00:22:43.400
mathematical models. So all of those, uh, um, philosophers

452
00:22:43.400 --> 00:22:45.040
science are used to thinking of as kind of

453
00:22:45.040 --> 00:22:47.550
the same basic technique, even they, even though they

454
00:22:47.550 --> 00:22:51.189
go about, um, modeling systems in different ways.

455
00:22:52.290 --> 00:22:55.979
And what is the relationship between the scientific model

456
00:22:56.270 --> 00:23:00.030
and the reality or the aspects of reality that

457
00:23:00.030 --> 00:23:01.510
it is trying to model?

458
00:23:02.239 --> 00:23:05.209
Yeah, we, we emphasize in our book that, um,

459
00:23:05.459 --> 00:23:07.969
uh, first of all, that relationship is, is often

460
00:23:07.969 --> 00:23:10.489
seen in philosophy of science as representation, right? In

461
00:23:10.489 --> 00:23:11.969
the, in the way that I, I talked about

462
00:23:11.969 --> 00:23:14.479
this sort of model standing in, in some sense

463
00:23:14.479 --> 00:23:16.810
for the real world. Um, YOU can study the

464
00:23:16.810 --> 00:23:19.349
model and then draw conclusions about the system in

465
00:23:19.349 --> 00:23:21.619
the world that's supposed to represent on the basis.

466
00:23:22.229 --> 00:23:24.709
On that basis. And, uh, we emphasize in the

467
00:23:24.709 --> 00:23:27.060
book that, uh, that relies on a kind of

468
00:23:27.060 --> 00:23:30.949
relevant similarity or set of relevant similarities between the

469
00:23:30.949 --> 00:23:33.459
model or features of the model and the system

470
00:23:33.459 --> 00:23:36.790
that's being modeled. Um, AND, but notice that effective

471
00:23:36.790 --> 00:23:38.900
modeling, right? The whole idea of, of using a

472
00:23:38.900 --> 00:23:41.689
model. INSTEAD of the studying, studying the system itself

473
00:23:41.689 --> 00:23:45.449
relies also on relevant differences. So I emphasize when

474
00:23:45.449 --> 00:23:47.770
I talked about the bay model right away that

475
00:23:47.770 --> 00:23:49.810
it's important that the San Francisco Bay model is

476
00:23:49.810 --> 00:23:52.520
a lot smaller than the real San Francisco Bay

477
00:23:52.729 --> 00:23:55.520
and that it's quicker acting, right? And so, so,

478
00:23:55.530 --> 00:24:01.579
um. Moers, scientific modelers, um, develop, uh, models again

479
00:24:01.579 --> 00:24:05.260
of one kind or another, mathematical equations, um, computer

480
00:24:05.469 --> 00:24:09.979
models, um, physical models, etc. um, IN ways, uh,

481
00:24:09.989 --> 00:24:12.989
that, um, uh, so that the models are, are

482
00:24:12.989 --> 00:24:16.109
relevant relevantly similar in certain respects to the systems

483
00:24:16.109 --> 00:24:19.060
they're interested in, but then also relevantly different, uh,

484
00:24:19.069 --> 00:24:22.270
so that they can sort of, um, Um, so

485
00:24:22.270 --> 00:24:25.180
they're convenient and, and, and usable in a way

486
00:24:25.180 --> 00:24:27.989
that that direct investigation of the system wouldn't be.

487
00:24:29.329 --> 00:24:32.560
And how do we know that a particular model

488
00:24:32.560 --> 00:24:35.290
is a good or at least a good enough

489
00:24:35.290 --> 00:24:36.250
model? Yeah,

490
00:24:36.410 --> 00:24:39.890
it's a, it's a hugely challenging question. Um, NOTICE

491
00:24:39.890 --> 00:24:41.969
that that it's uh similar to questions that we

492
00:24:41.969 --> 00:24:44.329
have about experiments too, though. This isn't a special

493
00:24:44.329 --> 00:24:48.250
question for models, right? When is, um, an experimental

494
00:24:48.250 --> 00:24:51.369
system enough like the phenomenon in the world that,

495
00:24:51.410 --> 00:24:53.729
that what we saw happen in the lab is

496
00:24:53.729 --> 00:24:55.354
gonna happen in In the real world too. And

497
00:24:55.354 --> 00:24:58.435
so the same question happens for models. Um, HOW

498
00:24:58.435 --> 00:25:00.905
do we know that, uh, right, if the San

499
00:25:00.905 --> 00:25:04.155
Francisco Bay model uh responded this way to, to

500
00:25:04.155 --> 00:25:07.074
the intervention under consideration to building dams, etc. THAT

501
00:25:07.074 --> 00:25:10.594
the real San Francisco Bay will, um, it's, it's

502
00:25:10.594 --> 00:25:14.050
a hugely challenging question. Um, AND, and at the

503
00:25:14.050 --> 00:25:15.920
heart of it is again the sort of relevant

504
00:25:15.920 --> 00:25:19.849
similarity question, I think. And so checking to see

505
00:25:19.849 --> 00:25:23.089
whether the parameters of the model, um, that you

506
00:25:23.089 --> 00:25:26.449
think matter, that the scientist thinks matters to the

507
00:25:26.449 --> 00:25:29.959
phenomenon under investigation, checking to see that those parameters

508
00:25:30.209 --> 00:25:33.089
are the same or relevantly similar, right? Um, SO

509
00:25:33.089 --> 00:25:35.329
maybe scaled, right, in the, in the case of

510
00:25:35.329 --> 00:25:39.150
the scale physical model. Um. Uh, AND then, and

511
00:25:39.150 --> 00:25:41.869
then checking to see which parameters matter. So that,

512
00:25:41.910 --> 00:25:44.939
so, um, it's easy to just, uh, imagine that

513
00:25:44.949 --> 00:25:47.670
that we have answers to what the relevant similarities

514
00:25:47.670 --> 00:25:49.310
need to be, but it could be, and it

515
00:25:49.310 --> 00:25:52.469
regularly is the case that scientists discovered that something

516
00:25:52.469 --> 00:25:55.750
they thought didn't matter is something that's important, um,

517
00:25:55.790 --> 00:25:57.939
to, to, is an important feature of the system.

518
00:25:57.949 --> 00:26:00.780
And so, I kind of, um, got lost to

519
00:26:00.780 --> 00:26:03.329
the details there. So just characterize that again. This

520
00:26:03.329 --> 00:26:06.810
is a really hard question. When, uh, is the

521
00:26:06.810 --> 00:26:09.250
kind of results in the model trustworthy? There's not

522
00:26:09.250 --> 00:26:10.969
a single answer, I think, to like, here's how

523
00:26:10.969 --> 00:26:12.560
you know, and we've done that and we're done.

524
00:26:12.810 --> 00:26:15.410
Um, BUT that the answer includes at least two

525
00:26:15.410 --> 00:26:17.569
ingredients. First of all, ensuring that there's the kind

526
00:26:17.569 --> 00:26:21.339
of relevant similarity and the parameters that matter. Um,

527
00:26:21.479 --> 00:26:25.280
BUT then secondly, ensuring that that you've actually accurately

528
00:26:25.280 --> 00:26:29.560
identified the main parameters that matter for the particular

529
00:26:29.560 --> 00:26:32.520
phenomenon that you're interested in, um, in order to

530
00:26:32.520 --> 00:26:34.729
have sort of assessed that effectively.

531
00:26:36.180 --> 00:26:38.359
Right. So let me now ask you a little

532
00:26:38.359 --> 00:26:41.670
bit about scientific reasoning. Could you tell us about

533
00:26:41.670 --> 00:26:46.439
the concepts of reasoning, inference, and argument?

534
00:26:47.160 --> 00:26:48.989
Yeah, so, so, um, this is a part of

535
00:26:48.989 --> 00:26:51.319
the book that, that my co-author Corey Wright, um,

536
00:26:51.390 --> 00:26:53.270
is more responsible for than I am, um, but

537
00:26:53.270 --> 00:26:56.989
I'll do my best. Um, SO, um, there's a

538
00:26:56.989 --> 00:26:59.180
big shift in the topics of our book from

539
00:26:59.180 --> 00:27:00.510
the kinds of topics that you and I have

540
00:27:00.510 --> 00:27:03.469
been talking about so far, right? How scientific experiments

541
00:27:03.469 --> 00:27:07.219
work, um, scientific models, etc. TO taking a step

542
00:27:07.219 --> 00:27:10.310
back and thinking about the, the reasoning patterns that

543
00:27:10.310 --> 00:27:12.550
you see in science. And so we want to

544
00:27:12.550 --> 00:27:16.900
emphasize that, um, Uh, in science, it's not as

545
00:27:16.900 --> 00:27:19.339
if you sort of set up an experiment and

546
00:27:19.339 --> 00:27:21.020
or it's not as if scientists set up an

547
00:27:21.020 --> 00:27:23.819
experiment, get the data, and then have a check

548
00:27:23.819 --> 00:27:26.020
mark or next next to their hypothesis, and they're

549
00:27:26.020 --> 00:27:30.630
done. Instead, um, data, uh, sort of are, are

550
00:27:30.630 --> 00:27:35.270
points where, uh, empirical information about the world weigh

551
00:27:35.270 --> 00:27:39.010
in on what actually can be quite elaborate scientific

552
00:27:39.010 --> 00:27:41.750
arguments. OK. So what we mean by arguments are

553
00:27:41.750 --> 00:27:47.089
sort of um um ways of Marshaling evidence um

554
00:27:47.089 --> 00:27:51.680
using reasoning in order to assemble, um, reasons in

555
00:27:51.680 --> 00:27:55.689
support of uh a scientific conclusion, right? So, so

556
00:27:55.689 --> 00:27:57.670
I, I suppose you can say that sort of

557
00:27:57.670 --> 00:28:01.089
um developing official scientific arguments, uh, it can, as

558
00:28:01.089 --> 00:28:04.449
a way of moving us from um empirical data

559
00:28:04.449 --> 00:28:08.150
weighing on hypotheses towards putting together. Um, A sort

560
00:28:08.150 --> 00:28:10.790
of, you know, uh, theoretical structure like we talked

561
00:28:10.790 --> 00:28:13.150
about a theory that kind of, um, uh, is,

562
00:28:13.189 --> 00:28:15.030
is a good guess of how the world really

563
00:28:15.030 --> 00:28:18.189
is. Um, SO one of the things that we

564
00:28:18.189 --> 00:28:20.630
wanted to emphasize in the contrast between reasoning and

565
00:28:20.630 --> 00:28:22.869
arguments is that arguments have, in the way that

566
00:28:22.869 --> 00:28:24.949
we use the term, have this, this structure of

567
00:28:24.949 --> 00:28:28.439
kind of uh socially available to the community of

568
00:28:28.439 --> 00:28:31.949
scientists, written down, right, or sort of um officially

569
00:28:31.949 --> 00:28:35.719
worked through, uh, in a way that um Uh,

570
00:28:35.760 --> 00:28:40.670
is it, is, um, useful for the, um, social,

571
00:28:41.119 --> 00:28:44.400
um, project that science is, right, where different scientists

572
00:28:44.400 --> 00:28:47.640
work across different projects and experiments to kind of

573
00:28:47.910 --> 00:28:51.760
um marshal evidence in favor of, um, or opposed

574
00:28:51.760 --> 00:28:56.469
to um different ideas. Um, EN route to to

575
00:28:56.469 --> 00:28:59.589
developing theories, um, about our world, um, and in

576
00:28:59.589 --> 00:29:02.670
contrast, reasoning is sort of, um, you know, quite

577
00:29:02.670 --> 00:29:06.300
broad, uh, an important feature of science, uh, where,

578
00:29:06.310 --> 00:29:09.349
where any individual scientist, um, does this on a

579
00:29:09.349 --> 00:29:12.770
regular basis, often without even recognizing it in how

580
00:29:12.770 --> 00:29:16.109
they connect empirical data to to ideas, confirming, dis

581
00:29:16.109 --> 00:29:17.510
confirming hypotheses, etc.

582
00:29:19.359 --> 00:29:22.949
So, uh, and in science, we have not only

583
00:29:23.119 --> 00:29:27.599
inductive reasoning, but also deductive and abductive reasoning, right?

584
00:29:27.709 --> 00:29:31.239
I mean, because sometimes people have these, there's this

585
00:29:31.239 --> 00:29:34.199
very common idea that all reasoning in science is

586
00:29:34.199 --> 00:29:38.109
inductive in the sense that if it works, then

587
00:29:38.109 --> 00:29:41.199
it means it's true or scientifically true, but we

588
00:29:41.199 --> 00:29:45.239
also, we can also use deduction and abduction in

589
00:29:45.239 --> 00:29:45.760
science,

590
00:29:45.920 --> 00:29:48.219
right? Yeah, and this is one place where work

591
00:29:48.219 --> 00:29:51.349
that philosophers of science, um, uh, sort of has

592
00:29:51.349 --> 00:29:54.459
something to offer for how we more broadly think

593
00:29:54.459 --> 00:29:58.550
about, about, um, argumentation or reasoning in science. Um,

594
00:29:58.699 --> 00:30:01.500
AND so, um, I guess speaking for myself, I

595
00:30:01.500 --> 00:30:04.099
think that the three types of reasoning that my

596
00:30:04.099 --> 00:30:06.420
co-authors and I identify in that book, as you

597
00:30:06.420 --> 00:30:11.250
said, inductive reasoning, deductive reasoning, and abductive reasoning. Um,

598
00:30:11.500 --> 00:30:15.295
THERE'S something important. Uh, ABOUT each of those forms

599
00:30:15.295 --> 00:30:17.734
of reasoning that, that kind of um helps us

600
00:30:17.734 --> 00:30:21.055
see something deep and interesting about science itself. So

601
00:30:21.055 --> 00:30:23.214
starting with deductive reasoning, as we do in the

602
00:30:23.214 --> 00:30:26.814
book, um, deductive reasoning is this kind of super

603
00:30:26.814 --> 00:30:29.734
fancy special kind of reasoning that philosophers science think

604
00:30:29.734 --> 00:30:32.805
a lot about insofar as, as, um, we use

605
00:30:32.805 --> 00:30:37.089
logic and study logic, um. Uh, AND mathematics, etc.

606
00:30:37.530 --> 00:30:40.650
um, AND deductive reasoning, uh, is sort of super

607
00:30:40.650 --> 00:30:44.530
special and fancy in that, um, uh, it's a

608
00:30:44.530 --> 00:30:47.170
there it, it provides a kind of certainty and

609
00:30:47.170 --> 00:30:51.520
guarantee that inductive and abductive forms of reasoning can't.

610
00:30:51.849 --> 00:30:57.569
So, um, a valid. Uh, INDUCTIVE argument, uh, which

611
00:30:57.569 --> 00:30:59.589
is the sort of term of art, right, valid,

612
00:30:59.729 --> 00:31:04.170
um, uh, deductive validity here, means that uh if

613
00:31:04.170 --> 00:31:06.290
the premises, if the starting points of the argument

614
00:31:06.290 --> 00:31:09.329
are true, then the conclusion absolutely has to be

615
00:31:09.329 --> 00:31:11.890
true as well. And there are interesting ways that,

616
00:31:11.989 --> 00:31:16.319
that, um, Uh, scientific methods can make use of

617
00:31:16.810 --> 00:31:21.760
that feature of um deductive argumentation. And it's worth

618
00:31:21.760 --> 00:31:26.520
noting, um, in general, uh, this isn't something, uh,

619
00:31:26.530 --> 00:31:30.010
that can conclude the truth of hypotheses about our

620
00:31:30.010 --> 00:31:32.640
world, right, beyond a shadow of a doubt, um,

621
00:31:32.650 --> 00:31:36.239
but there's sort of ways of, of um recruiting,

622
00:31:36.650 --> 00:31:41.410
uh, deductively valid arguments, um, in order to sort

623
00:31:41.410 --> 00:31:45.569
of, um, Uh, structure, um, the, the patterns of

624
00:31:45.569 --> 00:31:47.849
reasoning that we see in science, um, in certain

625
00:31:47.849 --> 00:31:52.250
special jobs. Um, INDUCTIVE reasoning, um, as, as you

626
00:31:52.250 --> 00:31:56.209
already suggested, um, is sort of, um, important broadly

627
00:31:56.209 --> 00:31:58.849
in science and is generally the kind of reasoning

628
00:31:58.849 --> 00:32:02.849
process behind, um, marshaling evidential support for against a

629
00:32:02.849 --> 00:32:05.609
hypothesis. Um, AND I would say that the important

630
00:32:05.609 --> 00:32:08.890
characteristic to notice here about inductive reasoning is that

631
00:32:08.890 --> 00:32:11.489
it's the opposite of deductive reasoning in the sense

632
00:32:11.489 --> 00:32:14.239
that it goes beyond, right, the conclusion goes beyond

633
00:32:14.239 --> 00:32:17.329
the premises, the starting points of the argument. Um,

634
00:32:17.410 --> 00:32:19.089
AND so an important thing to notice there is

635
00:32:19.089 --> 00:32:21.609
that there is a kind of conjecture or, or

636
00:32:21.609 --> 00:32:24.839
moving beyond our evidential basis, kind of, you know,

637
00:32:25.219 --> 00:32:27.410
um, putting yourself out there, uh, in what you're

638
00:32:27.410 --> 00:32:30.619
concluding. Um, AND, and as you say, that's an

639
00:32:30.619 --> 00:32:32.890
um I think widely seen to be an important

640
00:32:32.890 --> 00:32:36.619
feature of, of science, that, that hypotheses really kind

641
00:32:36.619 --> 00:32:39.410
of no matter how much data we've gotten, um,

642
00:32:39.540 --> 00:32:42.900
hypotheses and even our theories, um, are, are well

643
00:32:42.900 --> 00:32:46.619
corroborated theories are kind of um conjectural, um, about

644
00:32:46.619 --> 00:32:51.130
the world. And then briefly abductive reasoning, what we

645
00:32:51.130 --> 00:32:54.010
want to emphasize there is, um, that there's also

646
00:32:54.010 --> 00:32:56.569
an important kind of reasoning in science that that

647
00:32:56.569 --> 00:33:00.810
doesn't just kind of generalize inductively from the sort

648
00:33:00.810 --> 00:33:03.170
of things we see in our, our world, but

649
00:33:03.170 --> 00:33:05.410
that looks at the sort of evidence we have

650
00:33:05.410 --> 00:33:09.810
access to, um, to, um, in some cases, put

651
00:33:09.810 --> 00:33:13.050
together a sort of a, a potentially explanatory story

652
00:33:13.050 --> 00:33:15.410
about why those features of the world seem the

653
00:33:15.410 --> 00:33:19.219
way that they are. That might appeal to um

654
00:33:19.380 --> 00:33:23.060
uh features of our world that we can't directly

655
00:33:23.060 --> 00:33:26.930
test experimentally, right? So, so, um, some scientific theories

656
00:33:26.930 --> 00:33:30.410
get beyond positing things that we can just directly,

657
00:33:30.699 --> 00:33:33.739
uh, check for, um, and posit sort of explanatory

658
00:33:33.739 --> 00:33:36.214
features of the world that we have to Um,

659
00:33:36.244 --> 00:33:38.285
you know, to some extent or another, uh, sort

660
00:33:38.285 --> 00:33:40.964
of take on faith, right? So, so, um, uh,

661
00:33:41.045 --> 00:33:44.114
the Higgs boson, right? The most recent, um, uh,

662
00:33:44.125 --> 00:33:47.964
fundamental particle that, that, uh, um, was announced as,

663
00:33:48.005 --> 00:33:51.425
as having been discovered. Um, THERE'S evidence, uh, for

664
00:33:51.425 --> 00:33:53.604
the Higgs boson, but nobody can sort of look

665
00:33:53.604 --> 00:33:55.165
at one under a microscope.

666
00:33:55.859 --> 00:34:01.180
Mhm. Right. And what role do statistics and probability

667
00:34:01.180 --> 00:34:05.219
play in science and is all of science statistical

668
00:34:05.219 --> 00:34:07.290
and probabilistic or not?

669
00:34:08.228 --> 00:34:10.168
Yeah, good question. So here I'll say that my

670
00:34:10.168 --> 00:34:13.168
co-author Matteo Colombo is really our expert on probability

671
00:34:13.168 --> 00:34:17.290
and statistics um for our author group, um, but

672
00:34:17.290 --> 00:34:20.958
uh I'll do my best again. Um, um, uh,

673
00:34:20.969 --> 00:34:24.735
PROBABILITY and statistics are incredibly important. Science, um, that

674
00:34:24.735 --> 00:34:28.614
said, not all science, um, proceeds, um, with the

675
00:34:28.614 --> 00:34:30.774
use of statistics, right? So it's not as if,

676
00:34:30.824 --> 00:34:32.965
um, you have to check and make sure that,

677
00:34:33.043 --> 00:34:36.043
that a scientific article is using statistics before you

678
00:34:36.043 --> 00:34:39.254
know whether it's real science or not, right? Um.

679
00:34:39.530 --> 00:34:43.540
The reason, or a reason that pro probabilistic reasoning

680
00:34:43.540 --> 00:34:46.978
and um the tools of statistics are so useful

681
00:34:46.978 --> 00:34:49.458
in science, uh, from my perspective is that it's

682
00:34:49.458 --> 00:34:52.580
an exceedingly complex world that we live in. Lots

683
00:34:52.580 --> 00:34:54.860
of things are interacting all over the place, uh,

684
00:34:55.100 --> 00:34:57.620
including in the systems that we're interested in, including

685
00:34:57.620 --> 00:35:01.340
even in sort of well, um, uh, set up.

686
00:35:01.429 --> 00:35:06.139
Experimental systems, right? Experiments. Um, AND statistical tools can

687
00:35:06.139 --> 00:35:08.979
let you, or, or have, uh, uh, again, lots

688
00:35:08.979 --> 00:35:11.610
of different tricks, right? Lots of different ways of,

689
00:35:11.780 --> 00:35:17.139
of helping scientists, um, find, identify patterns, um, and,

690
00:35:17.179 --> 00:35:19.620
and sort of move, put to the side that

691
00:35:19.620 --> 00:35:22.590
the noise, the different influences that, that can obscure

692
00:35:22.590 --> 00:35:23.209
patterns.

693
00:35:24.080 --> 00:35:27.639
Mhm. So, uh, this is a question that I

694
00:35:27.639 --> 00:35:31.560
think uh relates to something that people, even lay

695
00:35:31.560 --> 00:35:35.129
people tend to be more exposed to, particularly in

696
00:35:35.129 --> 00:35:38.320
the news when it comes to statistical methods in

697
00:35:38.320 --> 00:35:42.060
science. Um, HOW can they be used to make,

698
00:35:42.209 --> 00:35:46.850
to make estimates about the population from a sample?

699
00:35:46.979 --> 00:35:49.590
Because, you know, many times when people hear about

700
00:35:49.590 --> 00:35:52.659
statistics uh uh in the news, they think, oh,

701
00:35:52.739 --> 00:35:57.110
but that didn't particularly, for example, in medicine. Uh,

702
00:35:57.409 --> 00:36:00.560
THEY, they tend to say, oh, but that didn't

703
00:36:00.560 --> 00:36:03.239
really happen to me, and I know someone who

704
00:36:03.239 --> 00:36:06.679
had, for example, side effects of vaccine or something

705
00:36:06.679 --> 00:36:09.729
like that. So, uh, tell us, how can we

706
00:36:09.729 --> 00:36:13.959
make estimates from just a sample of the entire

707
00:36:13.959 --> 00:36:14.479
population.

708
00:36:14.729 --> 00:36:17.419
Yes, this is an incredibly important use of statistics,

709
00:36:17.530 --> 00:36:21.820
um, and so, so as you suggest, um, uh.

710
00:36:22.810 --> 00:36:27.449
11 use of uh statistical methods, um, very widespread

711
00:36:27.449 --> 00:36:31.570
use is to um uh look at um uh

712
00:36:31.570 --> 00:36:34.810
only a subset of um a group, um could

713
00:36:34.810 --> 00:36:38.129
be people, could be, you know, etc. um, DOESN'T

714
00:36:38.129 --> 00:36:40.280
have to be people, uh, a subset of a

715
00:36:40.280 --> 00:36:44.179
group of one kind or another, uh, and, um,

716
00:36:44.429 --> 00:36:47.159
uh. So this actually starts to, what I'm going

717
00:36:47.159 --> 00:36:48.600
to say at least starts to sound a lot

718
00:36:48.600 --> 00:36:51.040
like what I was saying about modeling. Um, SO

719
00:36:51.040 --> 00:36:53.639
first of all, uh, the scientists check to ensure

720
00:36:53.639 --> 00:36:55.919
that the group under investigation, let's just stick with

721
00:36:55.919 --> 00:36:58.030
people because that is an intuitive example and it's,

722
00:36:58.040 --> 00:37:00.750
it's uh where you started us in, in thinking

723
00:37:00.750 --> 00:37:02.760
about it. Um, AND so scientists, first of all,

724
00:37:02.919 --> 00:37:05.729
check to ensure. Sure that the group under investigation

725
00:37:05.729 --> 00:37:08.850
is relevantly similar to the full population. So if

726
00:37:08.850 --> 00:37:11.679
your full population that you're worried about is, um,

727
00:37:11.889 --> 00:37:16.409
right, all Americans, uh uh um trying to avoid

728
00:37:16.409 --> 00:37:19.959
anything socially controversial, um, sorry, I'm not good with

729
00:37:19.959 --> 00:37:23.120
uh examples off the top of my head. Um,

730
00:37:23.260 --> 00:37:27.810
IF we're looking for all Americans, uh, and, um,

731
00:37:28.179 --> 00:37:31.020
what the health impacts are of eating at least

732
00:37:31.020 --> 00:37:34.570
one serving of green vegetable a day, right? Um,

733
00:37:34.580 --> 00:37:36.649
THEN you want to make sure the scientists want

734
00:37:36.649 --> 00:37:38.939
the health researchers want to make sure that the

735
00:37:38.939 --> 00:37:42.459
population under study is relevantly similar to all Americans,

736
00:37:42.540 --> 00:37:46.239
uh, if this is the, the population. Investigation. So

737
00:37:46.239 --> 00:37:50.120
if um they're researching a class of kindergarteners, this

738
00:37:50.120 --> 00:37:52.350
isn't this isn't going to, to work, right? Uh,

739
00:37:52.360 --> 00:37:54.360
WE need to make sure that we have um

740
00:37:54.360 --> 00:37:57.280
people of different ages, different types of lifestyles more

741
00:37:57.280 --> 00:38:01.439
generally, different uh uh background health conditions, etc. SUCH

742
00:38:01.439 --> 00:38:05.360
that the the um group under investigation is relevantly

743
00:38:05.360 --> 00:38:08.149
similar to the full population. Um, BUT then there's

744
00:38:08.149 --> 00:38:10.909
something kind of magical that happens, which is if

745
00:38:10.909 --> 00:38:14.149
the, uh, group is sufficiently large, right? You can't

746
00:38:14.149 --> 00:38:16.469
just study one person and see how eating at

747
00:38:16.469 --> 00:38:18.550
least one serving of vegetable a day is good

748
00:38:18.550 --> 00:38:20.860
for that person. Um, YOU have to have some,

749
00:38:20.949 --> 00:38:23.030
some variety among your subjects, but if you have

750
00:38:23.030 --> 00:38:25.850
a sufficiently large group, um, actually it doesn't have

751
00:38:25.850 --> 00:38:27.389
to be all that large, and I can't give

752
00:38:27.389 --> 00:38:28.429
you a number off the top of my head,

753
00:38:28.510 --> 00:38:32.169
but like 100 people is probably good. Um. Uh,

754
00:38:32.290 --> 00:38:35.239
OFTENTIMES medical studies are, are much larger than that.

755
00:38:35.560 --> 00:38:38.290
Um, SO sufficiently large group that's relevantly similar to

756
00:38:38.290 --> 00:38:41.449
the population under study, um, then you're able to

757
00:38:41.449 --> 00:38:44.409
project what uh the features of the full population

758
00:38:44.409 --> 00:38:46.570
are on the basis of the features or the,

759
00:38:46.610 --> 00:38:50.649
the responses of, um, this, this group in particular.

760
00:38:51.229 --> 00:38:54.949
I mean, we many times hear about correlation and

761
00:38:54.949 --> 00:38:59.979
causation and how correlation doesn't necessarily imply causation. So

762
00:38:59.979 --> 00:39:04.229
in science, what is the relationship between correlation and

763
00:39:04.229 --> 00:39:04.909
causation?

764
00:39:05.520 --> 00:39:07.580
Yeah, so there's not a single answer to give

765
00:39:07.580 --> 00:39:09.550
here. I mean, I think you just characterized the

766
00:39:09.550 --> 00:39:12.739
most important thing to remember, um, and that is

767
00:39:12.909 --> 00:39:16.790
correlation and, and identifying correlations in science is an

768
00:39:16.790 --> 00:39:20.189
incredibly in a variety of circumstances is an incredibly

769
00:39:20.189 --> 00:39:23.590
important guide to causal relationships. But as we've all

770
00:39:23.590 --> 00:39:26.870
been taught, you know, through school, uh correlation does

771
00:39:26.870 --> 00:39:29.909
not in itself constitute causation. There are other questions

772
00:39:29.909 --> 00:39:32.350
to ask when you see a correlation, a simple

773
00:39:32.350 --> 00:39:36.229
correlation before you know there's a causal relationship. Um,

774
00:39:36.360 --> 00:39:39.040
SO one way that correlation is, is really important

775
00:39:39.040 --> 00:39:43.560
is in, um, uh, statistical, uh, hypothesis testing, right?

776
00:39:43.719 --> 00:39:46.790
So, so when you have, uh, an experimental group

777
00:39:46.790 --> 00:39:48.550
and a control group, let's go back to our,

778
00:39:48.639 --> 00:39:50.959
um, people who eat at least one vegetable serving

779
00:39:50.959 --> 00:39:53.600
of vegetable a day. So for our experimental group

780
00:39:53.600 --> 00:39:56.270
is um being asked to have. At least one

781
00:39:56.270 --> 00:39:59.060
serving of vegetable a day and we measure our

782
00:39:59.060 --> 00:40:01.750
control group and say see that on balance they

783
00:40:01.750 --> 00:40:04.790
don't achieve that, something like that. Um, THEN the

784
00:40:04.790 --> 00:40:08.750
correlation uh in the health outcomes of the experimental

785
00:40:08.750 --> 00:40:11.649
group, right, the, the reduced incidence of cancer, uh,

786
00:40:11.659 --> 00:40:14.750
to, to choose one real effect of, of increasing

787
00:40:14.750 --> 00:40:19.520
vegetable consumption. Um, IS a guide to, um, uh,

788
00:40:19.530 --> 00:40:22.649
there being a causal relationship, that is a guide

789
00:40:22.649 --> 00:40:26.840
to, um, across people with, with all of different,

790
00:40:26.850 --> 00:40:30.600
uh, sort of background health conditions, ages, etc. um,

791
00:40:30.929 --> 00:40:34.290
uh, THAT if you choose to or if you

792
00:40:34.290 --> 00:40:36.510
consume at least one serving of vegetable a day,

793
00:40:36.610 --> 00:40:40.959
you'll see sort of a correlation with decreased, uh,

794
00:40:40.969 --> 00:40:44.510
incidence of cancer. Um, SO that's 11 context, scientific

795
00:40:44.510 --> 00:40:46.469
context in which correlation is an important guide to

796
00:40:46.469 --> 00:40:48.310
causation, but like I said, sort of there are

797
00:40:48.310 --> 00:40:50.270
lots of different ways in which it can be.

798
00:40:51.000 --> 00:40:54.159
Um, BUT, right, uh, kind of a lot of

799
00:40:54.159 --> 00:40:57.959
the, the, um, hoops that scientists jump through in

800
00:40:57.959 --> 00:41:03.580
creating controlled studies or using uh statistical techniques, uh,

801
00:41:03.600 --> 00:41:09.439
and, um, different, um, uh, techniques, uh, for conducting

802
00:41:09.439 --> 00:41:15.760
non-experimental studies are all developed to try to, um,

803
00:41:16.550 --> 00:41:19.629
Keep correlations from fooling us, right? To, to try

804
00:41:19.629 --> 00:41:23.030
to make it so that we don't infer causation

805
00:41:23.030 --> 00:41:25.669
mistakenly from correlations, because all sorts of things are

806
00:41:25.669 --> 00:41:28.310
correlated in our world, uh, getting, getting back to

807
00:41:28.310 --> 00:41:31.909
sort of the, the complex world, um, uh, that

808
00:41:31.909 --> 00:41:33.750
we live in, as I, as I pointed out

809
00:41:33.750 --> 00:41:34.300
earlier.

810
00:41:34.899 --> 00:41:38.679
Mhm. And so, how do we determine causation in

811
00:41:38.679 --> 00:41:39.590
science then?

812
00:41:40.290 --> 00:41:42.399
Yeah, so, so, so lots of different ways. This

813
00:41:42.399 --> 00:41:44.830
is, I think the same question is asking me,

814
00:41:44.959 --> 00:41:49.000
uh, sort of, um, uh, um, basically the same

815
00:41:49.000 --> 00:41:52.080
question is asking me sort of uh what experiments

816
00:41:52.080 --> 00:41:56.080
are in science, um. Uh, WHETHER there are multiple

817
00:41:56.080 --> 00:41:58.840
different scientific methods, etc. So much of that is

818
00:41:58.840 --> 00:42:04.030
focused on, um, trying to, uh, I guess it's,

819
00:42:04.360 --> 00:42:07.040
I'm overstating slightly, but, but so much of scientific

820
00:42:07.040 --> 00:42:11.639
methods are, um, trying to determine where there are

821
00:42:11.639 --> 00:42:16.350
causal relationships. Um. And so, um, variable control, right,

822
00:42:16.469 --> 00:42:20.270
intervention, um, in an experiment with control, with uh

823
00:42:20.270 --> 00:42:23.879
variable control, control of extraneous variables is one technique.

824
00:42:24.129 --> 00:42:27.750
Uh, STATISTICAL methods, um, to try to discern patterns

825
00:42:27.750 --> 00:42:31.709
across, um, variety, uh, and outcomes across a data

826
00:42:31.709 --> 00:42:36.899
set is another technique, um. Uh, CAREFUL, uh, uh,

827
00:42:36.909 --> 00:42:40.060
development of arguments, right, on the basis of, um,

828
00:42:40.070 --> 00:42:44.030
statistical reasoning from data, uh, is another part, uh,

829
00:42:44.050 --> 00:42:46.409
of a technique that's, that's quite important, uh, and

830
00:42:46.409 --> 00:42:47.169
the list goes on.

831
00:42:47.850 --> 00:42:50.560
Mhm. So let me ask you now a little

832
00:42:50.560 --> 00:42:53.959
bit about the explanation in science because there are

833
00:42:53.959 --> 00:42:55.879
different, or at least in the book you talk

834
00:42:55.879 --> 00:43:01.800
about different uh conceptions of explanation, including nomological pattern-based

835
00:43:01.800 --> 00:43:06.239
and causal conceptions of explanation. So, tell us about

836
00:43:06.239 --> 00:43:06.520
that.

837
00:43:06.979 --> 00:43:09.820
So this is a place um where the book,

838
00:43:09.979 --> 00:43:12.899
uh, our book becomes kind of more similar to

839
00:43:12.899 --> 00:43:15.340
what you see and more work in philosophy of

840
00:43:15.340 --> 00:43:18.439
science, right? So philosophers of science, including me, uh,

841
00:43:18.449 --> 00:43:22.580
love to argue about uh what successful scientific explanations

842
00:43:22.580 --> 00:43:25.860
look like. That is what features successful scientific explanations

843
00:43:25.860 --> 00:43:30.080
have. Um, AND, uh, at least some characterizations of

844
00:43:30.080 --> 00:43:35.199
that debate among philosophers of science identify, um, sort

845
00:43:35.199 --> 00:43:38.159
of as kind of core um positions, at least

846
00:43:38.159 --> 00:43:41.320
that have been held, held historically, uh, the philosophers

847
00:43:41.320 --> 00:43:45.229
who want to emphasize, uh, a deductive relationship, um,

848
00:43:45.469 --> 00:43:51.520
um, between, um, uh, an explanation and the phenomenon

849
00:43:51.520 --> 00:43:54.520
it explains, those who want to emphasize the importance

850
00:43:54.520 --> 00:43:57.770
of, um, Um, as, as we put it in

851
00:43:57.770 --> 00:44:02.129
the book, uh, sort of, um, uh, demonstrating patterns,

852
00:44:02.270 --> 00:44:06.209
right, or, or, or revealing patterns, um, uh, general

853
00:44:06.209 --> 00:44:09.570
patterns, uh, by providing an explanation that sort of

854
00:44:09.570 --> 00:44:12.840
bringing together multiple different kinds of phenomena, and then,

855
00:44:12.850 --> 00:44:16.770
um, Uh, more recently and, and, and really significantly

856
00:44:16.770 --> 00:44:18.570
in the field of philosophy, those who want to

857
00:44:18.570 --> 00:44:22.129
emphasize that explanations cite causes. And so the move

858
00:44:22.129 --> 00:44:25.399
that we make in recipes for Science is to

859
00:44:25.610 --> 00:44:29.120
sort of try to consider um what each of

860
00:44:29.120 --> 00:44:35.209
these philosophical views of explanation gets right, and then

861
00:44:35.209 --> 00:44:37.770
sort of What seemed to be the kind of

862
00:44:37.770 --> 00:44:40.889
downsides or shortcomings of each of these accounts. And

863
00:44:40.889 --> 00:44:43.050
so we're not sort of setting this up as

864
00:44:43.050 --> 00:44:45.889
a philosophical debate about what, what type of a

865
00:44:45.889 --> 00:44:48.689
kind of explanation is correct, but, but rather suggesting

866
00:44:48.689 --> 00:44:52.370
that there are resources um for thinking about explanatory

867
00:44:52.370 --> 00:44:54.889
reasoning and science from, from each of these uh

868
00:44:54.889 --> 00:44:57.570
philosophical views about scientific explanation.

869
00:44:58.709 --> 00:45:01.800
So earlier we talked a little bit about the

870
00:45:01.800 --> 00:45:04.479
limits of science, but now I, I want to

871
00:45:04.479 --> 00:45:09.399
ask you a more specific or uh question. What,

872
00:45:09.520 --> 00:45:13.439
what are the limitations of explanation in science?

873
00:45:14.820 --> 00:45:17.300
Um, Can you say a little bit more about

874
00:45:17.300 --> 00:45:17.830
what you mean?

875
00:45:18.770 --> 00:45:22.510
Uh, I mean, when we're trying to explain something

876
00:45:22.510 --> 00:45:27.179
in science, uh, what can be the limitations of

877
00:45:27.469 --> 00:45:31.310
doing that through scientific, uh, through the scientific method

878
00:45:31.310 --> 00:45:33.949
or the scientific methods.

879
00:45:34.750 --> 00:45:36.419
Yeah, all right, thanks for saying a little bit

880
00:45:36.419 --> 00:45:37.870
more. I needed a little bit more to kind

881
00:45:37.870 --> 00:45:40.489
of motivate my, my instincts on how I wanted

882
00:45:40.489 --> 00:45:45.139
to answer. Um, um, I, I, I don't know

883
00:45:45.139 --> 00:45:48.459
that I have anything general to say here. Um,

884
00:45:48.479 --> 00:45:51.679
AND I don't know that there is something that

885
00:45:51.679 --> 00:45:54.560
can, can be said on the front end about

886
00:45:54.560 --> 00:45:59.429
sort of, uh, where science needs to end, right?

887
00:45:59.500 --> 00:46:01.639
Or something like that. Um, BUT I do think

888
00:46:01.639 --> 00:46:05.489
at least one place to start to look, um,

889
00:46:05.600 --> 00:46:08.139
to, to get some instinct for Where that line

890
00:46:08.139 --> 00:46:12.820
might be is in, um, this connection that we

891
00:46:12.820 --> 00:46:16.780
made, uh, or that I made between, um, scientific

892
00:46:16.780 --> 00:46:21.340
knowledge and, um, sort of, uh, uh, an, a

893
00:46:21.340 --> 00:46:26.520
basis ultimately in, um, empirical information about our world.

894
00:46:26.820 --> 00:46:29.939
Um, AND so there, when we get sort of

895
00:46:29.939 --> 00:46:35.270
distant enough from Uh, any basis in empirical evidence,

896
00:46:35.399 --> 00:46:38.909
um, is where it starts to get unclear, um,

897
00:46:39.520 --> 00:46:42.000
whether we're still in a place that we can

898
00:46:42.000 --> 00:46:44.280
sort of generate properly scientific knowledge.

899
00:46:46.370 --> 00:46:48.870
So let us talk now a little bit about

900
00:46:48.870 --> 00:46:53.590
scientific breakthroughs and revolution. So what counts as a

901
00:46:53.590 --> 00:46:59.120
scientific breakthrough because we hear that uh concept or

902
00:46:59.120 --> 00:47:01.760
that term a lot, what does it mean?

903
00:47:01.989 --> 00:47:03.709
Yeah, good. So, so maybe I just want to

904
00:47:03.709 --> 00:47:07.379
say that scientific breakthroughs are when Um, some major

905
00:47:07.379 --> 00:47:11.169
advance, um, has occurred, and, and often this means,

906
00:47:11.250 --> 00:47:12.889
uh, in a way that we couldn't have predicted,

907
00:47:13.000 --> 00:47:16.090
right? So, so the Higgs boson discovery I mentioned

908
00:47:16.090 --> 00:47:17.969
earlier and we use that example in, in the

909
00:47:17.969 --> 00:47:21.209
book, um, this was a breakthrough because, right, it

910
00:47:21.209 --> 00:47:22.929
could, the data could have, could have turned out

911
00:47:22.929 --> 00:47:26.560
otherwise, um, but, but scientists, uh, Uh, you know,

912
00:47:26.699 --> 00:47:31.100
the, the Large Hadron Collider, um, got data that

913
00:47:31.100 --> 00:47:35.050
confirmed that the, um, existence of a new fundamental

914
00:47:35.419 --> 00:47:38.979
particle that had been conjectured, conjectured. Uh, SO there's

915
00:47:38.979 --> 00:47:41.020
a breakthrough in what we take to be true

916
00:47:41.020 --> 00:47:43.649
about the world, uh, in, in that base, uh,

917
00:47:43.659 --> 00:47:45.219
sort of in that kind of occasion.

918
00:47:46.100 --> 00:47:51.459
Mhm. And this change in science occur in revolutions

919
00:47:51.459 --> 00:47:55.149
or is it mostly non-revolutionary? Good.

920
00:47:55.379 --> 00:47:57.409
Yeah, so, so we do, we talk about, um,

921
00:47:57.540 --> 00:48:00.810
you know, Thomas Koon's really famous work on um

922
00:48:00.810 --> 00:48:05.209
theory change and specifically this idea that Um, if

923
00:48:05.209 --> 00:48:07.250
we look at the history of science, we don't

924
00:48:07.250 --> 00:48:10.449
just see cumulative progress and gaining more and more

925
00:48:10.449 --> 00:48:12.689
sort of knowledge about our world, but we see,

926
00:48:13.100 --> 00:48:15.850
uh, as you say, scientific revolutions. We see, according

927
00:48:15.850 --> 00:48:19.489
to Kuhn, major changes in what scientists take to

928
00:48:19.489 --> 00:48:23.629
be fundamental to the world, um. And Coon really

929
00:48:23.629 --> 00:48:27.580
emphasizes that um science can have this character and

930
00:48:27.580 --> 00:48:32.300
that there's a way in which that threatens cumulative

931
00:48:32.300 --> 00:48:34.530
progress and kind of this simple picture of of

932
00:48:34.530 --> 00:48:38.889
scientific advances. Um, SO you're asking, right, does most

933
00:48:38.889 --> 00:48:42.850
scientific change Look like that. Um, uh, I think

934
00:48:42.850 --> 00:48:45.489
the answer to that quite clearly and, and lots

935
00:48:45.489 --> 00:48:47.649
of, uh, philosopher of science have said this in

936
00:48:47.649 --> 00:48:49.929
response to a Konian view. No, that lots of

937
00:48:49.929 --> 00:48:53.800
scientific change looks like the more standard cumulative progress.

938
00:48:53.969 --> 00:48:57.969
Um, EVEN Kuon probably is OK with that. There

939
00:48:57.969 --> 00:49:01.330
is a question of sort of um to what

940
00:49:01.330 --> 00:49:08.129
extent um Kuon uh Kunian scientific revolutions happen across

941
00:49:08.129 --> 00:49:10.729
science and continue to happen, or whether he sort

942
00:49:10.729 --> 00:49:14.850
of picked on uh found particular instances of scientific

943
00:49:14.850 --> 00:49:17.610
change that have this feature, and science can have

944
00:49:17.610 --> 00:49:21.409
this feature, whereas, uh, often it doesn't happen that

945
00:49:21.409 --> 00:49:23.629
way. Um, AND so that's maybe where I would

946
00:49:23.629 --> 00:49:25.229
land is I would want to say, I think

947
00:49:25.229 --> 00:49:29.510
it's interesting and challenging and worthwhile to focus on.

948
00:49:29.989 --> 00:49:33.550
These periods of, of theory change that include a

949
00:49:33.550 --> 00:49:37.510
kind of radical rethinking of, of what's fundamentally true

950
00:49:37.510 --> 00:49:40.550
about our world, um, but then also to appreciate

951
00:49:40.550 --> 00:49:44.709
that those are really exceptions, um, and that historically

952
00:49:44.709 --> 00:49:47.070
there are just lots of instances of, of pretty

953
00:49:47.070 --> 00:49:50.909
direct cumulative change and progress in science. And then

954
00:49:50.909 --> 00:49:53.939
of course there are interesting philosophical questions to ask

955
00:49:53.939 --> 00:49:58.000
about the sort of Radical theory change, um, periods

956
00:49:58.000 --> 00:50:00.270
of science, even if these are really unusual, right?

957
00:50:00.370 --> 00:50:02.669
Is there any any way to talk about ways

958
00:50:02.669 --> 00:50:07.060
in which uh scientific progress has occurred even with

959
00:50:07.060 --> 00:50:09.580
that kind of radical change? Um, THESE are really

960
00:50:09.580 --> 00:50:13.149
interesting philosophical questions. Um, WHAT we do in that

961
00:50:13.149 --> 00:50:15.949
book really is, is, um, sort of leave those

962
00:50:15.949 --> 00:50:19.189
open, but, but our focus, um, you know, for

963
00:50:19.189 --> 00:50:22.510
sort of a, a broad undergraduate students, um, population

964
00:50:22.510 --> 00:50:24.870
that we're imagining is. We, as we wrote the

965
00:50:24.870 --> 00:50:28.629
book, is we emphasize the ways in which scientific

966
00:50:28.629 --> 00:50:33.510
knowledge is trustworthy, even if it's possible, still in

967
00:50:33.510 --> 00:50:35.590
the future that we might have this kind of

968
00:50:35.590 --> 00:50:38.310
uh radical scientific change, um, because I think that's

969
00:50:38.310 --> 00:50:40.510
an argument that that can be made, right? That,

970
00:50:40.629 --> 00:50:43.620
that we can know that that scientific knowledge, uh,

971
00:50:43.629 --> 00:50:46.469
as we have it today is uh sort of

972
00:50:46.469 --> 00:50:49.909
trustworthy, um, even if, uh, this kind of possibility

973
00:50:49.909 --> 00:50:51.300
of radical change is raised.

974
00:50:51.909 --> 00:50:56.389
Mhm. So there's also this very common idea among

975
00:50:56.729 --> 00:51:02.090
some science enthusiasts that are probably not very philosophically

976
00:51:02.090 --> 00:51:07.810
sophisticated when it comes to uh science where they

977
00:51:07.810 --> 00:51:12.610
say that science is an institution that, that is

978
00:51:12.610 --> 00:51:17.479
sort of impermeable to outside influences like for example,

979
00:51:17.570 --> 00:51:21.530
the social and historical context. Is that really the

980
00:51:21.530 --> 00:51:21.959
case?

981
00:51:22.439 --> 00:51:25.280
Absolutely not. I do have strong opinions on this

982
00:51:25.280 --> 00:51:28.320
one. So scientists are people, right? Um, SCIENTISTS bring

983
00:51:28.320 --> 00:51:29.919
to their work like the rest of us, kind

984
00:51:29.919 --> 00:51:32.600
of background ideas about how the world is, things

985
00:51:32.600 --> 00:51:34.879
that they're interested in, things that they're not interested

986
00:51:34.879 --> 00:51:37.909
in, and all of that provides a way for

987
00:51:38.199 --> 00:51:43.120
scientific projects to reflect the the going concerns uh

988
00:51:43.120 --> 00:51:45.659
at a certain time in history, in a particular

989
00:51:45.659 --> 00:51:49.120
community, etc. Um, YOU also get something you know

990
00:51:49.120 --> 00:51:51.810
I haven't talked about that much, um. Yet in

991
00:51:51.810 --> 00:51:56.489
this conversation, you also get um uh in with

992
00:51:56.489 --> 00:51:59.739
science, um, and important to scientific methods as well,

993
00:51:59.929 --> 00:52:04.129
a sort of um robust community uh with norms

994
00:52:04.129 --> 00:52:09.840
around. How exchanges happen, um, ways in which you

995
00:52:09.840 --> 00:52:11.919
need to be sort of open in your work

996
00:52:11.919 --> 00:52:15.780
to uh external critique from other scientists, etc. Um,

997
00:52:15.840 --> 00:52:20.840
SO, even as, um, scientists values, I think influence

998
00:52:20.840 --> 00:52:23.239
the kind of things that they work on. Um,

999
00:52:23.270 --> 00:52:26.139
AND the kind of techniques they use, etc. um,

1000
00:52:26.429 --> 00:52:29.310
THE, the role that those values play and how

1001
00:52:29.310 --> 00:52:31.590
those values influence the science is also sort of

1002
00:52:31.590 --> 00:52:34.149
subject to critique, uh, by one's peers in a

1003
00:52:34.149 --> 00:52:37.070
way that, uh, to some extent weeds out, uh,

1004
00:52:37.149 --> 00:52:39.510
at least some kinds of influences that that those

1005
00:52:39.510 --> 00:52:40.379
values can have.

1006
00:52:41.250 --> 00:52:44.560
Mhm. So tell us more about that bit that

1007
00:52:44.560 --> 00:52:47.350
you just mentioned. I mean, how important is it

1008
00:52:47.350 --> 00:52:50.379
in science for, for us to have sort of

1009
00:52:50.379 --> 00:52:55.820
um Let's say, uh, a cognitively diverse population of

1010
00:52:55.820 --> 00:53:01.729
scientists to uh critique each other, each other's work.

1011
00:53:02.229 --> 00:53:04.469
Um, YEAH, very important, and this is, this is

1012
00:53:04.469 --> 00:53:07.550
an idea that's gains kind of broader attraction, not

1013
00:53:07.550 --> 00:53:10.270
just in philosophy of science, but among scientists and

1014
00:53:10.510 --> 00:53:13.379
kind of broader discourse about science as well, um,

1015
00:53:13.389 --> 00:53:17.250
over the last several decades. Um, HAVING a variety

1016
00:53:17.250 --> 00:53:20.324
of, of scientists with different backgrounds. Grounds and different

1017
00:53:20.324 --> 00:53:24.004
sort of um antecedents, right, prior beliefs about the

1018
00:53:24.004 --> 00:53:27.564
world, um, is incredibly useful in making sure that

1019
00:53:27.844 --> 00:53:30.354
uh the kind of questions and challenges that should

1020
00:53:30.354 --> 00:53:32.524
be raised have been raised, right? If we have

1021
00:53:32.524 --> 00:53:36.284
lots of different perspectives um coming into to an

1022
00:53:36.284 --> 00:53:40.399
investigation, um. Uh, YEAH, and then, and then I

1023
00:53:40.399 --> 00:53:42.280
think one of, one of the ways that that

1024
00:53:42.280 --> 00:53:44.000
this can play a role in science that I've

1025
00:53:44.000 --> 00:53:46.709
emphasized in some of my other work is, um,

1026
00:53:47.000 --> 00:53:49.320
uh, one of the, the starting points that I

1027
00:53:49.320 --> 00:53:54.639
gave for where, um, values and personality traits and

1028
00:53:54.639 --> 00:53:57.320
sort of social identities can influence science is just

1029
00:53:57.320 --> 00:53:59.510
in what you want to study. And that sounds

1030
00:53:59.510 --> 00:54:01.590
so boring and obvious, right? So I'm interested in

1031
00:54:01.590 --> 00:54:04.870
biology for this reason, or, um, right, I want

1032
00:54:04.870 --> 00:54:07.030
to study cancer because some of my family has

1033
00:54:07.030 --> 00:54:10.110
been uh affected by cancer, etc. Um, THESE kinds

1034
00:54:10.110 --> 00:54:13.780
of mundane ways in which um scientists' attention are

1035
00:54:13.780 --> 00:54:17.260
directed in 11 place or another, I think actually.

1036
00:54:17.840 --> 00:54:23.250
Um, INFLUENCE in really subtle ways, features of the

1037
00:54:23.250 --> 00:54:28.479
research that's carried out, um, such that, um, uh,

1038
00:54:28.489 --> 00:54:30.879
the kinds of knowledge we have about the world,

1039
00:54:30.969 --> 00:54:32.729
right? Maybe this is a simple example, back to

1040
00:54:32.729 --> 00:54:35.879
the cancer example. If, um, if we have, uh,

1041
00:54:35.889 --> 00:54:39.709
scientists motivated to study lots of different kinds of

1042
00:54:39.709 --> 00:54:44.360
cancer, right? Uh, THEN we will, um, uh, generate,

1043
00:54:44.530 --> 00:54:48.989
uh, as a scientific establishment, uh, um. Um, I,

1044
00:54:49.000 --> 00:54:53.399
um, biomedical establishment, lots of different knowledge about different

1045
00:54:53.399 --> 00:54:56.350
types of cancer versus if we have scientists who,

1046
00:54:56.399 --> 00:54:59.760
who, um, are mainly focused on the most prevalent

1047
00:54:59.760 --> 00:55:02.080
forms of cancer, then we'll then we'll miss out

1048
00:55:02.080 --> 00:55:04.000
on a lot of that. Um, SO even if

1049
00:55:04.000 --> 00:55:06.600
this is sort of a simple straightforward way in

1050
00:55:06.600 --> 00:55:09.320
which um values can influence science, I think it

1051
00:55:09.320 --> 00:55:14.239
ends up sort of, um, Having implications for the

1052
00:55:14.239 --> 00:55:16.800
type of scientific knowledge that is amassed in a

1053
00:55:16.800 --> 00:55:18.550
way that ends up being really important.

1054
00:55:19.629 --> 00:55:27.050
Mhm. Is exclusion and marginalization based on social categories

1055
00:55:27.050 --> 00:55:31.719
like race, ethnicity, nationality, gender, and so on still

1056
00:55:31.719 --> 00:55:33.189
a thing in science?

1057
00:55:33.889 --> 00:55:36.290
Alas, it seems like it is, yeah, um, right,

1058
00:55:36.370 --> 00:55:39.439
so of course, um, a lot of science, um,

1059
00:55:39.689 --> 00:55:41.959
uh, and a lot of funding for science, um,

1060
00:55:42.010 --> 00:55:44.689
happened in some nations versus others, so it's, it's

1061
00:55:44.689 --> 00:55:47.969
easier to become a scient scientist and participate in

1062
00:55:47.969 --> 00:55:50.649
science if uh you have some citizenship in the

1063
00:55:50.649 --> 00:55:54.800
world versus others, um, and there's still, uh, disparities

1064
00:55:54.800 --> 00:55:58.915
in, um, the, uh, social. Identities of folks who

1065
00:55:58.915 --> 00:56:03.034
um are participating in science. There's still, you know,

1066
00:56:03.364 --> 00:56:06.685
sort of um gaps in citation rates, uh, and

1067
00:56:06.685 --> 00:56:09.165
grant uh famously sort of got a lot of

1068
00:56:09.165 --> 00:56:12.135
attention the last few years, sort of grant success

1069
00:56:12.604 --> 00:56:15.264
of scientists with different identities, and I'm sure it's,

1070
00:56:15.284 --> 00:56:17.554
you know, very complex as to why that's so,

1071
00:56:17.564 --> 00:56:20.554
but yes, this is a continuing challenge in science.

1072
00:56:21.449 --> 00:56:25.090
And uh how should we approach that issue? I

1073
00:56:25.090 --> 00:56:27.540
mean, do you think that we would need more

1074
00:56:27.889 --> 00:56:31.560
uh DEI programs or something like that?

1075
00:56:32.310 --> 00:56:35.669
Uh, YEAH, uh, to some, to some extent, this

1076
00:56:35.669 --> 00:56:38.189
is beyond my job, right? This is a question

1077
00:56:38.189 --> 00:56:41.229
for someone who does science policy. Um, I think.

1078
00:56:42.179 --> 00:56:45.290
Um, THE part that I'm comfortable thinking about is,

1079
00:56:45.310 --> 00:56:49.100
uh, the ways in which, um, um, social identities

1080
00:56:49.100 --> 00:56:51.419
can influence the kind of, or let me say

1081
00:56:51.419 --> 00:56:54.899
more broadly, the ways in which, um, having diverse

1082
00:56:54.899 --> 00:56:58.060
social identities uh in science is valuable for the

1083
00:56:58.060 --> 00:57:00.739
scientific enterprise, makes it so that science is better

1084
00:57:00.739 --> 00:57:04.580
at gaining knowledge, gains more trustworthy knowledge, and is

1085
00:57:04.580 --> 00:57:07.500
sort of improved among among across other dimensions as

1086
00:57:07.500 --> 00:57:11.260
well. Um. Yeah, how we get there I think

1087
00:57:11.260 --> 00:57:13.570
is a is a thorny set of questions and

1088
00:57:13.580 --> 00:57:17.469
and will certainly depend on sort of particular um

1089
00:57:17.469 --> 00:57:20.350
political context uh as well as sort of um

1090
00:57:20.350 --> 00:57:21.810
facts on the ground about science.

1091
00:57:22.939 --> 00:57:25.659
OK, so I have one last topic that I

1092
00:57:25.659 --> 00:57:28.860
would like to ask you about. Earlier, you mentioned

1093
00:57:28.860 --> 00:57:33.419
how science is not really value-free and the values

1094
00:57:33.419 --> 00:57:36.010
of scientists play a role in how they produce

1095
00:57:36.010 --> 00:57:41.379
scientific knowledge. Can science really ever be value-free?

1096
00:57:42.610 --> 00:57:45.659
Um, WELL, I think, I think it's important to,

1097
00:57:45.770 --> 00:57:48.260
to follow up with a, a question back to

1098
00:57:48.260 --> 00:57:49.780
you, but what do you, what do you mean

1099
00:57:49.780 --> 00:57:51.969
by can it really be value free?

1100
00:57:52.969 --> 00:57:57.310
Uh, I mean, I, I, ideally, I guess the

1101
00:57:57.310 --> 00:58:02.709
values brought to the table by scientific practitioners would

1102
00:58:02.709 --> 00:58:06.350
not play a role at all in their production

1103
00:58:06.350 --> 00:58:09.985
of scientific knowledge, I guess. Yeah, thank

1104
00:58:09.985 --> 00:58:12.854
you. Um, uh, SO in that sense, I think

1105
00:58:12.854 --> 00:58:15.445
no, um, because of what I said before, I

1106
00:58:15.445 --> 00:58:18.925
think, I think the kind of scientific knowledge that

1107
00:58:18.925 --> 00:58:25.169
we amass will always be influenced by Our values,

1108
00:58:25.179 --> 00:58:29.820
um, and the especially the values of the scientists

1109
00:58:30.070 --> 00:58:33.239
investigating our world. Um, NOW it is the case

1110
00:58:33.239 --> 00:58:36.350
if we have scientists with with lots of different

1111
00:58:36.350 --> 00:58:39.189
values and who challenge each other's values and look

1112
00:58:39.189 --> 00:58:42.709
for for in a phenomenon that uh other scientists

1113
00:58:42.709 --> 00:58:46.030
haven't identified to study, etc. THAT to some extent.

1114
00:58:46.810 --> 00:58:50.429
That this kind of mitigates the the downside to

1115
00:58:50.429 --> 00:58:53.320
that, right? Then we have lots of different people

1116
00:58:53.530 --> 00:58:57.090
looking for different kinds of scientific knowledge or doing

1117
00:58:57.090 --> 00:58:59.610
different kinds of scientific work uh to develop different

1118
00:58:59.610 --> 00:59:02.689
kinds of knowledge. Um, BUT that project will always,

1119
00:59:02.810 --> 00:59:06.679
I think, uh, and essentially be based in, um,

1120
00:59:06.689 --> 00:59:11.889
what scientists as individuals and then scientists as a

1121
00:59:11.889 --> 00:59:15.370
collective body, um, are prioritizing in a in a

1122
00:59:15.370 --> 00:59:19.290
way that You know, yeah, we, we, uh, uh,

1123
00:59:19.300 --> 00:59:21.459
we'll we'll find its way into what kinds of

1124
00:59:21.459 --> 00:59:22.699
knowledge we amass.

1125
00:59:23.310 --> 00:59:27.699
Mhm. So one last question then, if science cannot

1126
00:59:27.699 --> 00:59:31.620
be value-free, is that problematic in any way?

1127
00:59:32.520 --> 00:59:34.729
Uh, I don't think so. Yeah, so, so again,

1128
00:59:34.879 --> 00:59:36.840
kind of another work that I've done, I've, I've

1129
00:59:36.840 --> 00:59:39.520
emphasized that I think to make sense of the

1130
00:59:39.520 --> 00:59:42.969
features of science, we should see it as a

1131
00:59:42.969 --> 00:59:46.560
tool that humans have developed to serve our purposes.

1132
00:59:46.570 --> 00:59:48.719
And that's a way in which ultimately when we

1133
00:59:48.719 --> 00:59:54.540
zoom. Really far out, um, fundamentally, science is, um,

1134
00:59:54.669 --> 00:59:58.780
uh, a, um, set of methods and a community

1135
00:59:58.780 --> 01:00:01.070
and a set of practices for, for gaining knowledge

1136
01:00:01.070 --> 01:00:04.060
about the world that are, that are linked to

1137
01:00:04.270 --> 01:00:07.739
sort of embedded in. Uh, THE questions we humans,

1138
01:00:07.939 --> 01:00:10.100
uh, in particular humans, right, who have happened to

1139
01:00:10.100 --> 01:00:12.739
be scientists have about the world. Um, SO I

1140
01:00:12.739 --> 01:00:15.199
just think that's inherent to what science is. Um,

1141
01:00:15.219 --> 01:00:18.300
IT is, it is ultimately perspectival. It happens from

1142
01:00:18.300 --> 01:00:23.699
our distinctively, um, uh, human perspectives, uh, and, and

1143
01:00:23.699 --> 01:00:26.139
to support our distinctively human aims.

1144
01:00:26.820 --> 01:00:30.979
Mhm. Great. So, the book is again recipes for

1145
01:00:30.979 --> 01:00:34.899
science and introduction to scientific methods and reasoning. And

1146
01:00:34.899 --> 01:00:36.780
of course, I'm leaving a link to it in

1147
01:00:36.780 --> 01:00:40.860
the description of the interview. And Doctor Potosnik, just

1148
01:00:40.860 --> 01:00:43.260
before we go, apart from the book, would you

1149
01:00:43.260 --> 01:00:45.699
like to tell people where they can find you

1150
01:00:45.699 --> 01:00:47.459
and your work on the internet?

1151
01:00:48.209 --> 01:00:51.250
Sure. Um, SO I do have a website. Um,

1152
01:00:51.270 --> 01:00:56.310
IT'S just my full name, Angela Potocnikwithout apace.com, um,

1153
01:00:56.379 --> 01:00:59.389
and so you can get an overview of my,

1154
01:00:59.739 --> 01:01:01.830
uh, articles as well as the other books that

1155
01:01:01.830 --> 01:01:04.429
I've written, um, and then some, some like sort

1156
01:01:04.429 --> 01:01:08.159
of, um, online present stuff like this interview there,

1157
01:01:08.550 --> 01:01:12.590
um. Uh, AND yeah, besides recipes for science, um,

1158
01:01:12.760 --> 01:01:16.110
which I've co-authored, um, I have a book, Idealization

1159
01:01:16.110 --> 01:01:18.360
and the aims of Science, uh, that was published

1160
01:01:18.360 --> 01:01:21.520
in 2017, um, and a more recent short book

1161
01:01:21.520 --> 01:01:24.600
Science and the Public, um, uh, which came out

1162
01:01:24.600 --> 01:01:27.250
about a year ago. Um, YEAH, I don't know,

1163
01:01:27.280 --> 01:01:28.959
that's a start. It's a couple of things I

1164
01:01:28.959 --> 01:01:29.510
can say.

1165
01:01:29.989 --> 01:01:32.330
Yeah, great. I will be leaving some links to

1166
01:01:32.330 --> 01:01:34.560
that in the description of the interview as well,

1167
01:01:34.570 --> 01:01:37.090
and thank you so much for taking the time

1168
01:01:37.090 --> 01:01:39.120
to come on the show. It's been a very

1169
01:01:39.330 --> 01:01:40.889
informative conversation.

1170
01:01:41.229 --> 01:01:43.250
Thank you, Ricardo. Yeah, this has been fun. I

1171
01:01:43.250 --> 01:01:43.610
appreciate it.

1172
01:01:44.929 --> 01:01:47.449
Hi guys, thank you for watching this interview until

1173
01:01:47.449 --> 01:01:49.590
the end. If you liked it, please share it,

1174
01:01:49.770 --> 01:01:52.560
leave a like and hit the subscription button. The

1175
01:01:52.560 --> 01:01:54.760
show is brought to you by Nights Learning and

1176
01:01:54.760 --> 01:01:58.840
Development done differently, check their website at Nights.com and

1177
01:01:58.840 --> 01:02:02.560
also please consider supporting the show on Patreon or

1178
01:02:02.560 --> 01:02:05.040
PayPal. I would also like to give a huge

1179
01:02:05.040 --> 01:02:08.149
thank you to my main patrons and PayPal supporters

1180
01:02:08.149 --> 01:02:12.399
Perergo Larsson, Jerry Mullerns, Frederick Sundo, Bernard Seyche Olaf,

1181
01:02:12.479 --> 01:02:15.729
Alex Adam Castle, Matthew Whitting Barno, Wolf, Tim Hollis,

1182
01:02:15.860 --> 01:02:19.149
Erika Lenny, John Connors, Philip Fors Connolly. Then the

1183
01:02:19.149 --> 01:02:22.949
Mari Robert Windegaruyasi Zup Mark Nes calling in Holbrookfield

1184
01:02:22.949 --> 01:02:27.739
governor Michael Stormir Samuel Andrea, Francis Forti Agnseroro and

1185
01:02:27.739 --> 01:02:32.070
Hal Herzognun Macha Joan Lays and the Samuel Corriere,

1186
01:02:32.229 --> 01:02:35.899
Heinz, Mark Smith, Jore, Tom Hummel, Sardus France David

1187
01:02:35.899 --> 01:02:40.500
Sloan Wilson, Asila dearraujoro and Roach Diego Londonorea. Yannick

1188
01:02:40.500 --> 01:02:46.500
Punteran Rosmani Charlotte blinikol Barbara Adamhn Pavlostaevskynalebaa medicine, Gary

1189
01:02:46.500 --> 01:02:51.459
Galman Samov Zaledrianei Poltonin John Barboza, Julian Price, Edward

1190
01:02:51.459 --> 01:02:56.330
Hall Edin Bronner, Douglas Fry, Franca Bartolotti Gabrielon Scorteus

1191
01:02:56.330 --> 01:03:00.479
Slelitsky, Scott Zachary Fish Tim Duffyani Smith John Wieman.

1192
01:03:00.820 --> 01:03:05.370
Daniel Friedman, William Buckner, Paul Georgianneau, Luke Lovai Giorgio

1193
01:03:05.370 --> 01:03:10.070
Theophanous, Chris Williamson, Peter Vozin, David Williams, the Augusta,

1194
01:03:10.179 --> 01:03:14.409
Anton Eriksson, Charles Murray, Alex Shaw, Marie Martinez, Coralli

1195
01:03:14.409 --> 01:03:18.780
Chevalier, bungalow atheists, Larry D. Lee Junior, Old Eringbo.

1196
01:03:19.530 --> 01:03:23.580
Sterry Michael Bailey, then Sperber, Robert Grassy Zigoren, Jeff

1197
01:03:23.580 --> 01:03:28.129
McMahon, Jake Zu, Barnabas radix, Mark Campbell, Thomas Dovner,

1198
01:03:28.250 --> 01:03:32.649
Luke Neeson, Chris Stor, Kimberly Johnson, Benjamin Galbert, Jessica

1199
01:03:32.649 --> 01:03:38.330
Nowicki, Linda Brandon, Nicholas Carlsson, Ismael Bensleyman. George Eoriatis,

1200
01:03:38.370 --> 01:03:44.159
Valentin Steinman, Perkrolis, Kate van Goller, Alexander Aubert, Liam

1201
01:03:44.429 --> 01:03:50.010
Dunaway, BR Masoud Ali Mohammadi, Perpendicular John Nertner, Ursula

1202
01:03:50.010 --> 01:03:54.919
Gudinov, Gregory Hastings, David Pinsoff Sean Nelson, Mike Levine,

1203
01:03:55.169 --> 01:03:58.570
and Jos Net. A special thanks to my producers.

1204
01:03:58.580 --> 01:04:01.330
These are Webb, Jim, Frank Lucas Steffinik, Tom Venneden,

1205
01:04:01.429 --> 01:04:05.949
Bernard Curtis Dixon, Benedic Muller, Thomas Trumbull, Catherine and

1206
01:04:05.949 --> 01:04:09.189
Patrick Tobin, Gian Carlo Montenegroal Ni Cortiz and Nick

1207
01:04:09.189 --> 01:04:12.709
Golden, and to my executive producers Matthew Levender, Sergio

1208
01:04:12.709 --> 01:04:15.939
Quadrian, Bogdan Kanivets, and Rosie. Thank you for all.

