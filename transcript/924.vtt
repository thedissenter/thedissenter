WEBVTT

1
00:00:00.750 --> 00:00:03.690
Hello, everybody. Welcome to a new episode of the

2
00:00:03.750 --> 00:00:06.630
Decent. I'm your host as always Ricardo Loops. And

3
00:00:06.639 --> 00:00:09.689
today I'm joined by Doctor Stephanie. Her, she is

4
00:00:09.699 --> 00:00:14.010
a researcher, broadcaster and author focused on technology, politics

5
00:00:14.020 --> 00:00:16.729
and history. And today we're going to talk about

6
00:00:16.739 --> 00:00:20.209
her book Technology is Not Neutral, a short guide

7
00:00:20.219 --> 00:00:23.959
to technology ethics. So doctor her, welcome to the

8
00:00:23.969 --> 00:00:25.790
show. It's a pleasure to everyone.

9
00:00:26.100 --> 00:00:28.340
Thank you so much for having me or Gala.

10
00:00:30.139 --> 00:00:35.580
Great. So um uh tech uh technology ethics, I

11
00:00:35.590 --> 00:00:39.979
guess that uh people who think about is who

12
00:00:39.990 --> 00:00:43.169
look at these would think that OK, it's just

13
00:00:43.180 --> 00:00:47.819
another uh philosophy thing. Why should we care about

14
00:00:47.830 --> 00:00:51.029
that? It's just some about some abstract questions. But

15
00:00:51.040 --> 00:00:54.090
I mean, what is it really about? And what

16
00:00:54.099 --> 00:00:58.750
kinds of uh more practical questions, let's say, does

17
00:00:58.759 --> 00:00:59.520
it deal with?

18
00:01:00.009 --> 00:01:02.299
I love, I love your idea of like one

19
00:01:02.310 --> 00:01:05.459
more philosophy is if we're being bombarded by philosophies

20
00:01:05.470 --> 00:01:07.650
and all the time, and there's just philosophers walking

21
00:01:07.660 --> 00:01:11.480
around selling their wares in the street, which I

22
00:01:11.489 --> 00:01:13.279
guess is maybe true, we would just call them

23
00:01:13.290 --> 00:01:18.230
marketing people now. Uh No. So I think, look,

24
00:01:19.260 --> 00:01:23.339
I think technology and the way that humans have

25
00:01:23.349 --> 00:01:28.209
a relationship with technology has existed probably since we,

26
00:01:28.220 --> 00:01:31.550
you know, developed depos, thumbs and started making tools.

27
00:01:31.559 --> 00:01:34.190
Um, YOU know, so we would have picked up

28
00:01:34.199 --> 00:01:37.949
bones or stones or twigs and started fashioning them

29
00:01:38.239 --> 00:01:41.660
creating fire. And probably from that moment you started

30
00:01:41.669 --> 00:01:43.980
having human beings disagreeing about, you know, when is

31
00:01:43.989 --> 00:01:45.599
it acceptable to make a fire? What are the

32
00:01:45.610 --> 00:01:48.580
rules around fire? Is fire for cooking and keeping

33
00:01:48.589 --> 00:01:50.639
us warm and keeping predators away or is it

34
00:01:50.650 --> 00:01:53.739
ok to like torch our enemy camps village? Um,

35
00:01:53.750 --> 00:01:55.959
OR use it, you know, launch it into an

36
00:01:55.970 --> 00:01:58.040
arrow and shoot it at people. So I just

37
00:01:58.050 --> 00:02:00.980
feel like in some ways it's like nothing new

38
00:02:00.989 --> 00:02:03.860
under the sun, as Shakespeare said, it's, it's always

39
00:02:03.870 --> 00:02:05.500
been there. So I don't feel like this is

40
00:02:05.510 --> 00:02:10.339
like a new idea, um that people are hawking.

41
00:02:10.350 --> 00:02:13.580
I think it's, it's one of the oldest things

42
00:02:13.589 --> 00:02:17.220
because it's so fundamental to us. Beings have been

43
00:02:17.229 --> 00:02:19.839
making technology, you know, for a really long time.

44
00:02:19.850 --> 00:02:21.949
And we've also been philosophizing for a really long

45
00:02:21.960 --> 00:02:24.460
time because if we think about philosophy, kind of

46
00:02:24.470 --> 00:02:28.300
the way it's taught today, it's very abstract. We

47
00:02:28.309 --> 00:02:31.020
think about it in universities, uh you know, philosophy

48
00:02:31.029 --> 00:02:33.289
departments writing about topics that most of us probably

49
00:02:33.300 --> 00:02:35.080
are never going to read a book about, uh

50
00:02:35.089 --> 00:02:37.679
or an article or really care, which is a

51
00:02:37.690 --> 00:02:41.100
shame because we're actually doing philosophy all the time.

52
00:02:41.619 --> 00:02:44.589
We're doing it every day. So if you're interested

53
00:02:44.600 --> 00:02:48.309
in, in power and in politics that welcome to

54
00:02:48.320 --> 00:02:51.410
philosophy, you're doing political philosophy. If you're interested in

55
00:02:51.419 --> 00:02:54.229
like good and bad, right and wrong, um where

56
00:02:54.240 --> 00:02:56.259
do we draw the line on certain things? Welcome

57
00:02:56.270 --> 00:02:58.619
to philosophy. You're doing ethics. If you have really

58
00:02:58.630 --> 00:03:03.589
strong views on aesthetics, which could be anything from,

59
00:03:04.130 --> 00:03:07.199
you know, design in your house to like the

60
00:03:07.210 --> 00:03:10.770
sustainability or labor relations that go into the materials

61
00:03:10.779 --> 00:03:13.419
that you buy, any product that you buy or

62
00:03:13.429 --> 00:03:15.809
service that you buy or even things like user

63
00:03:15.820 --> 00:03:18.699
design and user experience. Welcome to philosophy, you are

64
00:03:18.710 --> 00:03:21.119
doing aesthetics, right, and so on and so forth.

65
00:03:21.130 --> 00:03:23.339
So we're doing it all the time, but I

66
00:03:23.350 --> 00:03:27.509
think we weren't certainly in the Anglo Saxon world,

67
00:03:27.520 --> 00:03:30.080
we're not really taught it in the way that

68
00:03:30.089 --> 00:03:32.830
often you are in the continent much more explicitly.

69
00:03:32.839 --> 00:03:35.360
So I think that was like the first bridge

70
00:03:35.369 --> 00:03:37.600
I wanted to build with people that I work

71
00:03:37.610 --> 00:03:39.619
with both in my client work. But also in

72
00:03:39.630 --> 00:03:42.800
my writing was to kind of get everybody confident

73
00:03:42.809 --> 00:03:44.490
with the fact that actually you've already been doing

74
00:03:44.500 --> 00:03:47.679
this your whole life. So now that we give

75
00:03:47.690 --> 00:03:49.490
you the terms, you have like a name for

76
00:03:49.500 --> 00:03:51.470
what you're doing. And I can take you through

77
00:03:51.479 --> 00:03:53.940
examples of how you've been doing it, that's a

78
00:03:53.949 --> 00:03:56.500
bit empowering and confidence building. So now you can

79
00:03:56.509 --> 00:03:59.690
start doing it deliberately because that is uh that

80
00:03:59.699 --> 00:04:04.080
is a shift. I think there's something really cool

81
00:04:04.289 --> 00:04:08.009
about how philosophy exists as a tool set. It's

82
00:04:08.020 --> 00:04:12.119
very practical. It's very pragmatic. So if you're facing,

83
00:04:13.220 --> 00:04:15.580
oh, I don't know, a problem or an opportunity

84
00:04:15.589 --> 00:04:17.769
you're trying to evaluate to do something or not

85
00:04:17.779 --> 00:04:20.440
to do something or just what you think about

86
00:04:20.450 --> 00:04:22.510
something. Like, what's your point of view on it?

87
00:04:22.869 --> 00:04:27.450
Sometimes, particularly today, life is very complicated. It can

88
00:04:27.459 --> 00:04:29.670
be nice to have a tool set that helps

89
00:04:29.679 --> 00:04:31.510
you to think through things so that you can

90
00:04:31.519 --> 00:04:34.440
do it with a bit of rigor and then

91
00:04:34.450 --> 00:04:36.170
you can talk about it. It gives you like

92
00:04:36.179 --> 00:04:40.559
a shared menu if you will a shared script

93
00:04:40.570 --> 00:04:42.959
for talking about it with other people. And it's

94
00:04:42.970 --> 00:04:45.290
really nice if you're a problem solver by a

95
00:04:45.299 --> 00:04:49.130
profession, which doesn't necessarily mean you have to be

96
00:04:49.140 --> 00:04:50.829
a technologist or an engineer. You might be a

97
00:04:50.839 --> 00:04:54.869
problem solver as a lawyer, as a regulator. Um

98
00:04:55.489 --> 00:04:57.309
You might be, or even as like a CEO

99
00:04:57.320 --> 00:04:58.600
and you're having to figure out, you know, do

100
00:04:58.609 --> 00:05:00.260
we go this way or that way? What, what

101
00:05:00.269 --> 00:05:02.239
problem I'm trying to solve here. It can be

102
00:05:02.250 --> 00:05:04.839
really nice because it's like a due diligence exercise

103
00:05:04.850 --> 00:05:06.700
that allows you, you can go through it and

104
00:05:06.709 --> 00:05:08.390
when you're done, you're like, OK, I've done this,

105
00:05:08.399 --> 00:05:10.339
I've done this, I've done this, I've done this

106
00:05:11.320 --> 00:05:13.410
and that's really helpful. So I think that's the

107
00:05:13.420 --> 00:05:16.730
thing that I find really exciting about technology ethics

108
00:05:16.739 --> 00:05:18.980
is it's really practical. Like when I go in

109
00:05:18.989 --> 00:05:21.809
and teach this to people afterwards, they're like, we're

110
00:05:21.820 --> 00:05:23.980
doing our, the way our team functions is different

111
00:05:23.989 --> 00:05:26.779
now or the way that we tackle opportunity and

112
00:05:26.790 --> 00:05:29.850
risk assessment is different now and by different, I'm

113
00:05:29.859 --> 00:05:33.910
hoping they mean better. Right. So it doesn't have

114
00:05:33.920 --> 00:05:36.260
to necessarily be right now. A I Ethics is

115
00:05:36.269 --> 00:05:38.329
very buzzy and has been for a couple of

116
00:05:38.339 --> 00:05:41.010
years. But like, I don't limit my analysis to

117
00:05:41.019 --> 00:05:44.529
A II I go as broad as you can

118
00:05:44.559 --> 00:05:46.950
in terms of all technology because A I is

119
00:05:46.959 --> 00:05:49.480
just, it's an exciting technology and it is definitely

120
00:05:49.489 --> 00:05:51.890
the technology of the day in terms of the

121
00:05:51.899 --> 00:05:56.179
media and marketing cycle. But there's so much more,

122
00:05:57.049 --> 00:05:59.589
there's so much more we can do with philosophy

123
00:05:59.649 --> 00:06:02.410
in terms of the human tech relationship. So I

124
00:06:02.420 --> 00:06:05.230
think it's really fun. I wouldn't, I wouldn't have

125
00:06:05.239 --> 00:06:06.470
spent my time on it if I found it

126
00:06:06.480 --> 00:06:10.929
boring or not useful. Um On the contrary, once

127
00:06:10.940 --> 00:06:12.790
I started really working with this, I was like,

128
00:06:12.799 --> 00:06:17.980
this is powerful and it's helpful and that is

129
00:06:17.989 --> 00:06:20.619
great because if you are trying to tackle particularly

130
00:06:20.630 --> 00:06:23.420
complicated problems, you need every tool that you have.

131
00:06:24.649 --> 00:06:27.200
Uh And I mean, the main question you tackle

132
00:06:27.209 --> 00:06:30.750
in the book is, is technology neutral. And uh

133
00:06:30.760 --> 00:06:34.049
of course, just by looking at the title, your

134
00:06:34.059 --> 00:06:37.390
position is obvious, but e even before we get

135
00:06:37.399 --> 00:06:42.464
into your position and go through some examples that

136
00:06:42.475 --> 00:06:46.144
really are illustrative of the fact that technology might

137
00:06:46.154 --> 00:06:50.024
not be neutral. Give us perhaps some examples of

138
00:06:50.035 --> 00:06:53.945
arguments from the other side. People who argue that

139
00:06:53.954 --> 00:06:58.024
technology is indeed neutral, that you find perhaps the

140
00:06:58.035 --> 00:06:59.225
most compelling.

141
00:07:00.010 --> 00:07:02.489
Yeah. So I actually used to think technology was

142
00:07:02.500 --> 00:07:05.130
neutral. It was, it was in the writing of

143
00:07:05.140 --> 00:07:07.079
the book that I had to change my mind

144
00:07:07.529 --> 00:07:09.549
and I'll give a few examples of why I

145
00:07:09.559 --> 00:07:11.529
used to think this. Um First of all, I

146
00:07:11.540 --> 00:07:15.570
came from a business perspective where and I should

147
00:07:15.579 --> 00:07:19.109
declare my nationality interest. So I'm American by birth.

148
00:07:19.119 --> 00:07:21.040
And then I've had my career in the United

149
00:07:21.049 --> 00:07:23.309
Kingdom. So this is very much an Anglo Saxon

150
00:07:23.869 --> 00:07:28.230
uh free market capitalism, hardcore perspective because I appreciate

151
00:07:28.239 --> 00:07:31.399
that's not the case everywhere. Uh For your global

152
00:07:31.410 --> 00:07:36.440
audience of this interview, that perspective uh is very

153
00:07:36.450 --> 00:07:40.329
anti regulation. Regulation is always being portrayed as like

154
00:07:40.339 --> 00:07:43.500
hindering innovation. It's going to stop innovation and innovation

155
00:07:43.510 --> 00:07:46.899
is really key particularly in the US, you know,

156
00:07:46.910 --> 00:07:50.839
to American superpower, competitiveness. So anything that would hinder

157
00:07:50.850 --> 00:07:54.140
that instantly becomes political, it doesn't matter if you're

158
00:07:54.149 --> 00:07:56.709
a Republican or Democrat, everybody's like, oh, nobody wants

159
00:07:56.720 --> 00:08:01.209
to, everything that hinders that is the bloody communists.

160
00:08:01.899 --> 00:08:04.140
Exactly. Like take your pick. Are we scared of

161
00:08:04.149 --> 00:08:06.290
like the former Soviet Union in the eighties? It

162
00:08:06.299 --> 00:08:09.170
was Japan now. It's China, right? So like nobody

163
00:08:09.179 --> 00:08:14.329
wants to hinder innovation with pesky regulation. Uh SO

164
00:08:14.339 --> 00:08:17.640
you have, you have that, that right there shows

165
00:08:17.649 --> 00:08:19.760
you like, it's not at the end of the,

166
00:08:19.769 --> 00:08:22.329
the innovation cycle. If you will, you decide, you

167
00:08:22.339 --> 00:08:23.679
build something and you decide if you're going to

168
00:08:23.690 --> 00:08:26.720
regulate it or not, that is inherently not neutral.

169
00:08:26.940 --> 00:08:30.799
But the way it was being portrayed to argue

170
00:08:30.809 --> 00:08:34.159
against regulation, you would be like, whoa, whoa, whoa

171
00:08:34.229 --> 00:08:36.789
um you know, classic example in the United States

172
00:08:36.799 --> 00:08:40.440
is guns don't kill people, people kill people. And

173
00:08:40.450 --> 00:08:43.520
that argument has been if you will weaponized uh

174
00:08:43.719 --> 00:08:47.010
very successfully in the United States to stop us

175
00:08:47.020 --> 00:08:50.289
from doing any real meaningful gun control. Not just

176
00:08:50.299 --> 00:08:52.989
because we have the second amendment which gives Americans

177
00:08:53.000 --> 00:08:55.890
the right to bear arms, but when that law

178
00:08:55.900 --> 00:08:59.049
was crafted, we didn't have some of the weapons

179
00:08:59.059 --> 00:09:00.780
that we have today that you can buy at

180
00:09:00.789 --> 00:09:04.849
your local Walmart. Um OFTEN without an ID background

181
00:09:04.859 --> 00:09:09.340
check, it's actually quite staggering. And so the founding

182
00:09:09.349 --> 00:09:12.570
fathers were not imagining taking guns and walking into

183
00:09:12.580 --> 00:09:14.859
a school and shooting up an entire school, which

184
00:09:14.869 --> 00:09:18.349
unfortunately is a very common occurrence now, um, tragically,

185
00:09:18.359 --> 00:09:21.679
all too common. And so I started looking at

186
00:09:21.690 --> 00:09:24.440
being like, well on the one hand, it is

187
00:09:24.450 --> 00:09:27.219
true guns do not on their own, kill someone

188
00:09:27.229 --> 00:09:30.119
because they can't like self pull the trigger, they

189
00:09:30.130 --> 00:09:32.760
can't self shoot if you will. Although people I'm

190
00:09:32.770 --> 00:09:35.010
sure are now working on building guns that do

191
00:09:35.020 --> 00:09:38.770
exactly that A I powered weaponry but even then

192
00:09:38.780 --> 00:09:41.559
there's a human that's, that's ultimately coding that and

193
00:09:41.570 --> 00:09:43.760
controlling it. So it's still, there's always a human

194
00:09:43.979 --> 00:09:45.919
that takes the gun and makes the decision to

195
00:09:45.929 --> 00:09:49.200
pull a trigger. But I also was like, yeah,

196
00:09:49.210 --> 00:09:52.070
but the muskets that were there in the 18th

197
00:09:52.080 --> 00:09:54.400
century are really different from like an A K

198
00:09:54.409 --> 00:09:57.559
15 assault rifle. You can kill a lot more

199
00:09:57.570 --> 00:10:00.260
people with the latter than with the former. So

200
00:10:00.270 --> 00:10:03.609
like a gun is not just a gun, like

201
00:10:03.619 --> 00:10:07.419
even within like the gun analogy, the amount of

202
00:10:07.429 --> 00:10:09.479
harm I can do with a musket versus like

203
00:10:09.489 --> 00:10:12.500
a pistol versus like the kind of weaponry that

204
00:10:12.510 --> 00:10:15.219
frankly, you should only ever be seeing held by

205
00:10:15.229 --> 00:10:17.609
the military in like a theater of war and

206
00:10:17.619 --> 00:10:21.239
is unfortunately on the street or in people's homes,

207
00:10:21.250 --> 00:10:23.909
um is, is like inherently not neutral. There were

208
00:10:23.919 --> 00:10:26.609
design choices that went into the making of the

209
00:10:26.619 --> 00:10:29.090
gun, the way that the bullets are done. Um

210
00:10:29.099 --> 00:10:32.330
There's like cop killer bullets that can pierce um

211
00:10:32.340 --> 00:10:35.960
body armor, right? So like the people who designed

212
00:10:35.969 --> 00:10:38.830
that knew that and the people who are choosing

213
00:10:38.840 --> 00:10:41.229
to sell it know it. So like they're not

214
00:10:41.239 --> 00:10:43.570
neutral either because you could decide to be like,

215
00:10:43.580 --> 00:10:46.719
we're not selling guns here and there indeed was

216
00:10:46.729 --> 00:10:48.330
a sporting store in the U SI think it

217
00:10:48.340 --> 00:10:51.229
was Dick's sporting good sporting goods, which decided not

218
00:10:51.239 --> 00:10:52.770
to. And then it got this massive blowback and

219
00:10:52.780 --> 00:10:56.770
it became a national issue precisely because they were

220
00:10:56.780 --> 00:11:00.890
exercising their right not to sell. Right. But that's

221
00:11:00.900 --> 00:11:04.380
not neutral because now you're like removing my, my

222
00:11:04.390 --> 00:11:06.789
right. Damn it to have guns. Um, SO this

223
00:11:06.799 --> 00:11:09.640
isn't like a, I don't want to make a

224
00:11:09.650 --> 00:11:11.880
sort of pro or anti gun statement. I have

225
00:11:11.890 --> 00:11:13.729
my own view on that obviously, of course, as

226
00:11:13.739 --> 00:11:15.869
a citizen, I'm sure it's probably obvious from here.

227
00:11:15.940 --> 00:11:18.549
But what I mean is even with something that's

228
00:11:18.559 --> 00:11:22.770
like such a little easy example, like guns, easy.

229
00:11:22.780 --> 00:11:25.349
And compared in comparison to A I because it's

230
00:11:25.359 --> 00:11:29.190
just a physical, you know, tool, even that you

231
00:11:29.200 --> 00:11:31.840
start to realize like it is not neutral to

232
00:11:31.849 --> 00:11:36.289
decide to design bullets that can pierce wound right.

233
00:11:36.299 --> 00:11:37.890
There's like no other reason that you would do

234
00:11:37.900 --> 00:11:40.299
that. There's no other purpose of particularly a good

235
00:11:40.309 --> 00:11:43.469
benign purpose that you could use that for. So

236
00:11:43.479 --> 00:11:45.469
when you start thinking about it in that way,

237
00:11:45.840 --> 00:11:47.619
you can actually start looking at pretty much, I'm

238
00:11:47.630 --> 00:11:49.260
just looking around my my house right now, like

239
00:11:49.270 --> 00:11:53.789
almost any object, you're like, shit. Somebody has designed

240
00:11:53.799 --> 00:11:56.570
every aspect of it from the, the raw materials

241
00:11:56.580 --> 00:11:59.239
that were pulled out of the ground to like

242
00:11:59.250 --> 00:12:02.450
the environmental impact of that, to how much the

243
00:12:02.460 --> 00:12:05.619
workers all got paid all along the supply chain,

244
00:12:06.450 --> 00:12:08.780
all of it. Um Whether or not it's designed

245
00:12:08.789 --> 00:12:10.869
for the majority of the population, which is right

246
00:12:10.890 --> 00:12:12.929
handed or like, do we take left handed people

247
00:12:12.940 --> 00:12:15.159
into account What about if you're color blind? What

248
00:12:15.169 --> 00:12:19.869
if you have like dyslexia, like every single design

249
00:12:19.880 --> 00:12:24.739
consideration is not neutral. And that's just, that's just,

250
00:12:24.750 --> 00:12:28.679
again, that's for like analog world, physical objects. Now

251
00:12:28.690 --> 00:12:30.229
you take that to the next level and you

252
00:12:30.239 --> 00:12:33.330
start getting into code, it's the same principle, but

253
00:12:33.340 --> 00:12:38.659
it's also like turbocharged because A I, one of

254
00:12:38.669 --> 00:12:41.309
the things that's fascinating about what the world we're

255
00:12:41.320 --> 00:12:43.950
living in now is that because we have more

256
00:12:43.960 --> 00:12:48.390
data than ever before and computer processing power than

257
00:12:48.400 --> 00:12:51.869
ever before. We can do things faster and at

258
00:12:51.880 --> 00:12:54.830
a greater scale than at any time in human

259
00:12:54.840 --> 00:12:57.150
history. Whether or not that will hold by the

260
00:12:57.159 --> 00:12:59.500
way is very contentious. We don't know if we've

261
00:12:59.510 --> 00:13:02.429
reached the limits of computer processing power. For instance,

262
00:13:02.559 --> 00:13:06.859
we definitely haven't reached the limits of data. So

263
00:13:07.099 --> 00:13:09.419
that starts getting really messy. You also look at

264
00:13:09.429 --> 00:13:11.659
like who is doing the designing, be it for

265
00:13:11.669 --> 00:13:16.630
code or a physical object and those groups are

266
00:13:16.640 --> 00:13:21.619
not representative of the whole of our populations, which

267
00:13:21.630 --> 00:13:25.229
is why it can sound like diversity and equality

268
00:13:25.239 --> 00:13:27.880
and inclusion. We call it de I here. I'm

269
00:13:27.890 --> 00:13:30.479
not sure what it is in, in um Portuguese,

270
00:13:30.489 --> 00:13:34.229
but you probably have a similar concept

271
00:13:34.280 --> 00:13:37.140
for it. Yeah, the initials are pretty much the

272
00:13:37.150 --> 00:13:37.820
same, the same.

273
00:13:38.109 --> 00:13:42.609
Ok, cool. So de I can in many ways

274
00:13:42.619 --> 00:13:45.719
just seem like another version of being politically correct

275
00:13:45.729 --> 00:13:48.219
writer in the United States. A woke and it

276
00:13:48.229 --> 00:13:50.710
seems like a bad thing. I don't look at

277
00:13:50.719 --> 00:13:52.419
it as a bad thing in terms of the

278
00:13:52.429 --> 00:13:54.700
political sense. I look at it from a design

279
00:13:54.710 --> 00:13:57.710
perspective of being like I want, if I'm selling

280
00:13:57.719 --> 00:14:00.640
something, you know, bring out the capitalism. If I'm

281
00:14:00.650 --> 00:14:04.520
selling a service or a tool or a product,

282
00:14:04.539 --> 00:14:07.890
I want it to work for the vast majority,

283
00:14:07.900 --> 00:14:11.270
it ideally for everybody. So I have a challenge

284
00:14:11.280 --> 00:14:13.609
there because I need it to scale. But I

285
00:14:13.619 --> 00:14:17.039
also need to be able to personalize and customize,

286
00:14:17.500 --> 00:14:19.929
depending on your individual needs or the needs of

287
00:14:19.940 --> 00:14:21.859
your company or the needs of the country that

288
00:14:21.869 --> 00:14:23.799
you're based in. Right? Because you might have different

289
00:14:23.809 --> 00:14:26.130
laws there. Um How do I, how do I

290
00:14:26.140 --> 00:14:30.169
focus on that? And that kind of stuff really

291
00:14:30.179 --> 00:14:32.609
fascinates me because I don't understand why it gets

292
00:14:32.619 --> 00:14:35.539
lampooned so much in certain certain branches of the

293
00:14:35.549 --> 00:14:38.979
press and indeed investment communities as being politicized because

294
00:14:38.989 --> 00:14:41.349
I'm like, that's just truly, that's just good business.

295
00:14:41.359 --> 00:14:43.570
But like that, you know, that's just my, that's

296
00:14:43.580 --> 00:14:45.320
just my view, but I would assume as a

297
00:14:45.330 --> 00:14:47.750
good hearted capitalist that you would want to design

298
00:14:47.760 --> 00:14:49.669
products that the, you know, the majority of people

299
00:14:49.679 --> 00:14:52.150
can buy because that's, you know, catching more money.

300
00:14:52.479 --> 00:14:55.349
So it's very strange. Um So I guess that's

301
00:14:55.359 --> 00:14:57.539
what I mean when I say like technology ethics

302
00:14:57.859 --> 00:15:00.239
is so much bigger than just like, is something

303
00:15:00.250 --> 00:15:02.780
good or bad. Like that's a really binary way

304
00:15:02.789 --> 00:15:07.840
of looking at it. It's very complex and rich.

305
00:15:07.849 --> 00:15:10.799
It's like a tapestry, you start pulling on one

306
00:15:10.809 --> 00:15:12.780
thread and then you pull on another and another

307
00:15:12.789 --> 00:15:14.419
and you, you know, you come out with this

308
00:15:14.429 --> 00:15:19.450
whole complex analysis that you can use if you

309
00:15:19.460 --> 00:15:21.750
wish to make things better.

310
00:15:23.369 --> 00:15:25.609
Yeah, I mean, at a certain point there, you

311
00:15:25.619 --> 00:15:30.299
mentioned regulation and regulation across different countries. And perhaps

312
00:15:30.309 --> 00:15:33.219
later in the interview when we talk about specific

313
00:15:33.229 --> 00:15:35.710
kinds of technologies, we can come back to this

314
00:15:35.719 --> 00:15:39.640
because uh recently with the release of threads, it's

315
00:15:39.650 --> 00:15:43.010
interesting because here in the European Union, it's not

316
00:15:43.020 --> 00:15:46.159
available yet and it has to do with data

317
00:15:46.169 --> 00:15:50.130
privacy, online privacy, data collection, data, the ownership and

318
00:15:50.140 --> 00:15:52.599
all of that. So uh we can come back

319
00:15:52.609 --> 00:15:56.070
to this uh later. But uh I mean, uh

320
00:15:56.159 --> 00:15:59.390
at a certain point you mentioned there or alluded

321
00:15:59.400 --> 00:16:01.760
to one of the points you make in the

322
00:16:01.770 --> 00:16:04.280
book because at a certain point you talk about

323
00:16:04.289 --> 00:16:08.000
or explore the idea of what is a tool

324
00:16:08.080 --> 00:16:11.890
and the di the difference, for example, between tools

325
00:16:11.900 --> 00:16:14.880
that are found and tools that are created. So

326
00:16:15.140 --> 00:16:17.919
uh uh tell us a little bit about that

327
00:16:17.929 --> 00:16:21.270
because I think it's very helpful in terms of

328
00:16:21.280 --> 00:16:25.049
trying to reframe the way we think about these

329
00:16:25.059 --> 00:16:25.799
questions.

330
00:16:26.299 --> 00:16:28.659
Yeah. So for me, this was um I wrote

331
00:16:28.669 --> 00:16:30.640
a lot of the book during the pandemic during

332
00:16:30.650 --> 00:16:33.010
lockdown. Uh And I would, you know, I go

333
00:16:33.020 --> 00:16:36.469
for my sort of hour long walk sometimes longer

334
00:16:36.479 --> 00:16:38.809
than an hour who the British police will find

335
00:16:38.820 --> 00:16:40.880
out now that I was walking for an hour

336
00:16:40.890 --> 00:16:43.780
and a half. Um, I would do these really

337
00:16:43.789 --> 00:16:46.270
long laps around my local park and, you know,

338
00:16:46.280 --> 00:16:48.710
there was such a weird time. Right. It was

339
00:16:48.719 --> 00:16:51.049
such a strange time for all of us and

340
00:16:51.059 --> 00:16:54.719
I started to really go into some fairly abstract

341
00:16:55.690 --> 00:16:58.150
directions of thinking. And so one of the things

342
00:16:58.159 --> 00:17:02.669
was like, let's think of the most neutral tool

343
00:17:02.679 --> 00:17:06.069
possible and then the most like non neutral tool.

344
00:17:06.079 --> 00:17:08.209
So my examples because, you know, I wanted to

345
00:17:08.219 --> 00:17:11.589
like draw the, the map if you will or

346
00:17:11.598 --> 00:17:13.910
draw matrix, you know, so what's what's like the

347
00:17:13.920 --> 00:17:17.489
most neutral and the the most completely value laden

348
00:17:17.920 --> 00:17:21.069
um thing. So the, the hardcore one for me

349
00:17:21.079 --> 00:17:24.589
was the atomic bomb, which was, there's only one

350
00:17:24.598 --> 00:17:27.800
reason that you would build an atomic bomb and

351
00:17:27.810 --> 00:17:29.560
only one reason you're really going to use it,

352
00:17:29.569 --> 00:17:32.219
which is to harm because there's, there's no like

353
00:17:32.579 --> 00:17:34.349
there's no way of getting around that harm. It

354
00:17:34.359 --> 00:17:37.270
will, you know, the radiation damage to any human

355
00:17:37.280 --> 00:17:40.430
that comes within the blast radius and also just

356
00:17:40.439 --> 00:17:46.439
like other parts of nature for sure. Um IS

357
00:17:46.449 --> 00:17:49.250
just non negotiable, it's going to happen in physics.

358
00:17:49.260 --> 00:17:52.099
So there's that, but there's also like the only

359
00:17:52.109 --> 00:17:54.550
two times that human beings have used, it was

360
00:17:54.560 --> 00:17:56.010
in the theater of war Right. So, it was

361
00:17:56.020 --> 00:17:59.349
like, it was designed in a war to be

362
00:17:59.359 --> 00:18:01.630
used in a war and we have lived under

363
00:18:01.640 --> 00:18:05.550
the shadow of threat of nuclear war ever since.

364
00:18:05.560 --> 00:18:07.619
And I grew up in the Cold War in

365
00:18:07.630 --> 00:18:09.939
the US. So, for me as a child, this

366
00:18:09.949 --> 00:18:12.719
was like the scariest thing that could ever happen

367
00:18:12.729 --> 00:18:15.209
to human beings as a nuke, like a rogue

368
00:18:15.219 --> 00:18:17.900
nuke situation or nukes getting out of control and

369
00:18:17.910 --> 00:18:19.880
just decimating entire countries.

370
00:18:20.199 --> 00:18:24.540
And very, unfortunately recently we've been living more or

371
00:18:24.550 --> 00:18:27.349
less through that kind of fear and we're still

372
00:18:27.359 --> 00:18:28.030
living through

373
00:18:28.040 --> 00:18:29.729
that. Yeah, I mean, that's the thing is like,

374
00:18:29.739 --> 00:18:31.310
everybody freaks out about A I, and I'm like,

375
00:18:31.319 --> 00:18:34.584
there's all these nukes, you know, it's like thousands

376
00:18:34.594 --> 00:18:36.324
and thousands of them and like, lots of countries

377
00:18:36.334 --> 00:18:38.584
have them that maybe shouldn't and it's too late

378
00:18:38.594 --> 00:18:40.305
now. Like, we can't put that genie back in

379
00:18:40.314 --> 00:18:41.864
the bottle. So that was like, that was, that

380
00:18:41.875 --> 00:18:44.454
was over here in my most extreme example of

381
00:18:44.464 --> 00:18:46.895
a technology that, like, you just wouldn't use a

382
00:18:46.905 --> 00:18:49.005
nuke for something good. Maybe you would have like,

383
00:18:49.015 --> 00:18:51.344
aliens were coming or an asteroid that was attacking

384
00:18:51.354 --> 00:18:53.084
earth and the only way we could stop it

385
00:18:53.660 --> 00:18:55.359
would be if we, like, launched a nuke out

386
00:18:55.369 --> 00:18:57.479
in space to, you know, blow up the asteroid.

387
00:18:57.489 --> 00:19:00.400
This is how I talk with little kids about

388
00:19:00.410 --> 00:19:01.839
tech ethics and they're like, they get it. They're

389
00:19:01.849 --> 00:19:05.050
like, yeah, you nuke against the asteroid. Maybe not

390
00:19:05.060 --> 00:19:06.810
the alien though. But, uh, we would want to

391
00:19:06.819 --> 00:19:09.479
talk with them first. Perhaps so. Yeah.

392
00:19:09.489 --> 00:19:12.780
Yeah. Perhaps. Let's not just assume immediately that they

393
00:19:12.790 --> 00:19:16.449
would come here to work and we would be

394
00:19:16.459 --> 00:19:21.489
preemptively killing another life farmer. I mean, come on,

395
00:19:21.500 --> 00:19:23.459
let's just give them a chance.

396
00:19:23.489 --> 00:19:26.209
Exactly. That's, that's my view as well in case

397
00:19:26.219 --> 00:19:29.829
they're listening. Uh, BUT then the other extreme I

398
00:19:29.839 --> 00:19:32.150
was like, well, what's the other, other extreme? And

399
00:19:32.160 --> 00:19:34.380
I got really into looking at nature when I

400
00:19:34.390 --> 00:19:37.099
was on my walks. And of course, this led

401
00:19:37.109 --> 00:19:39.979
to animals who use tools because what humans are

402
00:19:39.989 --> 00:19:42.130
not the only species that make tools, which is

403
00:19:42.140 --> 00:19:44.130
so cool, you can really go down a rabbit

404
00:19:44.140 --> 00:19:46.709
hole with this. Um And I did, I went

405
00:19:46.719 --> 00:19:48.229
down that rabbit hole so that you don't have

406
00:19:48.239 --> 00:19:50.869
to and looked at all of the different ways

407
00:19:50.880 --> 00:19:53.689
that animals fashion tools. And of course, this starts

408
00:19:53.699 --> 00:19:57.290
to become if you're interested in the history of

409
00:19:57.300 --> 00:20:01.989
what differentiates human beings from our other ape chimpanzee

410
00:20:02.000 --> 00:20:05.670
brethren. One of the big questions was human beings

411
00:20:05.680 --> 00:20:08.319
make tools. That's like a defining characteristic of what

412
00:20:08.329 --> 00:20:09.959
it means to be human, which is kind of

413
00:20:09.969 --> 00:20:11.869
trippy if you think about. Well, so the crows.

414
00:20:12.069 --> 00:20:15.140
So like, why is, why is that about making

415
00:20:15.150 --> 00:20:17.130
us human? But it just is. And so that

416
00:20:17.140 --> 00:20:19.430
was one of the things when Jane Goodall was

417
00:20:19.439 --> 00:20:22.910
um doing her amazing research about chimpanzees and she

418
00:20:22.920 --> 00:20:26.699
wrote to her then phd supervisor to describe what

419
00:20:26.709 --> 00:20:30.030
she was observing and he wrote back saying either

420
00:20:30.040 --> 00:20:32.469
we have to redefine what a tool is or

421
00:20:32.479 --> 00:20:34.630
we have to redefine what man is. And I

422
00:20:34.640 --> 00:20:37.829
was like, oh, there's something in this. And so

423
00:20:37.839 --> 00:20:39.810
it was like, well, what are those animals doing?

424
00:20:39.819 --> 00:20:42.209
And what were we doing? So, they were doing

425
00:20:42.219 --> 00:20:44.290
something along the lines of what I call a

426
00:20:44.300 --> 00:20:47.979
found tool. So they would find an object in

427
00:20:47.989 --> 00:20:51.989
nature, a stone, um, a branch and they would

428
00:20:52.000 --> 00:20:54.900
fashion it in some way to make a weapon.

429
00:20:54.910 --> 00:20:57.760
Usually it's used to hunt for food, um, rather

430
00:20:57.770 --> 00:21:01.030
than harm others, trapping food, et cetera, but it

431
00:21:01.040 --> 00:21:04.140
showed like advanced cognitive abilities. So I was like,

432
00:21:04.150 --> 00:21:09.219
ok, they're taking something that, that exists already and

433
00:21:09.229 --> 00:21:11.630
they're fashioning it in some way and they're coming

434
00:21:11.640 --> 00:21:14.359
up with really interesting uses for it. And there's

435
00:21:14.369 --> 00:21:16.119
a number of species that do it, of which

436
00:21:16.130 --> 00:21:18.040
we are one. So let's call that like the

437
00:21:18.050 --> 00:21:22.530
most even fire potentially could be viewed as neutral

438
00:21:22.540 --> 00:21:24.449
in the sense that it exists in nature. Like

439
00:21:24.459 --> 00:21:27.030
you can just look over in Canada right now

440
00:21:27.040 --> 00:21:29.349
where you're just getting these spontaneous wildfires because of

441
00:21:29.359 --> 00:21:31.500
the heat or when lightning strikes the earth, it

442
00:21:31.510 --> 00:21:35.750
can spark fires so that can exist in. So

443
00:21:35.760 --> 00:21:39.099
we didn't like invent fire. Nature invented fire. We

444
00:21:39.109 --> 00:21:41.119
just figured out how to harness it and then

445
00:21:41.130 --> 00:21:45.579
deliberately create conditions in which fire appears So I

446
00:21:45.589 --> 00:21:48.319
took that thinking and went back to the atomic

447
00:21:48.329 --> 00:21:51.390
bomb thinking and was like, OK, what do we

448
00:21:51.400 --> 00:21:53.670
mean by the atomic bomb? Because there's a whole

449
00:21:53.680 --> 00:21:55.329
process, you don't just start with an atomic bomb,

450
00:21:55.339 --> 00:21:58.380
they're incredibly difficult to build. Thank God uh given

451
00:21:58.390 --> 00:22:00.040
the harm that they can do. So I started

452
00:22:00.050 --> 00:22:04.410
reading honestly, it's like bringing back all these weird

453
00:22:04.420 --> 00:22:07.859
pandemic memories. But I spent like months, months and

454
00:22:07.869 --> 00:22:11.550
months reading about the journey to make that bomb

455
00:22:11.560 --> 00:22:14.060
and the scientists who started out working on it

456
00:22:14.069 --> 00:22:17.540
were not doing it to make a weapon, which

457
00:22:17.550 --> 00:22:19.660
I think is important because what you want to

458
00:22:19.670 --> 00:22:22.119
do is you want to identify where, where from

459
00:22:22.130 --> 00:22:25.839
like the first discovery to the first detonation over

460
00:22:25.849 --> 00:22:30.880
Hiroshima and the Nagasaki, where in that line do

461
00:22:30.890 --> 00:22:33.040
you cross, do you cross a line and it

462
00:22:33.050 --> 00:22:34.770
stops being neutral? So I was like, OK, the

463
00:22:34.780 --> 00:22:39.239
scientists who are just looking to understand what happens

464
00:22:39.250 --> 00:22:44.079
when you bombard uranium, that's just like pure science

465
00:22:44.089 --> 00:22:47.540
and the, the information of that the fact of

466
00:22:47.550 --> 00:22:49.829
that exists in nature or whether or not we

467
00:22:49.839 --> 00:22:53.290
ever discovered it as humans, it would exist because

468
00:22:53.300 --> 00:22:57.010
again, it's, it's, it's physics. So when does it

469
00:22:57.020 --> 00:23:00.530
start to become a weapon? And I identified in

470
00:23:00.540 --> 00:23:02.729
the book that it becomes a weapon in the

471
00:23:02.739 --> 00:23:07.089
mind of a brilliant Hungarian scientist, Leo Solar as

472
00:23:07.099 --> 00:23:09.050
he was walking down the street here in London,

473
00:23:09.060 --> 00:23:12.849
he attended a lecture, I think in 1938 and

474
00:23:12.859 --> 00:23:15.709
he suddenly had this idea of how to do

475
00:23:15.719 --> 00:23:18.550
it. And because he was friends with everyone, he's

476
00:23:18.560 --> 00:23:20.750
an amazing man. His book, Genius In The Shadows.

477
00:23:20.760 --> 00:23:22.430
It's a book about his life is really worth

478
00:23:22.439 --> 00:23:25.310
reading to discover like the networking of science and

479
00:23:25.319 --> 00:23:28.170
how an idea goes from idea to weapon or

480
00:23:28.180 --> 00:23:30.880
hopefully the idea to vaccine or idea to, you

481
00:23:30.890 --> 00:23:33.609
know, wonderful cure that will save us all from

482
00:23:33.619 --> 00:23:36.319
climate change. So he goes and talks to Einstein

483
00:23:36.329 --> 00:23:38.479
about it and because both of them were Central

484
00:23:38.489 --> 00:23:41.670
European and Jewish, which I think is also very

485
00:23:41.680 --> 00:23:45.180
important, they recognize the threat of Hitler far earlier

486
00:23:45.189 --> 00:23:48.439
than their American counterparts did. And they were like

487
00:23:48.920 --> 00:23:52.150
a, you could do this with the scientific information

488
00:23:52.160 --> 00:23:55.180
that we now have about how to split the

489
00:23:55.189 --> 00:23:58.869
atom, you could do this and you could weaponize

490
00:23:58.880 --> 00:24:02.300
it and we think that Hitler will so we'd

491
00:24:02.310 --> 00:24:04.910
better have a plan in place. And because Einstein

492
00:24:04.920 --> 00:24:08.119
was able due to his incredible status as a

493
00:24:08.130 --> 00:24:11.369
Nobel Prize winner to get an audience with the

494
00:24:11.380 --> 00:24:15.540
then US President Franklin Delano Roosevelt, they explained this

495
00:24:15.550 --> 00:24:19.729
to him, laid it out and then FDR green

496
00:24:19.739 --> 00:24:21.819
lit the deal if you will to create what

497
00:24:21.829 --> 00:24:24.369
became the Manhattan project, which ended up involving over

498
00:24:24.400 --> 00:24:26.989
1000 scientists and you know, massive budget and became

499
00:24:27.000 --> 00:24:29.170
a military project and scientists from all over the

500
00:24:29.180 --> 00:24:31.510
world worked on it. So you're like, so was

501
00:24:31.520 --> 00:24:34.829
it FDR that did it because he, he gave

502
00:24:34.839 --> 00:24:37.339
like the political nouse if you will and power

503
00:24:37.349 --> 00:24:40.880
and approval and money. Was it Einstein who like

504
00:24:40.890 --> 00:24:42.920
formed the bridge? Because Leo Solar could have had

505
00:24:42.930 --> 00:24:44.839
the idea. We all have great ideas, but like

506
00:24:44.849 --> 00:24:48.619
that doesn't necessarily lead to them being executed. So

507
00:24:48.630 --> 00:24:51.454
there's like a chain. It was like solar. Einstein

508
00:24:51.464 --> 00:24:54.814
FDRFDR then tasked Ben our Bush who is like

509
00:24:54.824 --> 00:24:58.165
head of all of America's totally cool World War

510
00:24:58.175 --> 00:25:01.135
Two science stuff. Another fascinating person to read about

511
00:25:02.265 --> 00:25:05.334
Robert Oppenheimer. Now subject of a major movie uh

512
00:25:05.344 --> 00:25:08.295
who led, you know, who like literally run the

513
00:25:08.305 --> 00:25:13.329
man project. All of it was absolutely fascinating for

514
00:25:13.339 --> 00:25:15.219
me to like I had to build out the

515
00:25:15.229 --> 00:25:18.260
map of who was working on it. You know,

516
00:25:18.270 --> 00:25:20.270
you could ultimately be like, no, all of these

517
00:25:20.280 --> 00:25:22.089
things could have happened and it actually comes down

518
00:25:22.099 --> 00:25:24.079
to the pilots who flew the plane and dropped

519
00:25:24.089 --> 00:25:28.459
the two bombs because they were the last kind

520
00:25:28.469 --> 00:25:30.719
of line of defense who could have, I don't

521
00:25:30.729 --> 00:25:33.530
know, made an ethical protest and done what many

522
00:25:33.540 --> 00:25:36.199
people wanted by that point, which was a demonstration

523
00:25:36.209 --> 00:25:40.040
of the bomb but not on a human population.

524
00:25:40.050 --> 00:25:41.599
You could have dropped it out in the ocean

525
00:25:41.609 --> 00:25:44.209
to let people see what it was capable of

526
00:25:44.219 --> 00:25:46.530
doing. And hopefully, then that would have made Japan

527
00:25:46.540 --> 00:25:48.550
surrender. That was like an actual idea that was

528
00:25:48.560 --> 00:25:51.410
being put forward. But by that point the new

529
00:25:51.420 --> 00:25:53.569
president, Harry Truman was like, no, we have to

530
00:25:53.579 --> 00:25:56.739
do this because he was given statistics saying if

531
00:25:56.750 --> 00:25:59.040
we don't drop this bomb and the fighting continues

532
00:25:59.050 --> 00:26:02.869
for another 18 months, which were the predictions, however

533
00:26:02.880 --> 00:26:04.479
many people will die and it was in the

534
00:26:04.489 --> 00:26:07.949
millions. So he was weighing up his ethical calculus,

535
00:26:07.959 --> 00:26:10.359
right. And it's easy for all of us to

536
00:26:10.369 --> 00:26:13.079
judge these things now knowing what we know now.

537
00:26:13.089 --> 00:26:15.699
But back then they didn't know and they had

538
00:26:15.709 --> 00:26:17.329
to make a call and they'd already been fighting

539
00:26:17.339 --> 00:26:20.079
war for a really long time. And, you know,

540
00:26:20.089 --> 00:26:21.810
we can argue about that and people do argue

541
00:26:21.819 --> 00:26:24.229
about that until the cows come home. So for

542
00:26:24.239 --> 00:26:26.099
me, I didn't want to argue about it. I

543
00:26:26.109 --> 00:26:31.260
wanted to sort of forensically map it because I

544
00:26:31.270 --> 00:26:35.329
can see it happening again. Uh I can see

545
00:26:35.339 --> 00:26:37.219
it happening in all sorts of different things. And

546
00:26:37.229 --> 00:26:38.250
like, I don't mean in the sense of it's

547
00:26:38.260 --> 00:26:40.780
leading to death. I mean, I, I can see

548
00:26:40.790 --> 00:26:43.449
it happening again in that we are in this

549
00:26:43.459 --> 00:26:50.119
incredible moment of flourishing scientifically and technologically. This is

550
00:26:50.130 --> 00:26:51.579
an, this is an amazing time. Like people will

551
00:26:51.589 --> 00:26:53.930
write about this. I think centuries later from now

552
00:26:54.030 --> 00:26:56.390
that this was like a real turning point moment

553
00:26:56.400 --> 00:27:00.130
in human science and technology evolution. And so what

554
00:27:00.140 --> 00:27:02.219
I'm hoping to do many people are working on

555
00:27:02.229 --> 00:27:04.140
this, I'm just like one tiny little person. But

556
00:27:04.150 --> 00:27:07.060
what I'm hoping to do um as a historian

557
00:27:07.069 --> 00:27:08.790
in training is like, write the history of the

558
00:27:08.800 --> 00:27:11.459
future, which is like, ok, so if, if we've

559
00:27:11.469 --> 00:27:14.920
got a, I now, what can we learn from

560
00:27:14.939 --> 00:27:17.890
the atomic bomb exercise that we just went through?

561
00:27:17.900 --> 00:27:21.439
You? And I here today to understand who's working,

562
00:27:21.449 --> 00:27:23.719
for instance, on A I, although it can also

563
00:27:23.729 --> 00:27:26.250
be genetic engineering, it could be any technology, put

564
00:27:26.260 --> 00:27:27.540
it in the whole point is that it should

565
00:27:27.550 --> 00:27:30.699
work for anything who's working on it. What are

566
00:27:30.709 --> 00:27:33.439
the ethical decisions that are in play? Who has

567
00:27:33.449 --> 00:27:36.530
the power to actually get things done or more

568
00:27:36.540 --> 00:27:41.939
importantly to stop something, right? All of that stuff

569
00:27:41.949 --> 00:27:44.000
and also who doesn't have the power, who's just

570
00:27:44.010 --> 00:27:47.430
on the receiving end of this? Because like, you

571
00:27:47.439 --> 00:27:52.489
know, the atomic crisis, if you will, that resulted

572
00:27:52.500 --> 00:27:54.709
from 1945 I think helped a lot of people

573
00:27:54.719 --> 00:27:56.640
to understand that this is something that affects all

574
00:27:56.650 --> 00:27:58.770
of humanity, but not all of humanity was involved

575
00:27:58.780 --> 00:28:02.849
in the design and deployment considerations. And even with

576
00:28:02.859 --> 00:28:06.880
nuclear arms control, even today, certain countries have a

577
00:28:06.890 --> 00:28:09.770
greater voice in that than others. And that matters

578
00:28:09.780 --> 00:28:11.969
because you hear with people talking about A I

579
00:28:11.979 --> 00:28:16.579
governance and they're like, we should have an international

580
00:28:16.589 --> 00:28:20.890
Atomic Energy Agency like exists today in Vienna to

581
00:28:20.900 --> 00:28:23.270
look at nuclear technology. We should have something like

582
00:28:23.280 --> 00:28:24.920
that for A I. And it's like, well, OK,

583
00:28:24.930 --> 00:28:29.430
let's just check that, that interesting idea. Let's examine

584
00:28:29.439 --> 00:28:34.160
that is the IAE A actually a good example,

585
00:28:34.170 --> 00:28:37.640
a template a model for us to use to

586
00:28:37.650 --> 00:28:41.489
govern A I. And like we need to interview

587
00:28:41.500 --> 00:28:43.020
the people who are working on it and also

588
00:28:43.030 --> 00:28:44.670
their critics and come up with that view, I've

589
00:28:44.680 --> 00:28:47.300
seen some people really dismiss it. You also saw

590
00:28:47.310 --> 00:28:49.770
a bunch of people saying we should have a

591
00:28:49.780 --> 00:28:53.170
CERN for A I research. So cern being the

592
00:28:53.180 --> 00:28:55.569
particle physics laboratory that's based on the French Swiss

593
00:28:55.579 --> 00:28:58.589
border as physicists again from around the world. And

594
00:28:58.599 --> 00:29:01.719
it's public, public science, if you will public interest

595
00:29:01.729 --> 00:29:05.010
science, so you would want to talk with CERN

596
00:29:05.020 --> 00:29:06.959
and be like, OK, like we have an example,

597
00:29:06.969 --> 00:29:08.969
we run the CERN experiment now for, you know,

598
00:29:08.979 --> 00:29:12.869
5060 years. Do you think that's actually relevant and

599
00:29:12.880 --> 00:29:16.719
appropriate if it isn't, could we do better with

600
00:29:16.729 --> 00:29:19.079
an A I research lab? What would that look

601
00:29:19.089 --> 00:29:24.530
like to make it fair equitable? Um REPRESENTATIVE more

602
00:29:24.540 --> 00:29:28.339
democratic. Uh HOW do we factor in things like

603
00:29:28.349 --> 00:29:31.500
climate and biodiversity, which we didn't necessarily in the

604
00:29:31.510 --> 00:29:34.380
early atomic discussions but actually really matter that sort

605
00:29:34.390 --> 00:29:36.660
of thing. So I think there's a lot we

606
00:29:36.670 --> 00:29:40.239
can learn from the history of this found technology

607
00:29:40.250 --> 00:29:42.109
if it's just something that's out there versus something

608
00:29:42.119 --> 00:29:44.910
that you very deliberately set out to make like

609
00:29:44.920 --> 00:29:47.800
an atomic bomb and most of us when we're

610
00:29:47.810 --> 00:29:51.839
making technology or using it or investing in it

611
00:29:52.400 --> 00:29:55.030
uh or buying it are not ever going to

612
00:29:55.040 --> 00:29:58.449
have to face the extremes of an atomic weapon,

613
00:29:58.719 --> 00:30:01.180
but we'll probably be somewhere closer from, we just

614
00:30:01.189 --> 00:30:04.829
found something and we, we like fashioned it or

615
00:30:04.839 --> 00:30:07.989
we're deliberately creating something that's probably more middle of

616
00:30:08.000 --> 00:30:10.469
the road between those two. So that's a really

617
00:30:10.479 --> 00:30:12.119
long example. But I think it's quite important because

618
00:30:12.130 --> 00:30:14.829
you can't really rush through talking about nuclear technology.

619
00:30:15.250 --> 00:30:18.079
Um, AND it matters because now we're having this

620
00:30:18.089 --> 00:30:21.020
big conversation globally about how to regulate A I

621
00:30:21.359 --> 00:30:23.660
and thing that people keep coming back to again

622
00:30:23.670 --> 00:30:27.380
and again and again is the nuclear war threat.

623
00:30:27.560 --> 00:30:30.119
They also cite the pandemic threat given that we've

624
00:30:30.130 --> 00:30:31.550
all just lived through that. I think we all

625
00:30:31.560 --> 00:30:36.119
had a very uh upfront close and personal stress

626
00:30:36.130 --> 00:30:40.109
test of pandemic governance and health governance and bio

627
00:30:40.560 --> 00:30:44.000
laboratory governance, right? Like was this a virus that

628
00:30:44.010 --> 00:30:46.310
was manufactured in the lab? Was it something that

629
00:30:46.319 --> 00:30:48.199
came from nature? Like this is something that's still

630
00:30:48.209 --> 00:30:51.390
being discussed? Scientists are still evolving their views on

631
00:30:51.400 --> 00:30:53.209
that and even if it is something that was

632
00:30:53.219 --> 00:30:55.229
found in nature, it still raises the issue of

633
00:30:55.239 --> 00:30:58.130
these labs, right? And like how the ethics, the

634
00:30:58.140 --> 00:31:03.099
ethics of bioengineering that all comes from World War

635
00:31:03.109 --> 00:31:05.979
Two, all of that thinking medical ethics, all of

636
00:31:05.989 --> 00:31:09.410
it really got an update from World War Two.

637
00:31:09.420 --> 00:31:11.459
So if you want to think about the technologies

638
00:31:11.469 --> 00:31:14.199
of the future, knowing your second World War Science

639
00:31:14.209 --> 00:31:17.890
and technology studies, history from the second World War

640
00:31:17.900 --> 00:31:23.180
onwards I think is essential, right? You know, you

641
00:31:23.189 --> 00:31:25.369
have, you can't, you can't be talking about A

642
00:31:25.380 --> 00:31:28.140
I to today in the abstract, you have to

643
00:31:28.150 --> 00:31:33.430
know we've already seen scientists taking ethical stances and

644
00:31:33.439 --> 00:31:37.219
doctors taking ethical stances. Um, SOME people have said

645
00:31:37.229 --> 00:31:38.939
that A I should be regulated more like the

646
00:31:38.949 --> 00:31:41.229
food and drug agency in the United States. Like

647
00:31:41.239 --> 00:31:43.530
you can't just, you can't just roll out a

648
00:31:43.540 --> 00:31:47.280
drug on the American population. It has to go

649
00:31:47.290 --> 00:31:51.380
through extremely rigorous testing, right? And God forbid when

650
00:31:51.390 --> 00:31:55.359
we're talking about global pharmaceutical manufacturing or global research

651
00:31:55.660 --> 00:31:59.189
um or research on the human body or embryos

652
00:31:59.199 --> 00:32:02.239
and stem cell tissue, right? Like there's entire governance

653
00:32:02.250 --> 00:32:05.790
structures set up for this that come from weirdly

654
00:32:05.800 --> 00:32:08.469
a World War Two starting framework because that's when

655
00:32:08.479 --> 00:32:13.560
we saw not just the potentially positive but also

656
00:32:13.609 --> 00:32:16.819
controversial narrative around atomic weapons, but also a lot

657
00:32:16.829 --> 00:32:21.260
of the Nazi medical experiments and bioresearch experiments, which

658
00:32:21.270 --> 00:32:24.670
were absolutely horrific, right? So all of that thinking

659
00:32:24.680 --> 00:32:26.920
is there. So if you don't know that thinking

660
00:32:27.250 --> 00:32:29.579
you're doing the classic thing that tech people do,

661
00:32:29.589 --> 00:32:31.339
which is like, oh what if we invented this

662
00:32:31.349 --> 00:32:33.550
thing? And you're like, you've invented something that's literally

663
00:32:33.560 --> 00:32:35.349
already existed and that people have been working on

664
00:32:35.359 --> 00:32:37.939
for decades, like do your literature review before you

665
00:32:37.949 --> 00:32:43.300
start talking, right? So classic. So classic,

666
00:32:44.910 --> 00:32:48.670
I mean, let me just ask you one question

667
00:32:48.680 --> 00:32:51.180
about all of what you what you've just said.

668
00:32:51.189 --> 00:32:56.510
So, um, you've talked mostly about nuclear weapons and

669
00:32:56.520 --> 00:32:59.939
you also have the discovery of nuclear fusion, for

670
00:32:59.949 --> 00:33:04.040
example. And uh I, I was wondering if you

671
00:33:04.050 --> 00:33:10.239
think that perhaps certain scientific discoveries themselves might not

672
00:33:10.250 --> 00:33:13.430
be neutral because I, I mean, we could, we

673
00:33:13.439 --> 00:33:17.255
could just say, uh and I'm not pointing fingers

674
00:33:17.265 --> 00:33:20.964
at anyone that studies or studied nuclear fission. I

675
00:33:20.974 --> 00:33:23.895
mean, it's uh as far as I, as I,

676
00:33:23.905 --> 00:33:26.824
as I'm concerned, it's perfectly fine to understand how

677
00:33:26.885 --> 00:33:29.094
atoms work and all of that. And the same

678
00:33:29.104 --> 00:33:32.494
for how genes work, for example. But at the

679
00:33:32.505 --> 00:33:36.609
same time, isn't it the case that uh first

680
00:33:36.619 --> 00:33:40.560
of all people, uh people who are making the

681
00:33:40.569 --> 00:33:44.589
scientific discoveries themselves are people and they have their

682
00:33:44.599 --> 00:33:49.510
own motivations and their work is u usually uh

683
00:33:49.520 --> 00:33:55.369
uh paid for by governments or private institutions. And

684
00:33:55.380 --> 00:34:02.880
that's also not random or usually not arbitrary. I

685
00:34:02.890 --> 00:34:06.420
mean, if they pay for something, they have particular

686
00:34:06.430 --> 00:34:10.458
goals in mind, they want certain developments instead of

687
00:34:10.469 --> 00:34:13.478
others, they want c to work. Why there certain

688
00:34:13.489 --> 00:34:17.789
knowledge instead of some other knowledge? So could it

689
00:34:17.799 --> 00:34:22.668
also, could you think or say that certain scientific

690
00:34:22.678 --> 00:34:28.398
discoveries are themselves not neutral even though they are

691
00:34:28.789 --> 00:34:32.938
just uh just uh uh at first sight producing

692
00:34:33.728 --> 00:34:35.829
useful knowledge or?

693
00:34:36.148 --> 00:34:39.029
Well, I think it's probably important to differentiate between

694
00:34:39.039 --> 00:34:43.708
the discovery and what leads to it. So, back

695
00:34:43.717 --> 00:34:45.569
in the day when I thought that technology was

696
00:34:45.579 --> 00:34:47.388
neutral before I wrote a book of the change

697
00:34:48.739 --> 00:34:50.748
if I was coming from the, the sort of

698
00:34:50.759 --> 00:34:53.543
technology um digital perspective. And I was like, this

699
00:34:53.554 --> 00:34:56.504
is math, this is mathematics and you hear that

700
00:34:56.514 --> 00:34:59.735
a lot um like Gary Kasparov, the chess grandmaster

701
00:34:59.745 --> 00:35:01.245
who wrote a book on A I called Deep

702
00:35:01.254 --> 00:35:03.504
Thinking was like on Twitter a few years ago.

703
00:35:03.514 --> 00:35:05.185
And I cited him in the book saying ethical

704
00:35:05.195 --> 00:35:09.274
A I is like ethical, electricity, like electricity is

705
00:35:09.284 --> 00:35:11.235
just electricity. Like he was kind of like, what

706
00:35:11.245 --> 00:35:15.054
is this uh this argument? And I, I understand

707
00:35:15.064 --> 00:35:16.875
what he means and you see it a lot.

708
00:35:16.885 --> 00:35:20.185
I follow Twitter obsessively and I'm constantly watching people

709
00:35:20.195 --> 00:35:23.969
argue about code is neutral. Math is neutral and

710
00:35:23.979 --> 00:35:25.879
all these people are trying to talk about values,

711
00:35:25.889 --> 00:35:28.560
but math has no values. It's like the universal

712
00:35:28.570 --> 00:35:32.840
language. And I understand that just like a phenomenon

713
00:35:32.850 --> 00:35:35.040
that exists in chemistry or a phenomenon that exists

714
00:35:35.050 --> 00:35:38.379
in physics. Again, putting the atom has like doesn't

715
00:35:38.389 --> 00:35:40.639
care what my politics are or who writes my

716
00:35:40.649 --> 00:35:43.340
paycheck, right? Like it just, it just exists, it's

717
00:35:43.350 --> 00:35:47.370
knowledge. So I think that part is, is neutral,

718
00:35:47.379 --> 00:35:50.800
something that just exists, is neutral in the natural

719
00:35:50.810 --> 00:35:58.250
physical world. That doesn't mean that motivations for seeking

720
00:35:58.260 --> 00:36:01.820
that knowledge out are irrelevant because I think they

721
00:36:01.830 --> 00:36:05.520
are relevant. Uh Absolutely the funding model. I mean,

722
00:36:05.530 --> 00:36:07.340
we're seeing this right now with A I like

723
00:36:07.350 --> 00:36:11.489
most people can't afford to build large language models

724
00:36:11.500 --> 00:36:14.169
there, there's this whole thing of like elite capture

725
00:36:14.179 --> 00:36:15.350
and whether or not we're going to have like

726
00:36:15.360 --> 00:36:17.860
a new monopoly of these things, which is why

727
00:36:17.870 --> 00:36:19.310
we're getting a lot of pushback and some people

728
00:36:19.320 --> 00:36:21.780
are wanting to release them as source. Now. Uh

729
00:36:21.790 --> 00:36:24.610
What data goes into the training sets, all of

730
00:36:24.620 --> 00:36:27.340
this stuff, the intellectual property thereof. Can these things

731
00:36:27.350 --> 00:36:30.350
be audited or not? And should they be particularly

732
00:36:30.360 --> 00:36:32.620
if they're involved in public procurement of any kind?

733
00:36:33.110 --> 00:36:36.300
Um OR like public service use of any kind.

734
00:36:36.669 --> 00:36:41.439
So I think we're sophisticated enough as a species

735
00:36:41.449 --> 00:36:44.060
where we can have this conversation and go if

736
00:36:44.070 --> 00:36:47.669
you are doing something, if you're seeking out knowledge

737
00:36:47.679 --> 00:36:50.429
and doing research on behalf of shareholders for a

738
00:36:50.439 --> 00:36:56.239
company or a private company or the government, governments

739
00:36:56.250 --> 00:36:58.389
are completely value laden. So of course, it matters

740
00:36:58.399 --> 00:37:00.270
if you're doing it for the US government versus

741
00:37:00.280 --> 00:37:03.489
the Chinese government versus let's pick Switzerland which claims

742
00:37:03.500 --> 00:37:08.169
to be neutral, uh an interesting country to tackle

743
00:37:08.179 --> 00:37:11.030
on that claim. Of course, these things matter. So

744
00:37:11.040 --> 00:37:13.429
I feel like we can, we can separate out

745
00:37:13.439 --> 00:37:15.350
the neutrality of the fact like, oh wow, if

746
00:37:15.360 --> 00:37:17.379
you cut off my finger, this is what happens

747
00:37:17.389 --> 00:37:20.100
like a finger being removed from its hand produces

748
00:37:20.110 --> 00:37:22.570
X numbers of physical responses and we can observe

749
00:37:22.580 --> 00:37:25.429
them and describe them forensically and repeat that experiment

750
00:37:25.439 --> 00:37:27.699
and hopefully stop cutting people's fingers off because we've,

751
00:37:27.729 --> 00:37:32.739
we've answered those questions. But why of doing that?

752
00:37:32.750 --> 00:37:36.409
The who of doing that? The, for what purpose

753
00:37:36.419 --> 00:37:38.209
are we going to use that knowledge? Is it,

754
00:37:38.219 --> 00:37:39.570
you know, maybe we're chopping our fingers for a

755
00:37:39.580 --> 00:37:41.959
really good reason. Maybe we're doing it terribly just

756
00:37:41.969 --> 00:37:45.419
to be awful. Like all of those questions are

757
00:37:45.429 --> 00:37:48.580
relevant and matter and we can use them to,

758
00:37:49.129 --> 00:37:51.949
to do science potentially in a more ethical way.

759
00:37:51.959 --> 00:37:54.409
And like, I know that's a really problematic statement

760
00:37:54.419 --> 00:37:55.929
for a lot of people. And it should be,

761
00:37:55.939 --> 00:37:58.149
I'm delighted that it's a problematic statement because it

762
00:37:58.159 --> 00:38:00.169
means that our thinking is like switched on and

763
00:38:00.179 --> 00:38:02.060
we're all going to go. Does that mean to

764
00:38:02.070 --> 00:38:04.899
do more ethical science? What does it mean to

765
00:38:04.909 --> 00:38:09.250
do ethical technology or ethical A I? And we

766
00:38:09.260 --> 00:38:11.199
see that with A I, right. I, I cannot

767
00:38:11.209 --> 00:38:13.300
think of another technology where so many people have

768
00:38:13.310 --> 00:38:15.360
been in such a hurry to claim that it's

769
00:38:15.370 --> 00:38:20.719
trustworthy, responsible, reliable, um ethical, you know, we don't,

770
00:38:20.729 --> 00:38:22.310
we don't feel the need to do that. And

771
00:38:22.320 --> 00:38:27.580
it's because I think people understand we've matured enough

772
00:38:27.590 --> 00:38:29.949
as a species to understand that A I is

773
00:38:29.959 --> 00:38:32.639
inherently not neutral, that we have to rush out

774
00:38:32.649 --> 00:38:36.209
to brand it as trustworthy or responsible because people

775
00:38:36.219 --> 00:38:38.899
are terrified. And there's, you know, there's a reason

776
00:38:38.909 --> 00:38:41.239
for that. There are some really scary uses, you

777
00:38:41.250 --> 00:38:43.739
could put this technology to. So you need to

778
00:38:43.750 --> 00:38:45.419
reassure people up front that, you know, we're just

779
00:38:45.429 --> 00:38:48.379
using it for I don't know, whatever it is.

780
00:38:48.389 --> 00:38:50.050
People want to be using it for, uh, it

781
00:38:50.060 --> 00:38:52.419
seems to me again, largely for advertising and marketing

782
00:38:52.429 --> 00:38:54.540
but there's a lot more, you know, drug discovery

783
00:38:54.550 --> 00:38:57.010
would be a great one. But even then, even

784
00:38:57.020 --> 00:38:59.000
then there could be, we could discover some really

785
00:38:59.010 --> 00:39:00.520
trippy stuff with that and it's gonna be, you

786
00:39:00.530 --> 00:39:02.310
know, what do we do with it? What do

787
00:39:02.320 --> 00:39:04.510
we do with that knowledge? You can't unknow something

788
00:39:04.520 --> 00:39:06.939
once you know it. Mhm.

789
00:39:07.620 --> 00:39:11.590
Yeah. Uh, BUT I mean, uh, explain a little

790
00:39:11.600 --> 00:39:16.229
bit better why in certain instances, technology A I

791
00:39:16.239 --> 00:39:20.469
systems, for example, can be biased. I mean, they

792
00:39:20.479 --> 00:39:24.500
can have, for example, sexual racial bias or biases

793
00:39:24.510 --> 00:39:28.040
of any other kind because there are people that,

794
00:39:28.360 --> 00:39:33.100
uh, particularly when it comes, for example, to how

795
00:39:33.110 --> 00:39:37.899
certain police departments in the US use systems to,

796
00:39:38.199 --> 00:39:42.919
uh, fight against crime, I guess in that way.

797
00:39:43.199 --> 00:39:47.399
And, uh, pe people, uh, just rely on the

798
00:39:47.409 --> 00:39:50.429
data, those systems generate and they say, oh, you're

799
00:39:50.439 --> 00:39:53.149
just feeding them data and they are processing the

800
00:39:53.159 --> 00:39:57.459
data and then they help, uh, the police. Uh,

801
00:39:57.469 --> 00:40:01.060
uh, I, I mean, when it comes to, uh,

802
00:40:01.070 --> 00:40:04.330
they have limited resources and they have in terms

803
00:40:04.340 --> 00:40:06.739
of when, when it comes for them to decide

804
00:40:06.919 --> 00:40:10.429
which particular areas they should police more or less.

805
00:40:10.439 --> 00:40:14.649
So it's not biased at all. It's just, uh,

806
00:40:14.899 --> 00:40:19.469
computer processing data. But I, I mean, that's not

807
00:40:19.479 --> 00:40:21.290
really the case. Oh,

808
00:40:21.300 --> 00:40:24.300
no. I mean, it's totally biased. It is completely

809
00:40:24.310 --> 00:40:26.909
biased and like that's the tricky thing. So you're

810
00:40:26.919 --> 00:40:29.939
right to highlight things like facial recognition technology because

811
00:40:29.949 --> 00:40:32.020
that's going to be regulated under the EU A

812
00:40:32.070 --> 00:40:34.840
I Act. And this whole question of, can you

813
00:40:34.850 --> 00:40:39.219
just have real time identity surveillance? Right. So people

814
00:40:39.229 --> 00:40:41.010
walking around like you see in the movies and

815
00:40:41.060 --> 00:40:42.310
you and I'd be walking down the street in

816
00:40:42.320 --> 00:40:44.169
a little square with a pair above our head

817
00:40:44.179 --> 00:40:47.189
and it would be like, Stephanie her, you know,

818
00:40:47.290 --> 00:40:49.719
Ricardo Lopez are walking down the street going into

819
00:40:49.729 --> 00:40:51.229
a coffee shop and they would have like our

820
00:40:51.239 --> 00:40:53.429
height and our weight and our eye color, but

821
00:40:53.439 --> 00:40:55.580
potentially more, you know how we voted in our

822
00:40:55.590 --> 00:40:57.340
last election, whether or not one of us has

823
00:40:57.350 --> 00:41:00.479
credit cards and um you know, pick your, pick

824
00:41:00.489 --> 00:41:03.669
your, your fantasy information profile about yourself or your

825
00:41:03.679 --> 00:41:08.419
nightmare all about your political, you know, our sexuality,

826
00:41:08.429 --> 00:41:11.250
uh you know, last last pornography was looked at

827
00:41:11.260 --> 00:41:13.639
yesterday, right? Because all that stuff is being tracked,

828
00:41:13.649 --> 00:41:17.290
all of it's being track. Um So yes, that

829
00:41:17.300 --> 00:41:19.699
exists, it's there. The eu is looking to take

830
00:41:19.709 --> 00:41:21.750
a position not to do that. We use it

831
00:41:21.760 --> 00:41:23.570
here in the United Kingdom where I'm talking to

832
00:41:23.580 --> 00:41:26.760
you from the London Metropolitan Police loves facial recognition

833
00:41:26.770 --> 00:41:29.530
technology um for reasons that are really bewildering because

834
00:41:29.540 --> 00:41:31.399
it doesn't seem to improve their performance at all,

835
00:41:31.409 --> 00:41:35.290
but they insist on using it. Um Despite parliament

836
00:41:35.300 --> 00:41:38.110
asking them repeatedly not to. But that's what happens

837
00:41:38.120 --> 00:41:40.679
when you don't pass laws making something, you know,

838
00:41:40.689 --> 00:41:43.600
banned or controlling it. You just go, please don't

839
00:41:43.610 --> 00:41:45.459
do it and the police just ignore it. In

840
00:41:45.469 --> 00:41:48.290
the US. We've done a really different approach with

841
00:41:48.300 --> 00:41:51.379
that, which is that certain cities or towns or

842
00:41:51.389 --> 00:41:56.610
states have put into law rules about using it

843
00:41:56.620 --> 00:41:58.909
or not using it and who can use it?

844
00:41:58.919 --> 00:42:02.629
Is it the cops or do you also need

845
00:42:02.639 --> 00:42:04.929
to regulate private sector use? Because one thing you

846
00:42:04.939 --> 00:42:06.560
could do is you could ban the police from

847
00:42:06.570 --> 00:42:08.570
using it but allow the private sector to carry

848
00:42:08.580 --> 00:42:11.330
on because remember, we must upset the private sector

849
00:42:11.469 --> 00:42:13.729
in the US. But the problem is the police

850
00:42:13.739 --> 00:42:15.860
can then just work around that and buy the

851
00:42:15.870 --> 00:42:19.530
data or sometimes just get it for free. But

852
00:42:19.540 --> 00:42:20.989
you know why get it for free when someone

853
00:42:21.000 --> 00:42:22.850
can make money off of it. Uh You can

854
00:42:22.860 --> 00:42:25.510
buy the data from a third party data broker

855
00:42:25.820 --> 00:42:29.270
legally. So they're still getting the data and we

856
00:42:29.280 --> 00:42:31.280
see this with Amazon Ring is a great example

857
00:42:31.290 --> 00:42:33.649
of this. Uh PEOPLE putting all those doorbells up

858
00:42:33.659 --> 00:42:36.229
needing, needing to identify everybody have no idea that

859
00:42:36.239 --> 00:42:38.110
that footage can actually just be taken by the

860
00:42:38.120 --> 00:42:40.580
cops with nothing bumping it. So like well done

861
00:42:40.590 --> 00:42:43.209
for participating in a surveillance society in your neighborhood.

862
00:42:43.699 --> 00:42:46.350
Uh It's just, you know, it's just happening. So

863
00:42:47.219 --> 00:42:49.699
that question sounds like well, so what? Nothing to

864
00:42:49.709 --> 00:42:51.840
hide, nothing to fear. Right. Like I'm not doing

865
00:42:51.850 --> 00:42:53.629
anything wrong. I don't care if I'm being observed.

866
00:42:53.639 --> 00:42:54.879
I hear this all the time and it's like,

867
00:42:54.889 --> 00:42:58.590
ok, cool. But the problem is that this technology

868
00:42:59.330 --> 00:43:02.909
tends to perform better on men with lighter skin

869
00:43:03.229 --> 00:43:07.830
and worst on women with darker skin. So we've

870
00:43:07.840 --> 00:43:10.540
had a number of wrongful arrests in the United

871
00:43:10.550 --> 00:43:13.179
States in which the police have used facial recognition

872
00:43:13.189 --> 00:43:15.350
technology to make arrests like as part of their

873
00:43:15.360 --> 00:43:18.949
arrest process and they have misidentified people who were

874
00:43:18.959 --> 00:43:23.030
innocent. So these people get subject to really traumatic

875
00:43:23.040 --> 00:43:25.070
arrests often in front of their family, they might

876
00:43:25.080 --> 00:43:27.739
be held in custody for, you know, 36 92

877
00:43:27.750 --> 00:43:31.260
hours, something horrific. Um, AND anybody who hasn't, you

878
00:43:31.270 --> 00:43:32.790
know, who thinks, oh, that's not so bad has

879
00:43:32.800 --> 00:43:35.709
obviously never been in a US police custody situation.

880
00:43:35.719 --> 00:43:39.320
It's not, not something you would do voluntarily. Um,

881
00:43:39.330 --> 00:43:41.469
NO disrespect to law enforcement. It's just, it's not,

882
00:43:41.479 --> 00:43:43.320
it's not nice to be treated as a suspected

883
00:43:43.330 --> 00:43:48.139
criminal and particularly if you're innocent. And then there's

884
00:43:48.149 --> 00:43:51.179
also the problem that there's no legal requirement in

885
00:43:51.189 --> 00:43:53.500
the United States when you are, you know, when

886
00:43:53.510 --> 00:43:57.040
you've been arrested and brought to trial, you don't

887
00:43:57.050 --> 00:43:59.639
have to be told there's no requirement to protect

888
00:43:59.649 --> 00:44:03.419
you telling you that facial recognition was used in

889
00:44:03.429 --> 00:44:08.530
your arrest, which is really problematic for technology that

890
00:44:08.540 --> 00:44:13.060
doesn't work very well. So that all of that

891
00:44:13.070 --> 00:44:15.310
is really bad, but then people will go. Ok,

892
00:44:15.320 --> 00:44:16.820
cool. So what we have to do to fix

893
00:44:16.830 --> 00:44:20.080
all of those, you know, acknowledge risks. It's really

894
00:44:20.090 --> 00:44:23.020
bad. Let's just pump it full of more data.

895
00:44:23.030 --> 00:44:26.590
Refine, refine, refine and get to a tool that

896
00:44:26.600 --> 00:44:28.500
works. It's never going to work 100% of the

897
00:44:28.510 --> 00:44:33.010
time, but like with high degree of accuracy, 99%

898
00:44:33.020 --> 00:44:35.120
of accuracy. So you're like, all right, if you

899
00:44:35.129 --> 00:44:39.280
solve the accuracy problem, have you solved the problem

900
00:44:39.290 --> 00:44:43.070
of facial recognition? I personally have argued that you

901
00:44:43.080 --> 00:44:47.510
do not why? Because now you've got your cameras

902
00:44:47.520 --> 00:44:51.649
that apparently are pretty accurate everywhere because and we've

903
00:44:51.659 --> 00:44:53.810
seen this um in the US is a great

904
00:44:53.820 --> 00:44:55.560
case in point. It isn't just the cops who

905
00:44:55.570 --> 00:44:57.399
want it. People are like, well, I I don't

906
00:44:57.409 --> 00:45:00.239
feel very confident we've got high gun crime in

907
00:45:00.250 --> 00:45:03.899
the United States or we're in schools or fill

908
00:45:03.909 --> 00:45:06.699
in the blank, whatever your personal security concerns are,

909
00:45:06.929 --> 00:45:08.629
I'm going to get a camera and put it

910
00:45:08.639 --> 00:45:11.929
everywhere. So now imagine a United States in which

911
00:45:12.159 --> 00:45:15.550
private individuals have cameras in their homes. Every business

912
00:45:15.560 --> 00:45:17.750
has cameras, cities get in on the act because

913
00:45:17.760 --> 00:45:18.889
like we got, you know, we'll do this to

914
00:45:18.899 --> 00:45:22.629
fight crime and you now have it where people

915
00:45:22.639 --> 00:45:27.290
are being surveyed nonstop. You would actually have to

916
00:45:27.300 --> 00:45:29.010
almost flip it and say, where are they not

917
00:45:29.020 --> 00:45:32.229
being surveyed? Right? And where is that data not

918
00:45:32.239 --> 00:45:36.909
being kept recorded? Traded? You know who owns the

919
00:45:36.919 --> 00:45:38.620
cameras. So here in the UK, we have a

920
00:45:38.629 --> 00:45:40.830
problem that a lot of the CCTV cameras that

921
00:45:40.840 --> 00:45:43.449
we have all over this country are very awkwardly

922
00:45:43.459 --> 00:45:46.909
sourced from China. And so a big campaign has

923
00:45:46.919 --> 00:45:49.439
gone to rip them out uh because this is

924
00:45:49.449 --> 00:45:52.370
now finally, finally being deemed to be a security

925
00:45:52.379 --> 00:45:55.300
risk. And then the question becomes ok. So is

926
00:45:55.310 --> 00:45:58.020
it the fact that the camera is made by

927
00:45:58.030 --> 00:46:00.379
a Chinese company? Is that the security risk or

928
00:46:00.389 --> 00:46:02.810
is the act of having these cameras up at

929
00:46:02.820 --> 00:46:05.780
all a security risk? Like, would you feel more

930
00:46:05.790 --> 00:46:07.699
comfortable if the camera making it was a British

931
00:46:07.709 --> 00:46:11.590
company? Right? And I think a lot of people

932
00:46:11.600 --> 00:46:14.110
to be completely frank would they would be fine

933
00:46:14.120 --> 00:46:16.459
with that. Um For them, the issue is, it's

934
00:46:16.469 --> 00:46:19.760
a, it's a known hostile power. I mean, China

935
00:46:19.770 --> 00:46:21.580
has been identified as a great one of the

936
00:46:21.590 --> 00:46:24.949
national security risks to the UK. So you get

937
00:46:24.959 --> 00:46:27.899
into these situations where you can just tell nobody

938
00:46:27.909 --> 00:46:31.840
thought this through because, and you always have to

939
00:46:31.850 --> 00:46:33.850
do this. And again, this is like my historian

940
00:46:33.860 --> 00:46:37.340
training, you have to always imagine whatever system you're

941
00:46:37.350 --> 00:46:45.250
building in your peaceful, liberal democratic happy country being

942
00:46:45.310 --> 00:46:49.750
weaponized if somebody gets elected, who is awful. Now,

943
00:46:49.760 --> 00:46:51.629
the classic example would be like, what if Hitler

944
00:46:51.639 --> 00:46:53.209
had all of this tech, right? But you know,

945
00:46:53.219 --> 00:46:55.610
let's not give that man any more um time

946
00:46:55.620 --> 00:46:58.199
and attention that he's already had. You don't have

947
00:46:58.209 --> 00:46:59.679
to go back to World War Two to look

948
00:46:59.689 --> 00:47:03.620
at examples of countries that have become increasingly um

949
00:47:03.629 --> 00:47:06.189
how can we say this, you know, cracking down

950
00:47:06.199 --> 00:47:09.570
on women's reproductive rights that happened in the United

951
00:47:09.580 --> 00:47:11.459
States right now, right? Like we don't, we don't

952
00:47:11.469 --> 00:47:12.429
have to go to World War Two. We can

953
00:47:12.439 --> 00:47:15.379
literally just open the newspaper today and see that

954
00:47:15.389 --> 00:47:17.639
women who need to get abortions or to go

955
00:47:17.649 --> 00:47:19.979
to an abortion clinic or a reproductive clinic simply

956
00:47:19.989 --> 00:47:23.199
to get health advice are now being criminalized in

957
00:47:23.209 --> 00:47:25.919
several US states. As are the people that help

958
00:47:25.929 --> 00:47:30.219
them, their friends, their mothers, whatever. And that was

959
00:47:30.229 --> 00:47:32.520
something that has always been a threat. But then

960
00:47:32.530 --> 00:47:34.899
I think most people, if you had said before,

961
00:47:34.909 --> 00:47:40.179
Roe versus Wade was, was challenged um successfully. If

962
00:47:40.189 --> 00:47:41.959
you had told them this could be a risk,

963
00:47:41.969 --> 00:47:43.260
they would have looked at you like you were

964
00:47:43.360 --> 00:47:47.820
some crazy feminist. Well, here you are crazy feminist.

965
00:47:47.830 --> 00:47:52.060
It's happened, it's happened. And so you've got your

966
00:47:52.070 --> 00:47:54.939
phone data, all of your internet data, right? So

967
00:47:54.949 --> 00:47:58.120
Facebook has had problems. Meta has had problems because

968
00:47:58.129 --> 00:48:01.020
they've been handing over data to cops, to arrest

969
00:48:01.030 --> 00:48:03.820
women who need to go and get an abortion.

970
00:48:04.379 --> 00:48:06.570
And if you had told somebody that when Facebook

971
00:48:06.580 --> 00:48:08.590
came on the scene in the mid two thousands,

972
00:48:08.600 --> 00:48:10.439
they would not have believed you. I'm sure that

973
00:48:10.449 --> 00:48:13.620
Mark Zuckerberg and his designing crew never thought that

974
00:48:13.629 --> 00:48:15.860
that would be a risk because no one imagined

975
00:48:15.929 --> 00:48:19.280
the US political context changing in that way. You

976
00:48:19.290 --> 00:48:23.610
can imagine it with the Lbgtqi A plus community

977
00:48:23.620 --> 00:48:26.709
which again is constantly under threat, not just in

978
00:48:26.719 --> 00:48:29.699
the US, but like everywhere, in terms of their

979
00:48:29.709 --> 00:48:32.800
right to get married, their right to adopt, um

980
00:48:32.810 --> 00:48:34.830
just their right to not be like harassed and

981
00:48:34.840 --> 00:48:38.300
persecuted on the street. You are now going to

982
00:48:38.310 --> 00:48:41.139
have all of this surveillance equipment that potentially can

983
00:48:41.149 --> 00:48:44.520
be put in the hands of a democratically elected

984
00:48:44.530 --> 00:48:48.010
government that is bad, right? And bad in the

985
00:48:48.020 --> 00:48:50.429
sense of like would prosecute them, persecute them. And

986
00:48:50.439 --> 00:48:51.979
that's, you know, that's my view. That's bad. I

987
00:48:51.989 --> 00:48:53.550
know there's people that would disagree with that and

988
00:48:53.560 --> 00:48:54.159
I don't care.

989
00:48:54.419 --> 00:48:57.169
I bet, I bet that the Center in Florida

990
00:48:57.300 --> 00:48:59.110
would love that. Yeah.

991
00:48:59.219 --> 00:49:01.610
No, they absolutely would love it. They would love

992
00:49:01.620 --> 00:49:03.949
it. So, like, you just, you have to design

993
00:49:03.959 --> 00:49:06.840
for that in mind and that's where like sci

994
00:49:06.850 --> 00:49:11.169
fi training and like a very good, healthy uh

995
00:49:11.179 --> 00:49:14.800
background in literature and cinema can be really helpful

996
00:49:14.810 --> 00:49:19.550
because it helps you to imagine scenarios that will

997
00:49:19.560 --> 00:49:22.540
seem crazy at the time and be like, yeah,

998
00:49:22.550 --> 00:49:25.860
but what if, how many steps away or again,

999
00:49:25.870 --> 00:49:27.120
like, and that's why one of the chapters in

1000
00:49:27.129 --> 00:49:28.280
my book is, where do you draw the line?

1001
00:49:28.439 --> 00:49:31.580
I'm like, how many steps do you have before

1002
00:49:31.590 --> 00:49:36.669
your liberal democracy turns into like fascism or simply

1003
00:49:36.679 --> 00:49:42.120
authoritarianism? Or like a Christian theocracy or whatever, it

1004
00:49:42.129 --> 00:49:43.030
doesn't have to be Christian. It could be any

1005
00:49:43.040 --> 00:49:47.129
religion. But like that matters and those rights that

1006
00:49:47.139 --> 00:49:50.010
we have in so many liberal democracies are so

1007
00:49:50.340 --> 00:49:52.929
precious and they have been so fought and hard

1008
00:49:52.939 --> 00:49:56.149
won and they're also so easily taken away. And

1009
00:49:56.159 --> 00:49:57.899
that's where you must know your history because if

1010
00:49:57.909 --> 00:50:00.080
you don't know history, someone will say, yeah. But

1011
00:50:00.090 --> 00:50:02.000
you know, you're just worrying about nothing and you

1012
00:50:02.010 --> 00:50:04.060
need to be able to go. No, this has

1013
00:50:04.070 --> 00:50:06.840
already happened or it happened in this way. And

1014
00:50:06.850 --> 00:50:09.800
actually here in this case, we're only, you know,

1015
00:50:09.810 --> 00:50:11.449
it would only take two or three steps for

1016
00:50:11.459 --> 00:50:14.199
us to enter that world. So how do I

1017
00:50:14.209 --> 00:50:17.080
design for that? I mean, a really good strategist

1018
00:50:17.510 --> 00:50:22.479
and a really good technology designer, technology ethicist can't

1019
00:50:22.489 --> 00:50:27.040
simply rely on a technological background. You must have

1020
00:50:27.300 --> 00:50:30.070
the social sciences and you know, liberal arts and

1021
00:50:30.080 --> 00:50:32.649
humanities training as well. I think it's one of

1022
00:50:32.659 --> 00:50:35.110
the toughest jobs to do actually. And that's no

1023
00:50:35.120 --> 00:50:38.840
disrespect to engineering colleagues or more sort of classically

1024
00:50:38.850 --> 00:50:43.159
trained stem colleagues. Their, their work is also extremely

1025
00:50:43.169 --> 00:50:47.419
challenging and difficult. But there there's something especially hard

1026
00:50:47.429 --> 00:50:52.750
about the human component, right? People don't use things

1027
00:50:52.760 --> 00:50:55.020
that necessarily the way they were intended or they

1028
00:50:55.030 --> 00:50:57.989
modify them because again, it's just in our nature.

1029
00:50:58.399 --> 00:51:02.100
So you have to always design with the worst

1030
00:51:02.110 --> 00:51:04.500
in mind. And that means you have to have

1031
00:51:05.350 --> 00:51:09.070
incredible knowledge and a really good imagination and like

1032
00:51:09.080 --> 00:51:15.040
a humility to think about your own blind spots,

1033
00:51:16.189 --> 00:51:18.969
right? Which is why you don't want monocultural teams.

1034
00:51:19.149 --> 00:51:22.060
You have to have people with really different experiences

1035
00:51:22.070 --> 00:51:24.679
and those different views have to be really respected

1036
00:51:25.010 --> 00:51:29.100
because those people will help you see risk that

1037
00:51:29.110 --> 00:51:31.419
you would just miss you. You won't hear it,

1038
00:51:31.429 --> 00:51:33.320
you won't see it. You need somebody else who's

1039
00:51:33.330 --> 00:51:35.479
like, I know what this is like because I

1040
00:51:35.489 --> 00:51:38.370
am of this community or I'm from this country

1041
00:51:38.379 --> 00:51:40.770
and I saw this or my, my country lived

1042
00:51:40.780 --> 00:51:46.300
through this. Um That's, that's a tough one.

1043
00:51:47.010 --> 00:51:50.780
But uh you mentioned uh sci-fi there. Uh And

1044
00:51:50.790 --> 00:51:53.790
I mean, I, I understand all of your arguments

1045
00:51:53.800 --> 00:51:57.050
but II, I have to say that at least

1046
00:51:57.060 --> 00:52:00.709
to some extent and unless I'm un I'm misunderstanding

1047
00:52:00.719 --> 00:52:04.020
what you're saying there about sci fi, I might

1048
00:52:04.030 --> 00:52:09.189
have some issue with people uh real uh looking

1049
00:52:09.199 --> 00:52:12.169
into or relying on. I don't know, something that

1050
00:52:12.179 --> 00:52:15.649
is portrayed in a sci fi movie or sci

1051
00:52:15.669 --> 00:52:20.429
fi book when it comes to uh worrying about

1052
00:52:20.439 --> 00:52:24.939
the potential dangers of technology A I or something

1053
00:52:24.949 --> 00:52:30.050
like that. Because um I mean, for example, if

1054
00:52:30.060 --> 00:52:33.100
you think that uh the things you should be

1055
00:52:33.110 --> 00:52:37.379
worried about are I don't know, a terminator like

1056
00:52:37.389 --> 00:52:43.600
scenarios or West world like scenarios where technology suddenly

1057
00:52:43.610 --> 00:52:48.610
becomes sentient and develops their own uh motives and

1058
00:52:48.620 --> 00:52:51.500
goals and all of that and suddenly wants to

1059
00:52:51.510 --> 00:52:55.709
wipe out humanity or perhaps, uh, the next day

1060
00:52:55.719 --> 00:52:59.889
we have to be worried about, uh, mistreating, uh

1061
00:52:59.899 --> 00:53:02.989
A I systems because they might be sentient and

1062
00:53:03.000 --> 00:53:06.389
all of that. I mean, I just worry that,

1063
00:53:06.729 --> 00:53:11.719
uh, if people take those kinds of scenarios too

1064
00:53:11.729 --> 00:53:16.570
seriously, they might distract, that might help distract them

1065
00:53:16.580 --> 00:53:22.520
from the actual more realistic issues that might derive

1066
00:53:22.530 --> 00:53:26.129
from technology. You know? I mean, do you understand

1067
00:53:26.139 --> 00:53:27.820
what I'm worried about here? I

1068
00:53:27.830 --> 00:53:30.120
completely understand it. And that's been a concern that

1069
00:53:30.129 --> 00:53:31.699
a lot of people have raised in the past

1070
00:53:31.709 --> 00:53:33.709
couple of months ever since people started writing those

1071
00:53:33.719 --> 00:53:35.679
letters saying we should have a pause and A

1072
00:53:35.689 --> 00:53:38.959
I research and warning of the different risks that

1073
00:53:38.969 --> 00:53:42.570
it presents on an existential societal level. And that

1074
00:53:42.580 --> 00:53:45.570
group of people who are worried about existential risks

1075
00:53:45.580 --> 00:53:50.229
of A I have been accused of worried about

1076
00:53:50.239 --> 00:53:53.330
something that may never happen because it's not really

1077
00:53:53.340 --> 00:53:55.100
a I that they're worried about, they're worried about

1078
00:53:55.110 --> 00:53:59.679
artificial general intelligence, which is a different beast in

1079
00:53:59.689 --> 00:54:02.570
the sense that that's, that's the moment that again,

1080
00:54:02.580 --> 00:54:05.080
it's hypothetical, it has not happened and it may

1081
00:54:05.090 --> 00:54:08.100
never happen. But in theory, it's the moment when

1082
00:54:08.370 --> 00:54:12.500
smart machines become smarter than human beings. I love

1083
00:54:12.510 --> 00:54:14.330
how I said that and the dog just that's

1084
00:54:14.340 --> 00:54:18.179
hilarious. The robot dog, um smart machines, when, when

1085
00:54:18.189 --> 00:54:21.419
these machines become more intelligent than us as a

1086
00:54:21.429 --> 00:54:23.320
species and like, what would they do to us

1087
00:54:23.560 --> 00:54:26.260
is the big fear and there is a concern

1088
00:54:26.270 --> 00:54:28.350
that that's distracting from what I guess you could

1089
00:54:28.360 --> 00:54:32.469
call now. Risks, risks you could have now, risks

1090
00:54:32.479 --> 00:54:33.189
or

1091
00:54:33.199 --> 00:54:34.830
even near future

1092
00:54:35.520 --> 00:54:38.280
quite of, you know, it's either it's happening now

1093
00:54:38.290 --> 00:54:40.550
and here is, you know, the risk of discrimination

1094
00:54:40.560 --> 00:54:42.510
in like how A I is used in healthcare,

1095
00:54:42.520 --> 00:54:44.310
how A I is used in the medical or

1096
00:54:44.320 --> 00:54:47.719
sorry, the legal profession or risks of misinformation and

1097
00:54:47.729 --> 00:54:50.729
disinformation in terms of elections and journalism and like

1098
00:54:50.739 --> 00:54:53.989
public confidence in the integrity of how the the

1099
00:54:54.000 --> 00:54:56.689
citizen state relationship works. That's

1100
00:54:56.699 --> 00:55:00.550
all happening or selling your online data, for example,

1101
00:55:00.669 --> 00:55:03.050
selling your online data, gathering your data. I mean,

1102
00:55:03.060 --> 00:55:05.129
like literally a month doesn't go by when meta

1103
00:55:05.139 --> 00:55:07.679
isn't being fined for some sort of data violation

1104
00:55:07.689 --> 00:55:09.060
and they just, you know, they just price it

1105
00:55:09.070 --> 00:55:12.280
in and everybody is there. It's incredible to me,

1106
00:55:12.290 --> 00:55:15.679
but they do. Um So that's all happening now

1107
00:55:15.689 --> 00:55:17.830
and then you're right to identify like near term

1108
00:55:17.840 --> 00:55:19.429
risks, which is like we're not quite there as

1109
00:55:19.439 --> 00:55:20.070
a risk.

1110
00:55:21.159 --> 00:55:23.239
Perhaps a good example, perhaps a good example of

1111
00:55:23.250 --> 00:55:27.080
that would be certain genetic engineering technologies. I mean,

1112
00:55:27.090 --> 00:55:31.620
we're not really there yet, but it's probably in

1113
00:55:31.629 --> 00:55:32.899
the near future. So

1114
00:55:33.949 --> 00:55:35.739
yeah, you could come up with, I'm sure a

1115
00:55:35.750 --> 00:55:38.570
number of different categories to kind of like, you

1116
00:55:38.580 --> 00:55:41.110
know, make columns if you will. So definitely need

1117
00:55:41.120 --> 00:55:42.929
to worry about this now because it's already happening

1118
00:55:43.159 --> 00:55:45.689
likely to happen soon, but we're not there yet.

1119
00:55:45.699 --> 00:55:47.409
And here's the conditions that we would have to

1120
00:55:47.419 --> 00:55:51.000
fulfill to get there versus like may never happen.

1121
00:55:51.010 --> 00:55:53.780
But if they did call them low probability, high

1122
00:55:53.790 --> 00:55:59.060
impact events, um egag I takes over um and

1123
00:55:59.070 --> 00:56:00.209
what will they do to us and turn us

1124
00:56:00.219 --> 00:56:04.679
into slaves or something? So, you know, is that

1125
00:56:04.689 --> 00:56:08.199
distracting is your question? I think, I don't know.

1126
00:56:08.209 --> 00:56:09.449
First of all, I don't think that you're going

1127
00:56:09.459 --> 00:56:11.209
to get, I don't think it's like helpful to

1128
00:56:11.219 --> 00:56:12.929
tell people not to think about something because they're

1129
00:56:12.939 --> 00:56:14.320
going to think about it. It's like, you know,

1130
00:56:14.330 --> 00:56:16.669
that, that experiment of don't think of the white

1131
00:56:16.679 --> 00:56:18.469
polar bear. You know, as I'm telling you to

1132
00:56:18.479 --> 00:56:19.969
do this, your brain is like all I can

1133
00:56:19.979 --> 00:56:21.919
think of is a white polar bear. So I

1134
00:56:21.929 --> 00:56:24.800
think, I think first of all, it's actually probably

1135
00:56:24.810 --> 00:56:27.370
I'm not the cognitive psychologist, but my guess would

1136
00:56:27.379 --> 00:56:29.929
be the easiest thing to do is actually to

1137
00:56:29.939 --> 00:56:32.790
name it. Like do what we just did be

1138
00:56:32.800 --> 00:56:34.939
like, there's these different types of risks. The one

1139
00:56:34.949 --> 00:56:37.000
that the media really loves to go for is

1140
00:56:37.010 --> 00:56:39.409
the one that's actually the least likely why do

1141
00:56:39.419 --> 00:56:41.510
they like to go for it? Because it's great

1142
00:56:41.520 --> 00:56:45.310
storytelling. We've actually, we've literally seen this movie before.

1143
00:56:45.320 --> 00:56:47.399
So I talk with clients a lot and I've

1144
00:56:47.409 --> 00:56:49.050
got a presentation that I've been using the past

1145
00:56:49.060 --> 00:56:51.409
couple of months that it is really like driven

1146
00:56:51.419 --> 00:56:53.830
people wild in a good way that is looking

1147
00:56:53.840 --> 00:56:56.520
at cinema and we talk about the different ways

1148
00:56:56.530 --> 00:56:59.590
that A I appears in cinema over time and

1149
00:56:59.600 --> 00:57:03.419
it's so effective because you have, you can't have

1150
00:57:03.429 --> 00:57:05.810
a conversation about A I without naming Terminator, you

1151
00:57:05.820 --> 00:57:07.949
just can't. So I make it the first slide.

1152
00:57:07.959 --> 00:57:11.449
I'm like, let's, let's name it, let's dismantle it

1153
00:57:11.459 --> 00:57:13.600
and deconstruct it like a bomb, you know, take

1154
00:57:13.610 --> 00:57:15.870
it apart and neutralize it if you will and

1155
00:57:15.879 --> 00:57:17.939
then talk about why it's so resonant. Everybody has

1156
00:57:17.949 --> 00:57:19.199
a really good laugh and this kind of like

1157
00:57:19.209 --> 00:57:21.030
looks around like, you know, I'm not the only

1158
00:57:21.040 --> 00:57:23.169
one who thinks about Terminator. No, we all think

1159
00:57:23.179 --> 00:57:26.189
about Terminator. Why is that? And then you move

1160
00:57:26.199 --> 00:57:28.159
on, you would maybe talk about the matrix, you

1161
00:57:28.169 --> 00:57:32.179
might talk about Blade Runner. Um You can talk

1162
00:57:32.189 --> 00:57:34.050
about Westworld, you could talk about black mirror, right?

1163
00:57:34.060 --> 00:57:35.550
So you go through all the different things that

1164
00:57:35.560 --> 00:57:38.050
are in popular culture and you also look at

1165
00:57:38.060 --> 00:57:40.860
the imagery, right? So it's not just the story,

1166
00:57:41.080 --> 00:57:43.739
it's the picture. So like the Terminator, what's quite

1167
00:57:43.750 --> 00:57:47.159
terrifying about the Terminator is he's both human. Uh

1168
00:57:47.169 --> 00:57:50.159
ALTHOUGH he's like a superman, she's, it's Arnold Schwarzenegger,

1169
00:57:50.520 --> 00:57:52.669
but he's also when he like rips off all

1170
00:57:52.679 --> 00:57:55.510
of his fleshy bits. He is made the designer

1171
00:57:55.520 --> 00:57:57.679
who is very cleverly in the movie, made it

1172
00:57:57.689 --> 00:58:01.780
to look like a human technological skeleton. So it's

1173
00:58:01.790 --> 00:58:04.090
like a metal head. It's literally a metal skull

1174
00:58:04.100 --> 00:58:06.290
and it has teeth, like it has actual human

1175
00:58:06.300 --> 00:58:07.810
teeth and you're like, why, like, why does it

1176
00:58:07.820 --> 00:58:09.489
need human teeth? It's a robot. It does not

1177
00:58:09.500 --> 00:58:12.110
need. So what is that about? And the reason

1178
00:58:12.120 --> 00:58:14.959
is because it's terrifying, right? It's really scary. If

1179
00:58:14.969 --> 00:58:16.070
you saw that when you were a kid, you

1180
00:58:16.080 --> 00:58:18.169
were like unable to not ever see it again.

1181
00:58:18.860 --> 00:58:20.679
So you have to think about why that is

1182
00:58:20.689 --> 00:58:22.689
or like the image of um like a human

1183
00:58:22.699 --> 00:58:24.649
hand kind of going like that to another human

1184
00:58:24.659 --> 00:58:28.659
hand. And it's, it's, it's riffing off of Michelangelo's

1185
00:58:28.669 --> 00:58:32.379
Sistine chapel, right of God touching Adam and giving

1186
00:58:32.389 --> 00:58:35.629
the spark of life. And you'll see that, that

1187
00:58:35.639 --> 00:58:37.790
image a lot when we talk about A I

1188
00:58:37.800 --> 00:58:41.929
because it's a really useful shorthand visually for us

1189
00:58:41.939 --> 00:58:45.669
to think about, you know, God God, something that

1190
00:58:45.679 --> 00:58:48.060
people call like God in the judeo-christian sense with

1191
00:58:48.070 --> 00:58:51.919
that picture created humans. And so then they'll riff

1192
00:58:51.929 --> 00:58:53.540
on it and you'll see another image of a

1193
00:58:53.550 --> 00:58:57.250
human hand touching a robot finger, right? Like it's

1194
00:58:57.260 --> 00:59:00.080
going like that. And then in this case, humans

1195
00:59:00.090 --> 00:59:03.840
have become God and the robot is our creation.

1196
00:59:03.850 --> 00:59:06.320
And that taps into one of the best science

1197
00:59:06.330 --> 00:59:08.610
fiction films of all time or movies or books

1198
00:59:08.620 --> 00:59:10.030
around of all time, which is of course, Mary

1199
00:59:10.159 --> 00:59:12.840
Shelley's Frankenstein, like this idea that you can, you

1200
00:59:12.850 --> 00:59:14.379
can create it and then it goes rogue and

1201
00:59:14.389 --> 00:59:17.479
it's a fascinating piece of literature uh that I

1202
00:59:17.489 --> 00:59:22.060
think captured something in, again humans because we create

1203
00:59:22.070 --> 00:59:23.860
things all the time and it's this sort of

1204
00:59:23.870 --> 00:59:26.020
primal fear of what happens when our creations come

1205
00:59:26.030 --> 00:59:28.500
back and like kill us, which probably actually is

1206
00:59:28.510 --> 00:59:32.270
about like parents with their Children, right? Like it's

1207
00:59:32.280 --> 00:59:34.169
in a really demented way. But I'm talking, I'm

1208
00:59:34.179 --> 00:59:37.570
talking subconscious stuff, right? Stuff that works across all

1209
00:59:37.580 --> 00:59:41.060
societies that there's that fear of your creation getting

1210
00:59:41.070 --> 00:59:43.870
out of control because that, that's a narrative that

1211
00:59:43.879 --> 00:59:48.050
we know we recognize it uh across time. So

1212
00:59:48.060 --> 00:59:50.919
you have to, I think you actually, it's a

1213
00:59:50.929 --> 00:59:53.550
wasted amount of energy to tell people don't think

1214
00:59:53.560 --> 00:59:56.379
about these things. It's distracting. I think it's actually

1215
00:59:56.389 --> 00:59:59.040
more effective to think about it right up front.

1216
00:59:59.120 --> 01:00:03.219
Name it have a chat together, build everybody's critical

1217
01:00:03.229 --> 01:00:05.560
thinking and images on the news. Whenever you talk

1218
01:00:05.570 --> 01:00:07.459
about A I, I do a lot of work

1219
01:00:07.469 --> 01:00:09.149
with the media. When I go on television, it

1220
01:00:09.159 --> 01:00:10.570
will be a split screen. It will be me

1221
01:00:10.580 --> 01:00:12.320
talking about A I with a bunch of books

1222
01:00:12.330 --> 01:00:14.590
in the background, hopefully saying intelligent things and then

1223
01:00:14.600 --> 01:00:16.820
the images that they put on the other side

1224
01:00:16.830 --> 01:00:21.080
of the screen to illustrate A I are like

1225
01:00:21.090 --> 01:00:24.850
on drugs, they're like hallucinatory acid trips. It'll be

1226
01:00:24.860 --> 01:00:28.760
like it'll be like a light sort of floating.

1227
01:00:28.770 --> 01:00:30.449
You know, like when people say they, they almost

1228
01:00:30.459 --> 01:00:32.169
die and they have like a near death experience,

1229
01:00:32.179 --> 01:00:34.000
they're in a, they're in a white tunnel going

1230
01:00:34.010 --> 01:00:37.280
towards the light, they'll show something like that, then

1231
01:00:37.290 --> 01:00:40.679
they'll show like a video game graphic of a

1232
01:00:40.689 --> 01:00:44.949
human head from the neck up. That's completely translucent.

1233
01:00:44.959 --> 01:00:46.860
You can see right through it. And inside is

1234
01:00:46.870 --> 01:00:51.000
a human brain glowing orange and it's like rotating

1235
01:00:51.100 --> 01:00:54.120
around and it's like floating on a magic carpet,

1236
01:00:54.129 --> 01:00:56.209
like a video game version of a magic carpet.

1237
01:00:56.219 --> 01:01:00.139
Why? Because I'm assuming it's because they're like, oh

1238
01:01:00.149 --> 01:01:02.500
if we're talking about artificial intelligence, we have to

1239
01:01:02.510 --> 01:01:03.929
show what do we think of intelligence, you think

1240
01:01:03.939 --> 01:01:06.590
of a brain? So we'll show the, we'll show

1241
01:01:06.600 --> 01:01:09.570
the viewers a brain but like a like a

1242
01:01:09.580 --> 01:01:11.330
sci fi version of a brain. It's not like

1243
01:01:11.340 --> 01:01:12.800
an actual brain because an actual brain is a

1244
01:01:12.810 --> 01:01:16.969
bit gross, right? It's sort of the biological wet

1245
01:01:16.979 --> 01:01:21.260
thing. So they show you instead an abstraction of

1246
01:01:21.270 --> 01:01:23.840
a brain and then they might show the finger

1247
01:01:23.850 --> 01:01:26.419
image, right? Like they, they riff on weird stuff

1248
01:01:26.429 --> 01:01:27.959
and once you see this or you'll see like

1249
01:01:27.969 --> 01:01:30.649
lots of zeros and ones raining down, right? Like

1250
01:01:30.659 --> 01:01:33.560
in the matrix. And there's a reason for that.

1251
01:01:33.570 --> 01:01:36.800
They're not, this is not an accident. These things

1252
01:01:36.810 --> 01:01:40.580
are highly iconic images from the films and shows

1253
01:01:40.590 --> 01:01:42.239
that we've all seen. So they become a visual

1254
01:01:42.250 --> 01:01:46.040
shorthand. So you can't, I just think you can't

1255
01:01:46.739 --> 01:01:48.850
ignore this stuff. I think you actually have to

1256
01:01:48.860 --> 01:01:52.370
go right at it straight at it. Discuss it

1257
01:01:52.530 --> 01:01:55.649
and then you can if you want per it

1258
01:01:56.139 --> 01:01:58.780
and go, let's actually look at the stuff that

1259
01:01:58.790 --> 01:02:02.840
is perhaps less visually sexy, right? Less visually interesting

1260
01:02:02.850 --> 01:02:06.929
to show which is going to be predictive policing

1261
01:02:06.939 --> 01:02:12.840
algorithms, facial recognition, technology discrimination. Um BANKS using A

1262
01:02:12.850 --> 01:02:14.760
I to decide if you can get a mortgage

1263
01:02:14.770 --> 01:02:18.449
or not. Right? Like that, that is less sci-fi

1264
01:02:18.459 --> 01:02:22.239
sexy. It's less scary, but it's actually most people's

1265
01:02:22.729 --> 01:02:28.840
experience of A I. So that's fascinating. Most people

1266
01:02:28.850 --> 01:02:32.100
don't realize how A I is already being used

1267
01:02:32.110 --> 01:02:36.919
on them, right? Like I think they would be

1268
01:02:37.129 --> 01:02:39.310
appalled if they did. So that's, I think the

1269
01:02:39.320 --> 01:02:42.800
media's challenge and the challenge of writers and analysts

1270
01:02:42.810 --> 01:02:44.610
and people are trying to educate the public is

1271
01:02:44.620 --> 01:02:50.820
like you're going to need a visual iconography if

1272
01:02:50.830 --> 01:02:53.010
you will a visual language and you're going to

1273
01:02:53.020 --> 01:02:56.250
need a narrative language for storytelling that makes those

1274
01:02:56.260 --> 01:03:00.899
real risks, risks that are right now as compelling

1275
01:03:02.370 --> 01:03:05.610
as the ones that are more hypothetical, but that

1276
01:03:05.620 --> 01:03:08.110
we've all been seeing in shows and movies for

1277
01:03:08.120 --> 01:03:11.149
decades now. Right? So it's a, again, so many

1278
01:03:11.159 --> 01:03:15.739
things with technology are actually about culture, right? They're

1279
01:03:15.750 --> 01:03:19.040
about the human relationship with technology. So like getting

1280
01:03:19.050 --> 01:03:21.959
people involved and caring about something like A I

1281
01:03:21.969 --> 01:03:23.429
which, you know, we're in a cost of living

1282
01:03:23.439 --> 01:03:25.709
crisis here in the UK, good luck going out

1283
01:03:25.719 --> 01:03:28.110
onto the streets of Brazil. I guess the Portugal

1284
01:03:28.120 --> 01:03:31.419
getting people to care, I guess that across the

1285
01:03:31.429 --> 01:03:34.050
entire room we're living through a cost of living

1286
01:03:34.060 --> 01:03:34.780
crisis.

1287
01:03:34.989 --> 01:03:36.989
Yeah. Right. So, if you're like, you know, do

1288
01:03:37.000 --> 01:03:38.370
you want to have this chat? People are like,

1289
01:03:38.379 --> 01:03:40.780
no, because I'm too busy, like, dealing with massive

1290
01:03:40.790 --> 01:03:44.000
inflation or, like very high interest rates or unemployment

1291
01:03:44.010 --> 01:03:46.000
or climate change, like, you know, half of Europe

1292
01:03:46.010 --> 01:03:48.080
as we were just discussing under a massive heat

1293
01:03:48.090 --> 01:03:52.939
dome and sweltering away. So, getting them to think

1294
01:03:52.949 --> 01:03:54.889
about A I is tricky. So you have to

1295
01:03:54.899 --> 01:03:57.340
help them, you have to make that really easy

1296
01:03:57.350 --> 01:03:59.699
for them to do. And so that's where I

1297
01:03:59.709 --> 01:04:02.550
really enjoy this kind of work because I've noticed

1298
01:04:02.560 --> 01:04:04.139
the effect that it has on people when you

1299
01:04:04.149 --> 01:04:05.909
take them through some of the concepts that we've

1300
01:04:05.919 --> 01:04:08.280
just been discussing is they're like, oh my God,

1301
01:04:08.290 --> 01:04:11.250
I see this everywhere. Now I see those images

1302
01:04:11.260 --> 01:04:14.020
everywhere. I see. The media loves to go to

1303
01:04:14.030 --> 01:04:16.810
some stories and then not to others. Why is

1304
01:04:16.820 --> 01:04:19.300
that? You have to look at their incentive structure.

1305
01:04:19.340 --> 01:04:23.850
What do they get measured on clicks, viewing figures,

1306
01:04:23.879 --> 01:04:26.100
et cetera. So the scarier they can make the

1307
01:04:26.110 --> 01:04:28.830
story. So why any time Elon Musk does everything,

1308
01:04:28.840 --> 01:04:31.899
the media loves it because it's, he's there in

1309
01:04:31.919 --> 01:04:34.530
some sort of symbiotic relationship, right? He says something

1310
01:04:34.540 --> 01:04:36.780
outrageous, they cover it and go, isn't it outrageous?

1311
01:04:36.790 --> 01:04:38.530
He then is like, I hate the press, you

1312
01:04:38.550 --> 01:04:43.479
know, the world weirdest dysfunctional relationship ever. But people

1313
01:04:43.489 --> 01:04:46.250
who are doing like really important work on A

1314
01:04:46.260 --> 01:04:49.570
I are not getting that kind of media coverage,

1315
01:04:50.090 --> 01:04:52.242
right? And they maybe don't talk the way that

1316
01:04:52.312 --> 01:04:54.992
Elon Musk talks, they won't give examples or say

1317
01:04:55.002 --> 01:04:57.482
things that are really outrageous to get attention. If

1318
01:04:57.492 --> 01:05:03.302
you're a really measured, considered scientist or researcher, you're

1319
01:05:03.312 --> 01:05:05.242
not going to say something that's very Clickbait.

1320
01:05:06.183 --> 01:05:08.843
Yeah. And by the way, since you mentioned that,

1321
01:05:08.853 --> 01:05:11.512
let's talk a little bit more about social media

1322
01:05:11.522 --> 01:05:16.183
because it's not only the misinformation issue but also

1323
01:05:16.393 --> 01:05:20.726
in terms of these discussions surrounding the supposed neutrality

1324
01:05:20.736 --> 01:05:23.246
of technology. I mean, if you just look at

1325
01:05:23.256 --> 01:05:27.926
social media, it's ply obvious that there's no neutrality

1326
01:05:27.936 --> 01:05:30.795
there at all because I, I mean, even what

1327
01:05:30.805 --> 01:05:35.476
you get mostly exposed to, it's just what they

1328
01:05:35.486 --> 01:05:40.835
decide to boost to get more views, clicks, likes

1329
01:05:40.845 --> 01:05:45.486
whatever and usually it's the most outrageous stuff out

1330
01:05:45.496 --> 01:05:46.595
there, right?

1331
01:05:48.179 --> 01:05:51.320
And lies. I mean, there's fascinating research about how

1332
01:05:51.330 --> 01:05:55.550
lies spread much faster than facts on the internet

1333
01:05:55.560 --> 01:05:57.469
and like, yeah, now we're in this world where

1334
01:05:57.479 --> 01:06:00.090
so much of it can be faked. Um NOT

1335
01:06:00.100 --> 01:06:03.689
just imagery and video footage but sound audio. So

1336
01:06:03.699 --> 01:06:05.040
you're going to have this thing where people are

1337
01:06:05.050 --> 01:06:06.550
going to find it very, very difficult to know

1338
01:06:06.560 --> 01:06:10.570
what is real and not real. I don't know,

1339
01:06:10.580 --> 01:06:13.030
I sometimes think that we may be approaching if

1340
01:06:13.040 --> 01:06:16.040
not the end of social media, it definitely a

1341
01:06:16.050 --> 01:06:20.750
new phase. Um Are, you know, do people do

1342
01:06:20.760 --> 01:06:23.149
people really want to go online and see their

1343
01:06:23.159 --> 01:06:27.199
friends talking about holidays and babies and lunch, which

1344
01:06:27.209 --> 01:06:29.330
was a lot of how social media was from

1345
01:06:29.340 --> 01:06:32.379
the mid two thousands onward. And now it seems

1346
01:06:32.389 --> 01:06:36.560
to be kind of invaded by content creators, you

1347
01:06:36.570 --> 01:06:38.919
know, influencers and the like, and then if you

1348
01:06:38.929 --> 01:06:40.320
start feeling like, oh my God, if I go

1349
01:06:40.330 --> 01:06:43.540
on, it's actually manipulating me, that's not good either.

1350
01:06:43.550 --> 01:06:45.179
And there's all the mental health research of, you

1351
01:06:45.189 --> 01:06:46.830
know, lots of people who spend time on social

1352
01:06:46.840 --> 01:06:50.330
media end up feeling really depressed or anxious. Um,

1353
01:06:50.449 --> 01:06:52.659
AND it can feel really toxic for many, many

1354
01:06:52.669 --> 01:06:55.399
people just to go on. It could be awful.

1355
01:06:55.409 --> 01:06:59.070
I just wonder, I don't know. I'm, I'm thinking

1356
01:06:59.080 --> 01:07:01.649
aloud here, but I do wonder if there's just

1357
01:07:01.659 --> 01:07:03.340
going to be a bunch of people for whom

1358
01:07:03.770 --> 01:07:06.010
this start to just feel really irrelevant because it's

1359
01:07:06.020 --> 01:07:08.629
kind of like, I don't know the way that

1360
01:07:08.639 --> 01:07:10.889
television, I just came back from the US and

1361
01:07:10.899 --> 01:07:14.949
I'm always just stunned by American television. Now, the

1362
01:07:14.959 --> 01:07:18.360
amount of advertising that you are just bombarded with

1363
01:07:18.370 --> 01:07:19.870
and it's, you know, if you're not used to

1364
01:07:19.879 --> 01:07:21.409
it, if you are in a country where you

1365
01:07:21.419 --> 01:07:23.370
don't have a lot of advertising in your TV,

1366
01:07:23.570 --> 01:07:25.199
you just kind of look at your American family

1367
01:07:25.209 --> 01:07:27.040
and friends and you're like, you're just being like

1368
01:07:27.050 --> 01:07:29.649
brainwashed with all of this all the time and

1369
01:07:29.659 --> 01:07:32.054
that's how social media feels like my Twitter feed

1370
01:07:32.064 --> 01:07:34.435
feed. Since Elon Musk took over, it's just full

1371
01:07:34.475 --> 01:07:34.495
of,

1372
01:07:34.905 --> 01:07:37.544
no, but since you talk about that, about American

1373
01:07:37.554 --> 01:07:40.225
television, let me just tell you that I'm a

1374
01:07:40.235 --> 01:07:44.534
wrestling fan and so I watch wrestling mostly from

1375
01:07:44.544 --> 01:07:47.729
the US, of course, because it's the, the biggest

1376
01:07:47.739 --> 01:07:50.020
place for wrestling in the world. But, uh, I

1377
01:07:50.030 --> 01:07:53.469
mean, I, I really notice that, uh, if you

1378
01:07:53.479 --> 01:07:58.050
watched wrestling, like, 20 years ago you would have

1379
01:07:58.060 --> 01:08:01.879
the matches and then a few breaks with advertisements

1380
01:08:01.889 --> 01:08:04.030
and all of that. But, but now you get

1381
01:08:04.040 --> 01:08:09.300
split screens where there's, uh, uh, a tiny window

1382
01:08:09.310 --> 01:08:13.290
with the match and then next, with the advertisement.

1383
01:08:13.300 --> 01:08:15.739
And I'm like, oh man, I want to watch

1384
01:08:15.750 --> 01:08:19.209
the match. I don't care about pizzas and burgers

1385
01:08:19.220 --> 01:08:20.330
and whatever. Let me change.

1386
01:08:21.120 --> 01:08:22.810
I thought when I go to the cinema and

1387
01:08:22.819 --> 01:08:24.160
it's like, I'm just here to see the movie

1388
01:08:24.169 --> 01:08:25.669
and ideally the previews and I feel like I

1389
01:08:25.680 --> 01:08:27.419
pay quite a lot to go to the cinema

1390
01:08:27.580 --> 01:08:29.290
and then you have to sit through, you know,

1391
01:08:29.299 --> 01:08:31.479
20 minutes of adverts, but then you work it

1392
01:08:31.490 --> 01:08:33.629
out and so you just show up later, right?

1393
01:08:33.640 --> 01:08:35.129
So if you want, there's ways, there's always ways

1394
01:08:35.140 --> 01:08:37.979
of hacking, there's probably some way of like hacking

1395
01:08:37.990 --> 01:08:40.819
your wrestling channel to only see the WS about

1396
01:08:40.919 --> 01:08:43.318
the ads. But I just, I guess I'm just

1397
01:08:43.328 --> 01:08:45.429
saying that I feel like these things evolve and

1398
01:08:45.438 --> 01:08:47.837
like social media for a while clearly had some

1399
01:08:47.849 --> 01:08:50.999
sort of utility. It helps people feel connected clearly.

1400
01:08:51.429 --> 01:08:55.069
But then it started to have, what would you

1401
01:08:55.080 --> 01:08:59.000
call it if it's not utility? I was gonna

1402
01:08:59.009 --> 01:09:02.140
say negative utility. But, you know, again, like, it

1403
01:09:02.149 --> 01:09:04.810
has a cost to it and I guess you're

1404
01:09:04.819 --> 01:09:07.290
constantly weighing up in life. Is the pain worth

1405
01:09:07.299 --> 01:09:09.850
the pleasure. Right. Like, is it, is it full?

1406
01:09:09.859 --> 01:09:11.450
And I just think for a lot of people,

1407
01:09:12.169 --> 01:09:14.370
I mean, I've heard constantly is this the end

1408
01:09:14.379 --> 01:09:16.069
of Twitter? And like, I'm very mixed because I

1409
01:09:16.080 --> 01:09:17.899
use Twitter for instance, for my work quite a

1410
01:09:17.910 --> 01:09:19.419
lot. But part of me was like, maybe the

1411
01:09:19.430 --> 01:09:20.870
best thing that could happen to me is that

1412
01:09:20.879 --> 01:09:25.310
Twitter, like, failed and tried because I'm not on

1413
01:09:25.319 --> 01:09:27.549
other than linkedin, I'm not on any other social

1414
01:09:27.560 --> 01:09:29.839
media channel. I managed to like, break all of

1415
01:09:29.850 --> 01:09:33.600
those addictions and habits from my youth. Um, Twitter

1416
01:09:33.609 --> 01:09:35.569
is like the last holdout and in a way

1417
01:09:35.580 --> 01:09:37.520
it would just do me a huge favor if

1418
01:09:37.529 --> 01:09:39.457
it just wasn't even an option, which is a

1419
01:09:39.469 --> 01:09:42.278
really, that, that's a weird feeling to have. On

1420
01:09:42.288 --> 01:09:43.798
the one hand, I miss the old days of

1421
01:09:43.809 --> 01:09:44.999
Twitter because I had a lot of fun. I

1422
01:09:45.008 --> 01:09:46.858
made amazing contacts and friends on it and it

1423
01:09:46.868 --> 01:09:48.957
was really helpful to me for my work. But

1424
01:09:48.969 --> 01:09:51.019
I do feel that it's, it's just, it's not

1425
01:09:51.028 --> 01:09:53.959
a very nice place. It's like going into, I

1426
01:09:53.970 --> 01:09:56.160
was in Frankfurt airport a couple of weeks ago

1427
01:09:56.169 --> 01:09:58.669
and they have like an old fashioned smoking lounge

1428
01:09:59.009 --> 01:10:01.930
in the airport and it's like a glass cage

1429
01:10:01.939 --> 01:10:04.580
for smokers. And if you're a non smoker, which

1430
01:10:04.589 --> 01:10:06.589
I am you're walking by, you see all these

1431
01:10:06.600 --> 01:10:09.040
people in, you know what looks basically like a

1432
01:10:09.049 --> 01:10:14.229
cancer room. You know, they all smoking and like,

1433
01:10:14.240 --> 01:10:16.870
you just look at them and you're like, my

1434
01:10:16.879 --> 01:10:21.140
God, it's expensive. It's dangerous. It's stinky. Like you,

1435
01:10:21.149 --> 01:10:23.379
you're going to come out of there. Absolutely reeking.

1436
01:10:23.879 --> 01:10:23.939
It's

1437
01:10:24.500 --> 01:10:26.870
a, but the, but like the compassion kicks in

1438
01:10:26.879 --> 01:10:29.580
because it's one of the hardest addictions to kick.

1439
01:10:30.029 --> 01:10:33.149
But, but rarely do you see it that way?

1440
01:10:33.160 --> 01:10:36.029
And I kind of wonder if we're getting to

1441
01:10:36.040 --> 01:10:38.430
the point where, where some people can either see

1442
01:10:38.439 --> 01:10:41.379
themselves in the social media equivalent of the smoking

1443
01:10:41.390 --> 01:10:44.410
lounge in Frankfurt Airport and be like, why are

1444
01:10:44.419 --> 01:10:47.399
you doing this to yourself? Like if these things

1445
01:10:47.410 --> 01:10:49.850
make you feel so bad, why do you go

1446
01:10:49.859 --> 01:10:52.240
on them if you feel the news is unreliable

1447
01:10:52.250 --> 01:10:54.479
or you just get shouted out by crazy people

1448
01:10:54.490 --> 01:10:56.459
you've never met? Why are you signing up for

1449
01:10:56.470 --> 01:10:58.669
an emotional beating? Like there's other ways to get

1450
01:10:58.680 --> 01:11:01.140
your news that are probably more reliable and that

1451
01:11:01.149 --> 01:11:05.100
don't involve that. So, you know, all of us

1452
01:11:05.109 --> 01:11:06.660
I think are going to have a real and

1453
01:11:06.669 --> 01:11:10.129
probably are already having, um, a sort of reckoning

1454
01:11:10.140 --> 01:11:12.160
with a new relationship. And I think that could

1455
01:11:12.169 --> 01:11:14.509
be a real challenge for the social media companies

1456
01:11:14.520 --> 01:11:16.149
is if you just got a mass movement of

1457
01:11:16.160 --> 01:11:17.640
people who were like, you know what, this isn't

1458
01:11:17.649 --> 01:11:20.479
worth it anymore. Yeah, that's hard.

1459
01:11:21.620 --> 01:11:24.779
But by the way, uh related to that about

1460
01:11:24.790 --> 01:11:29.660
collecting data online and selling people's data because there

1461
01:11:29.669 --> 01:11:33.029
are people out there that are perhaps still not

1462
01:11:33.040 --> 01:11:36.100
sold on this idea that they should care about

1463
01:11:36.109 --> 01:11:38.819
this because they're just like, oh, come on, I

1464
01:11:38.830 --> 01:11:41.439
go on the internet and I go on Facebook

1465
01:11:41.450 --> 01:11:45.120
and just, uh, see some of the news and

1466
01:11:45.129 --> 01:11:48.629
uh share a few silly stuff. I mean, uh

1467
01:11:48.640 --> 01:11:51.470
stuff related to my vacation or something like that,

1468
01:11:51.479 --> 01:11:55.450
my kids and perhaps I watch some vanilla porn

1469
01:11:55.459 --> 01:11:58.279
and go on Amazon and buy some stuff. I

1470
01:11:58.290 --> 01:12:01.399
mean, what, what's the big deal with their collecting

1471
01:12:01.410 --> 01:12:04.939
that, that date, uh uh uh the, the, the

1472
01:12:05.020 --> 01:12:08.540
update and then selling it to other people? I

1473
01:12:08.549 --> 01:12:13.799
mean, I'm not doing anything bad than with the

1474
01:12:13.810 --> 01:12:18.390
I, I'm not overwhelmed on the internet with ads

1475
01:12:18.399 --> 01:12:21.310
that I don't really care about because they're also

1476
01:12:21.319 --> 01:12:24.419
catering to the things that, that I tend to

1477
01:12:24.430 --> 01:12:26.600
like. So what's the big deal there?

1478
01:12:27.979 --> 01:12:30.209
So there's so many ways we could tackle that.

1479
01:12:30.220 --> 01:12:33.299
I guess one that I would start out with

1480
01:12:33.310 --> 01:12:36.540
is like, can they imagine like, can they literally

1481
01:12:36.549 --> 01:12:40.680
conceive of a world in which they aren't having

1482
01:12:40.689 --> 01:12:42.660
all of their data gathered? Because like, that's an

1483
01:12:42.669 --> 01:12:45.390
option, right? That's a design choice. That we've all

1484
01:12:45.399 --> 01:12:48.180
made, we could have a world in which you

1485
01:12:48.189 --> 01:12:51.350
can't track me from site to site to site

1486
01:12:51.560 --> 01:12:54.549
or which third party brokers aren't, are like, just

1487
01:12:54.560 --> 01:12:56.979
not allowed to exist much less traffic in our

1488
01:12:56.990 --> 01:13:00.799
data for profit. Um And it's true like I

1489
01:13:00.810 --> 01:13:02.520
struggle with this because I think most people have

1490
01:13:02.529 --> 01:13:04.750
just priced in that they're going to have their

1491
01:13:04.759 --> 01:13:10.250
data involved in a data hack or leak at

1492
01:13:10.259 --> 01:13:12.799
some point. And like, what's the worst that happens

1493
01:13:12.810 --> 01:13:14.870
to them is maybe a little bit of casual

1494
01:13:14.879 --> 01:13:17.799
identity theft, perhaps a bit of fraud, uh which

1495
01:13:17.810 --> 01:13:20.529
hopefully their banks will cover, right? So if you

1496
01:13:20.540 --> 01:13:23.220
look at where the incentives are to care about

1497
01:13:23.229 --> 01:13:25.160
this, I don't know how much it is on

1498
01:13:25.169 --> 01:13:27.759
the individual banks care about it because they want

1499
01:13:27.770 --> 01:13:31.430
to stop fraud. Um Governments care about it because

1500
01:13:31.439 --> 01:13:33.770
they also need to stop identity fraud for all

1501
01:13:33.779 --> 01:13:37.410
sorts of security reasons. But like do individuals care

1502
01:13:37.680 --> 01:13:39.890
and I I'm with you. I think the example

1503
01:13:39.899 --> 01:13:41.299
that you just gave of the person who's like

1504
01:13:41.310 --> 01:13:44.209
going through the journey of sharing their data is

1505
01:13:44.220 --> 01:13:47.040
kind of a personal preference. Um At this point,

1506
01:13:47.049 --> 01:13:49.339
some people really care about it. Other people don't,

1507
01:13:49.350 --> 01:13:50.580
I think you could make it more of like

1508
01:13:50.589 --> 01:13:53.709
a consumer protection competition issue to say I don't

1509
01:13:53.720 --> 01:13:55.830
even really have a choice so I might care

1510
01:13:55.839 --> 01:13:58.709
about it. But the regulators aren't doing a good

1511
01:13:58.720 --> 01:14:00.700
enough job because there's no way for me to

1512
01:14:00.709 --> 01:14:05.890
have options to choose to create an online experience

1513
01:14:05.899 --> 01:14:08.310
for myself because I have to be online that

1514
01:14:08.319 --> 01:14:12.859
doesn't involve this. But there's also the whole factor.

1515
01:14:12.870 --> 01:14:15.509
The whole question in mind of so much of

1516
01:14:15.520 --> 01:14:18.220
how we've allowed everything to work is for free,

1517
01:14:18.959 --> 01:14:20.879
but it isn't really for free because your data

1518
01:14:20.890 --> 01:14:23.529
is the, is the product that's being trafficked and

1519
01:14:23.540 --> 01:14:28.290
traded for a profit. If you remove that, do

1520
01:14:28.299 --> 01:14:31.640
I have to pay to compensate for it? Right.

1521
01:14:31.649 --> 01:14:34.100
So if I want to have ad free listening

1522
01:14:34.109 --> 01:14:37.479
on my favorite podcast, that option exists, but I

1523
01:14:37.490 --> 01:14:39.620
have to join the podcast and pay a subscription

1524
01:14:39.629 --> 01:14:42.680
because fair enough the podcast creators like have bills

1525
01:14:42.689 --> 01:14:44.319
to pay as well and they're like, listen, we

1526
01:14:44.330 --> 01:14:47.859
either get paid from ads or subscription, you decide.

1527
01:14:48.290 --> 01:14:50.120
And like, that's what was interesting with Twitter is

1528
01:14:50.129 --> 01:14:52.060
I think Elon Musk tried to go down that

1529
01:14:52.069 --> 01:14:54.609
path by getting people to pay, you know, 8

1530
01:14:54.620 --> 01:14:56.529
a month to be verified because he was, he

1531
01:14:56.540 --> 01:14:58.020
was saying he wanted to do it that way,

1532
01:14:58.500 --> 01:15:01.120
which was slightly flawed because Twitter's revenue model was

1533
01:15:01.129 --> 01:15:03.439
largely advertising based as it is for indeed most

1534
01:15:03.450 --> 01:15:05.490
of the platforms. And the subscription model doesn't really

1535
01:15:05.500 --> 01:15:07.140
seem to work with any of those. And it's

1536
01:15:07.149 --> 01:15:09.390
also really difficult to get people to pay for

1537
01:15:09.399 --> 01:15:11.540
something they've had for free for a really long

1538
01:15:11.549 --> 01:15:14.430
time. Howls of protest. Uh People don't even want

1539
01:15:14.439 --> 01:15:16.279
to pay for good journalism. So you'll constantly see

1540
01:15:16.290 --> 01:15:18.830
people bitching online going. This article is behind a

1541
01:15:18.839 --> 01:15:21.939
paywall. Not understanding. I guess they don't understand the

1542
01:15:21.950 --> 01:15:24.819
cost of good journalism and not like reporters have

1543
01:15:24.830 --> 01:15:27.279
to be paid. Editors have to be paid. Uh,

1544
01:15:27.290 --> 01:15:29.100
THEY just, they just want it for free. So

1545
01:15:29.109 --> 01:15:31.100
people always want stuff for free and they won't

1546
01:15:31.109 --> 01:15:33.209
pay for it. So I think in that case

1547
01:15:33.220 --> 01:15:35.640
for, for the majority of people like that, they

1548
01:15:35.649 --> 01:15:37.859
won't care. And I'm not, to be honest, I'm

1549
01:15:37.870 --> 01:15:40.169
not even sure that they should care, which is

1550
01:15:40.180 --> 01:15:42.109
a controversial statement to make because they have almost

1551
01:15:42.120 --> 01:15:44.529
no power to get it fixed. I think the

1552
01:15:44.540 --> 01:15:47.529
people who do have power and who do care

1553
01:15:47.540 --> 01:15:50.850
who have like an incentive to care are the

1554
01:15:50.859 --> 01:15:54.850
big companies looking to bust fraud and they lobby

1555
01:15:54.859 --> 01:15:57.399
like mad. So they could actually lobby for a

1556
01:15:57.410 --> 01:15:59.810
safer internet if they wanted to. And in fact,

1557
01:15:59.819 --> 01:16:02.879
instead what they're doing is just upping the amount

1558
01:16:02.890 --> 01:16:06.330
of, you know, anti fraud protections that you would

1559
01:16:06.339 --> 01:16:08.169
have to use when you're doing online banking. For

1560
01:16:08.180 --> 01:16:10.669
instance, you might get like a, you know, you'll

1561
01:16:10.680 --> 01:16:12.779
buy something online and then you'll get a code

1562
01:16:12.790 --> 01:16:14.680
to your phone from your bank checking that you

1563
01:16:14.689 --> 01:16:16.660
actually wanted to make this purchase, right? Like that's

1564
01:16:16.669 --> 01:16:18.520
a new mechanism or getting people to have multi

1565
01:16:18.709 --> 01:16:21.299
factor authentication to check that it's really them doing

1566
01:16:21.310 --> 01:16:25.580
something. So we haven't, we haven't come up with,

1567
01:16:25.589 --> 01:16:27.620
with a way around this. And I think that's

1568
01:16:27.629 --> 01:16:31.029
because again, the ultimate extreme example of risk is

1569
01:16:31.120 --> 01:16:34.850
you build this massive surveillance capitalism model or the

1570
01:16:34.859 --> 01:16:38.939
Chinese social system, social credit system model of surveillance

1571
01:16:40.009 --> 01:16:43.430
in the liberal democratic world. We haven't yet had

1572
01:16:44.490 --> 01:16:47.830
unfortunately a pretty grim test run which would be

1573
01:16:47.839 --> 01:16:51.180
a bad government getting elected into power who then

1574
01:16:51.189 --> 01:16:53.450
weaponizes all of the information that's gathered on all

1575
01:16:53.459 --> 01:16:56.080
of us. And because humans seem to need to

1576
01:16:56.089 --> 01:16:58.910
see risks before they can decide to. Then, oh

1577
01:16:58.919 --> 01:17:00.330
God, we better fix that and make sure that

1578
01:17:00.339 --> 01:17:02.109
doesn't happen again. It's very difficult for them to

1579
01:17:02.120 --> 01:17:06.040
think ahead and prevent something from happening. I don't

1580
01:17:06.049 --> 01:17:08.100
see that going away anytime soon. It would be

1581
01:17:08.109 --> 01:17:10.509
really nice if we did because honestly, the cost

1582
01:17:10.520 --> 01:17:14.839
to society of fraud and identity theft is massive

1583
01:17:15.310 --> 01:17:18.899
and we have a new generation, new generation uh

1584
01:17:18.910 --> 01:17:20.819
that's been coming on really since the early two

1585
01:17:20.830 --> 01:17:24.939
thousands, who all of their life so much of

1586
01:17:24.950 --> 01:17:27.459
their life, more than any other human in history

1587
01:17:27.470 --> 01:17:31.000
is online. So the, the risk is not proportionate

1588
01:17:31.009 --> 01:17:32.819
if you're a baby boomer and the majority of

1589
01:17:32.830 --> 01:17:36.490
your life is not online. If your generation z

1590
01:17:37.149 --> 01:17:38.850
almost all of it is or not all of

1591
01:17:38.859 --> 01:17:41.350
it. That's unfair. That's an exaggeration. Um, LET'S just

1592
01:17:41.379 --> 01:17:41.990
call it.

1593
01:17:42.680 --> 01:17:44.759
Well, I mean, I can tell you, I can

1594
01:17:44.770 --> 01:17:46.680
tell you that I have a little brother who

1595
01:17:46.689 --> 01:17:49.410
is 10 years, 10 years younger than me. And

1596
01:17:49.419 --> 01:17:53.209
he's basically lived with internet his entire life. I

1597
01:17:53.220 --> 01:17:57.000
mean, I started using internet when I was 9,

1598
01:17:57.009 --> 01:18:00.029
10 years old, but he lived with internet, been

1599
01:18:01.399 --> 01:18:03.950
posting pictures of them for years, you know, that

1600
01:18:03.959 --> 01:18:05.799
they have an internet presence that they weren't even

1601
01:18:05.810 --> 01:18:07.790
aware of. I mean, that you can create all

1602
01:18:07.799 --> 01:18:12.029
sorts of existential um, angst and emotional problems about

1603
01:18:12.040 --> 01:18:14.750
privacy and sharing and who's, who has to share

1604
01:18:14.759 --> 01:18:18.180
your image or your story or your information. That's

1605
01:18:18.189 --> 01:18:20.540
probably another reason that we haven't really evolved yet

1606
01:18:20.549 --> 01:18:23.089
is I think when as that generation comes of

1607
01:18:23.100 --> 01:18:26.669
age and they are coming of age now, um

1608
01:18:26.680 --> 01:18:29.580
and only will continue to do so, they may

1609
01:18:29.589 --> 01:18:31.910
have different views on this. Whereas I think for

1610
01:18:31.919 --> 01:18:35.240
the baby boomers and possibly generation X even who

1611
01:18:35.250 --> 01:18:39.479
are largely in positions of power, it hasn't affected

1612
01:18:39.490 --> 01:18:41.689
them as much. It'd be interesting like to talk

1613
01:18:41.700 --> 01:18:43.350
with your little brother or indeed anybody who's of

1614
01:18:43.359 --> 01:18:47.000
that younger generation to feel. I think they are

1615
01:18:47.009 --> 01:18:53.479
really different notions of privacy and culture around sharing

1616
01:18:53.490 --> 01:18:55.560
and consent. So on the one hand, they have

1617
01:18:55.569 --> 01:18:57.509
less privacy, but I think they're also much more

1618
01:18:57.520 --> 01:19:00.549
alive to this question of consent and what that

1619
01:19:00.560 --> 01:19:02.879
means and why the consent model doesn't even always

1620
01:19:02.890 --> 01:19:06.069
work. I still though I still come down to,

1621
01:19:06.080 --> 01:19:07.890
I think it's a very old school problem. I

1622
01:19:07.899 --> 01:19:11.609
think regulators have really failed on competition because if

1623
01:19:11.620 --> 01:19:15.049
you don't want to be tracked by Facebook, um,

1624
01:19:15.839 --> 01:19:19.459
across the internet. It just doesn't matter that the,

1625
01:19:19.470 --> 01:19:22.890
the regulatory fines, well, they can pay the fines

1626
01:19:23.000 --> 01:19:25.629
like that. That model has to be updated to

1627
01:19:25.640 --> 01:19:28.209
deal with giants who can afford to pay fines

1628
01:19:28.220 --> 01:19:29.899
and actually really happy to do that. As long

1629
01:19:29.910 --> 01:19:31.910
as you don't interfere with their operating model, what

1630
01:19:31.919 --> 01:19:33.879
we actually have to do is make it so

1631
01:19:33.890 --> 01:19:35.310
that it can't do that legally in the first

1632
01:19:35.319 --> 01:19:38.439
place. You know, if Mark Zuckerberg literally faced criminal

1633
01:19:38.450 --> 01:19:40.660
charges and could like do jail time for that,

1634
01:19:40.669 --> 01:19:42.490
I'm sure he would change his model, but since

1635
01:19:42.500 --> 01:19:43.939
he just has to write a check,

1636
01:19:44.209 --> 01:19:47.169
yeah, I mean, because those fines, they don't hurt

1637
01:19:47.180 --> 01:19:49.830
their profits at all. Let's be real

1638
01:19:50.029 --> 01:19:52.890
completely. I mean, in fact, I still remember with

1639
01:19:52.899 --> 01:19:55.839
horror, the FTC had issued what was then the

1640
01:19:55.850 --> 01:19:59.120
biggest fine against Facebook for privacy violations and Facebook

1641
01:19:59.129 --> 01:20:03.080
share price went up, didn't hurt them, it went

1642
01:20:03.089 --> 01:20:05.390
up. Why did it go up? It went up

1643
01:20:05.399 --> 01:20:08.259
because people had been worried that the FTC might

1644
01:20:08.270 --> 01:20:12.160
actually take action on their data gathering practices, but

1645
01:20:12.169 --> 01:20:14.240
they didn't. So they were like super, if you're,

1646
01:20:14.250 --> 01:20:15.500
if you're telling me that all you're going to

1647
01:20:15.509 --> 01:20:17.279
do is find me, then I can build that

1648
01:20:17.290 --> 01:20:20.890
into my financial modeling, call it, call it a

1649
01:20:20.899 --> 01:20:25.529
tax pay it and carry on which is what

1650
01:20:25.540 --> 01:20:27.450
they do. And so that's going to be, the

1651
01:20:27.459 --> 01:20:30.379
question is like, we were talking about threads with,

1652
01:20:30.390 --> 01:20:32.279
with meta coming up with this new social media

1653
01:20:32.290 --> 01:20:35.649
platform to rival Twitter and the like. And I

1654
01:20:35.660 --> 01:20:38.120
was fascinated by how many people signed up and

1655
01:20:38.129 --> 01:20:39.529
we're talking about it. It was like, have you

1656
01:20:39.540 --> 01:20:42.669
forgotten who is behind all of this? These are

1657
01:20:42.680 --> 01:20:47.770
the same people who were complaining when Francis Hagen

1658
01:20:47.779 --> 01:20:50.779
blew the whistle on mental health abuses by Facebook

1659
01:20:50.790 --> 01:20:53.770
Instagram on Children. And they're the same people who

1660
01:20:53.779 --> 01:20:57.029
freaked out when Facebook was involved with Cambridge Analytica

1661
01:20:57.040 --> 01:21:00.029
in rigging the US election in 2016. You know,

1662
01:21:00.060 --> 01:21:02.250
all thinking that Mark Zuckerberg is, is awful. But

1663
01:21:02.580 --> 01:21:04.310
as soon as he put this out because he's

1664
01:21:04.319 --> 01:21:06.250
not Elon Musk and it became the thing like

1665
01:21:06.259 --> 01:21:09.890
they had a total memory wipe and they, and

1666
01:21:09.899 --> 01:21:12.540
they all signed up not thinking, I wonder why

1667
01:21:12.549 --> 01:21:14.759
this isn't allowed to be released in the European

1668
01:21:14.770 --> 01:21:17.169
Union yet, right? So like we were just talking

1669
01:21:17.180 --> 01:21:19.089
about the fact that you can't get it there

1670
01:21:19.100 --> 01:21:23.830
because the amount of data that threads harvests is

1671
01:21:23.839 --> 01:21:26.500
huge and we know that these people are not

1672
01:21:26.509 --> 01:21:29.029
going to be using it for good, they're using

1673
01:21:29.040 --> 01:21:32.240
it for profit and yet people signed up. So

1674
01:21:32.250 --> 01:21:34.419
like that was again, as a a technology ethicist,

1675
01:21:34.430 --> 01:21:37.830
I was fascinated because I was like all that

1676
01:21:37.839 --> 01:21:39.759
you can give people all the information in the

1677
01:21:39.770 --> 01:21:42.330
world and they will still make bad choices. It's

1678
01:21:42.339 --> 01:21:45.560
just not, it's not enough to give them information

1679
01:21:45.569 --> 01:21:47.109
and it's not enough to remind them again and

1680
01:21:47.120 --> 01:21:50.350
again and again, that need to have a social

1681
01:21:50.359 --> 01:21:57.129
media life, uh seems to be really strong in

1682
01:21:57.140 --> 01:21:58.740
a lot of people. We saw it first with

1683
01:21:58.750 --> 01:22:01.220
Mastodon, then we saw the blue sky now its

1684
01:22:01.229 --> 01:22:03.700
threads like it's, it's this thing and it never

1685
01:22:03.709 --> 01:22:06.189
seems to get the critical mass that, that may

1686
01:22:06.200 --> 01:22:08.470
have changed by the time this podcast go out,

1687
01:22:08.660 --> 01:22:11.240
um they'll have a spike in early adoption and

1688
01:22:11.250 --> 01:22:13.490
then it kind of falls off. And that's what

1689
01:22:13.500 --> 01:22:15.100
I mean about kind of looking to the long

1690
01:22:15.109 --> 01:22:17.040
term is like, are people actually going to want

1691
01:22:17.049 --> 01:22:20.049
this? Because what, what need does it serve and

1692
01:22:20.060 --> 01:22:23.200
is the price too high to pay? Yeah, very

1693
01:22:23.330 --> 01:22:24.589
fascinating. But I don't know.

1694
01:22:24.859 --> 01:22:27.750
But by the way, since uh earlier, you mentioned

1695
01:22:27.759 --> 01:22:31.180
that you wrote your book during the COVID-19 pandemic,

1696
01:22:31.189 --> 01:22:33.549
I would also like to ask you what, what

1697
01:22:33.560 --> 01:22:36.549
is your idea about uh some of the digi

1698
01:22:36.669 --> 01:22:40.660
digital health tools that were used during the COVID-19

1699
01:22:40.669 --> 01:22:43.549
pandemic because of course, we were dealing with a

1700
01:22:43.839 --> 01:22:48.794
major health issue and perhaps even if there with

1701
01:22:48.805 --> 01:22:53.484
some data collection, uh I, I mean, it, it

1702
01:22:53.495 --> 01:22:58.484
would still be ethical to do that. The pros

1703
01:22:58.495 --> 01:23:01.785
would outweigh the cons because of the threat we

1704
01:23:01.794 --> 01:23:05.305
were dealing with. But what do you think about

1705
01:23:05.314 --> 01:23:09.104
uh some of the data that were potentially collected

1706
01:23:09.274 --> 01:23:14.145
by, I guess governments mostly during that period?

1707
01:23:14.790 --> 01:23:17.250
It's interesting, isn't it like we haven't really had

1708
01:23:17.259 --> 01:23:19.509
all of the different countries that built that kind

1709
01:23:19.520 --> 01:23:23.310
of health surveillance tech if you will um come

1710
01:23:23.319 --> 01:23:25.790
out as a group, I don't mean individually but

1711
01:23:25.799 --> 01:23:28.120
as a group or through the auspices of the,

1712
01:23:28.129 --> 01:23:32.069
who the World Health Organization to say, like if

1713
01:23:32.080 --> 01:23:34.439
we have another pandemic, God forbid in, you know,

1714
01:23:34.450 --> 01:23:37.450
a few years time, is this a tool that

1715
01:23:37.459 --> 01:23:39.339
we want to have in our toolbox Eg was

1716
01:23:39.350 --> 01:23:41.540
it effective or not? And not only was it

1717
01:23:41.549 --> 01:23:43.339
effective? Was it worth it? Which is a different

1718
01:23:43.350 --> 01:23:47.740
question? Um The UK has had some studies that

1719
01:23:47.750 --> 01:23:53.879
came out arguing that it reduced transmission. But II

1720
01:23:53.890 --> 01:23:56.859
I still question some of that because we can't

1721
01:23:56.870 --> 01:24:01.370
really run a couple of other sort of counterfactual

1722
01:24:01.379 --> 01:24:04.470
experiments. Like what, what would it be like if

1723
01:24:04.479 --> 01:24:06.950
we hadn't used it? There's a lot of problems

1724
01:24:06.959 --> 01:24:08.810
still with some of the things that I cook.

1725
01:24:09.200 --> 01:24:11.250
And I also just think I interviewed loads of

1726
01:24:11.259 --> 01:24:14.520
doctors while I was writing that chapter and none

1727
01:24:14.529 --> 01:24:16.689
of them were asking for this. Like this was

1728
01:24:16.700 --> 01:24:19.189
not the tool, this was not the mitigation that

1729
01:24:19.200 --> 01:24:22.049
they need, that they felt they needed. Um The

1730
01:24:22.060 --> 01:24:25.810
most effective mitigations were the lockdowns unfortunately. And then

1731
01:24:25.919 --> 01:24:30.310
obviously the big one was vaccines, but doctors weren't

1732
01:24:30.319 --> 01:24:32.279
calling for this. It really felt for me like

1733
01:24:32.290 --> 01:24:35.069
a solution in search of a problem in the

1734
01:24:35.080 --> 01:24:38.799
sense that this massive crisis happened. Technologists wanted to

1735
01:24:38.810 --> 01:24:42.490
do something investors saw a potential to make money

1736
01:24:42.500 --> 01:24:45.459
from it and like, Voila, let's go for it.

1737
01:24:45.470 --> 01:24:48.169
And you saw in the case of Singapore, um,

1738
01:24:48.180 --> 01:24:50.109
they said at first we, you know, we're making

1739
01:24:50.120 --> 01:24:51.959
this mandatory, but don't worry, we're going to collect

1740
01:24:51.970 --> 01:24:53.819
data that we would never use for like a

1741
01:24:53.830 --> 01:24:57.529
criminal policing aspect. We're only using it for public

1742
01:24:57.540 --> 01:24:58.970
health and of course they did use it for

1743
01:24:58.979 --> 01:25:02.330
the criminal policing aspect. So, like, not a surprise,

1744
01:25:02.339 --> 01:25:05.060
like, saw that one coming a mile away. And

1745
01:25:05.069 --> 01:25:07.040
absolutely, I think the UK would have done it.

1746
01:25:07.049 --> 01:25:09.240
I mean, we've seen, unfortunately, we're going through our

1747
01:25:09.250 --> 01:25:12.399
COVID inquiry now and it's been pretty grim, the

1748
01:25:12.410 --> 01:25:15.319
behavior of people in power. Uh, CERTAINLY within our

1749
01:25:15.330 --> 01:25:17.370
current government, a lot of the ministers who were

1750
01:25:17.379 --> 01:25:19.180
not following their own laws or, you know, they

1751
01:25:19.189 --> 01:25:21.189
were, the police were really clamping down and there

1752
01:25:21.200 --> 01:25:24.520
was like a certain people were more heavily policed

1753
01:25:24.529 --> 01:25:26.910
than others and there was a racial, ethnic class

1754
01:25:26.919 --> 01:25:30.520
component to that, right. So you do that and

1755
01:25:30.529 --> 01:25:33.540
then you put technology solutions on top of that.

1756
01:25:33.549 --> 01:25:35.520
I just think you're going to create some really

1757
01:25:35.529 --> 01:25:40.029
serious problems. The parliament hadn't really created pandemic legislation

1758
01:25:40.439 --> 01:25:42.740
in place to deal with it. And part of

1759
01:25:42.750 --> 01:25:44.959
the reason, um, I put my book out in

1760
01:25:44.970 --> 01:25:48.500
February of 2022 and that was because I was

1761
01:25:48.509 --> 01:25:50.189
in my poor publishers. I was like, we have

1762
01:25:50.200 --> 01:25:55.060
to wait because they started passing legislation I think

1763
01:25:55.069 --> 01:25:58.129
it was to remember now, the last order England

1764
01:25:58.140 --> 01:26:01.209
was the last one to create a legal framework

1765
01:26:01.220 --> 01:26:03.009
to allow these, to allow these apps which had

1766
01:26:03.020 --> 01:26:04.859
already been in existence for like a year at

1767
01:26:04.870 --> 01:26:09.049
that point, maybe even more. Um They didn't have

1768
01:26:09.060 --> 01:26:10.609
a legal framework for it though in the four

1769
01:26:10.620 --> 01:26:13.509
nations of the United Kingdom until starting in September

1770
01:26:13.520 --> 01:26:17.000
of 2021. And then England was the last one

1771
01:26:17.009 --> 01:26:19.720
in December of 2021. So I was typing against

1772
01:26:19.729 --> 01:26:21.890
the clock because I wanted to capture that before

1773
01:26:21.899 --> 01:26:24.660
we went to press uh and put it out

1774
01:26:24.700 --> 01:26:30.930
to show really, the UK had, had completely changed

1775
01:26:30.939 --> 01:26:32.529
its position. We used to be a country that

1776
01:26:32.540 --> 01:26:35.069
was super proud of not having identity cards and

1777
01:26:35.080 --> 01:26:36.689
all of a sudden in this case, we did

1778
01:26:36.700 --> 01:26:38.419
and we've also put them in for voting now,

1779
01:26:38.430 --> 01:26:42.490
by the way, like massive cultural shift here, not

1780
01:26:42.500 --> 01:26:46.529
without protest. So they did that. And then within

1781
01:26:46.540 --> 01:26:49.910
like two months of England passing that law, they

1782
01:26:49.919 --> 01:26:52.109
basically were like, we're not using the app anymore.

1783
01:26:52.120 --> 01:26:55.029
Why? Because it wasn't like it wasn't effective, it

1784
01:26:55.040 --> 01:26:58.149
was not what, what was needed. So we did

1785
01:26:58.160 --> 01:26:59.720
all of this mass, you know, they blew a

1786
01:26:59.729 --> 01:27:03.169
huge amount of political capital and wasted loads of

1787
01:27:03.180 --> 01:27:06.270
time on something that they in the end themselves

1788
01:27:06.279 --> 01:27:08.470
decided it wasn't going to be a requirement. And

1789
01:27:08.479 --> 01:27:10.680
what was really awful in that is they kept

1790
01:27:10.689 --> 01:27:12.629
lying about it. So they kept saying, hey, we're

1791
01:27:12.640 --> 01:27:14.799
not building it when they were secretly building it,

1792
01:27:14.979 --> 01:27:16.279
then they were like, well, we're building it but

1793
01:27:16.290 --> 01:27:17.959
it's not going to be mandatory and blah, blah,

1794
01:27:17.970 --> 01:27:22.310
blah. So each time they kind of destroyed public

1795
01:27:22.319 --> 01:27:26.529
trust, which is essential in something like a national

1796
01:27:26.540 --> 01:27:29.100
crisis or international crisis, like a pandemic. So, you

1797
01:27:29.109 --> 01:27:31.259
know, my takeaway for what it's worth and stuff

1798
01:27:31.270 --> 01:27:33.200
like that is, you know, a I'm not convinced

1799
01:27:33.209 --> 01:27:36.870
it was worth it scientifically and medically, it wasn't

1800
01:27:36.879 --> 01:27:41.399
what healthcare professionals certainly were calling for. Um The

1801
01:27:41.410 --> 01:27:43.850
risks are super high in terms of potential for

1802
01:27:43.859 --> 01:27:48.689
abuse and they blew so much political and social

1803
01:27:48.700 --> 01:27:51.680
trust and that matters in a democracy because if

1804
01:27:51.689 --> 01:27:53.500
we, you know, I guarantee you, if we go

1805
01:27:53.509 --> 01:27:55.560
again into another pandemic, a lot of people are

1806
01:27:55.569 --> 01:27:59.430
going to remember all the lying that government did

1807
01:27:59.819 --> 01:28:02.970
trust matters when you're handing over data, trust matters.

1808
01:28:02.979 --> 01:28:05.720
If you're doing surveillance and trust matters in terms

1809
01:28:05.729 --> 01:28:07.500
of health and because you, you're talking to people

1810
01:28:07.509 --> 01:28:10.930
about their bodies, ultimately, you know, you play with

1811
01:28:10.939 --> 01:28:13.160
that with your peril. So that for me was

1812
01:28:13.169 --> 01:28:15.459
the real learning point was like, how do I

1813
01:28:15.470 --> 01:28:21.660
create trust in the scientific method in health care?

1814
01:28:21.669 --> 01:28:24.049
You're asking people to make massive sacrifices, you have

1815
01:28:24.060 --> 01:28:27.450
to be even more trustworthy than normal because you're,

1816
01:28:27.459 --> 01:28:30.700
you're, you're making a bigger, ask a bigger demand

1817
01:28:31.229 --> 01:28:33.609
and for my two cents for what it's worth

1818
01:28:33.620 --> 01:28:36.450
in the UK. We blew that. We absolutely blew

1819
01:28:36.459 --> 01:28:39.459
it. Um So it wouldn't be great to, to

1820
01:28:39.470 --> 01:28:41.450
have to have, you know, run that experiment again.

1821
01:28:41.459 --> 01:28:44.680
If there's, you know, pandemic version 2.0 I would

1822
01:28:44.689 --> 01:28:46.259
have a lot of confidence and I suspect the

1823
01:28:46.270 --> 01:28:47.580
US would be the same. I mean, that was

1824
01:28:47.589 --> 01:28:50.399
another case, my family and friends over in America,

1825
01:28:50.939 --> 01:28:53.910
they were like there was no case of requiring

1826
01:28:53.919 --> 01:28:56.169
people to use that kind of surveillance technology for

1827
01:28:56.180 --> 01:28:58.229
health, for better or for worse. And you can

1828
01:28:58.240 --> 01:29:00.060
look at the outcomes on that. But that's what

1829
01:29:00.069 --> 01:29:02.799
I'm talking about. The technology is just one part

1830
01:29:02.810 --> 01:29:06.479
of it. There's the cultural bit about adaptation. Why

1831
01:29:06.490 --> 01:29:09.410
were certain European countries were happy to do it?

1832
01:29:09.560 --> 01:29:12.180
And others weren't certain countries could afford to do

1833
01:29:12.189 --> 01:29:14.859
it or have the infrastructure, do it? Certain populations

1834
01:29:14.870 --> 01:29:17.899
have an iphone or an Android and others just

1835
01:29:17.910 --> 01:29:20.220
don't. So it's not even an option for them,

1836
01:29:20.399 --> 01:29:23.689
right? Like all of those things come into play.

1837
01:29:23.700 --> 01:29:26.049
And if you're looking at utilitarianism, if you're looking

1838
01:29:26.060 --> 01:29:28.470
at like the greatest number of happiness for the

1839
01:29:28.479 --> 01:29:30.979
greatest numbers of people, you might want to do.

1840
01:29:30.990 --> 01:29:32.600
What I was trying to do is go back

1841
01:29:32.609 --> 01:29:35.899
to the original problem set and go what is

1842
01:29:35.910 --> 01:29:38.959
it that the healthcare profession says it needs, it

1843
01:29:38.970 --> 01:29:42.609
needs P pe they thought they needed ventilators that

1844
01:29:42.620 --> 01:29:44.689
later was dismissed because to be honest, by the

1845
01:29:44.700 --> 01:29:47.029
point, you're on a ventilator. It's pretty bad. Um,

1846
01:29:47.040 --> 01:29:49.790
THEY needed people to stay home and they really

1847
01:29:49.799 --> 01:29:52.549
needed a race for a vaccine. That is where

1848
01:29:52.560 --> 01:29:54.450
you want to put, given that you have limited

1849
01:29:54.459 --> 01:29:57.470
capital and limited resources. That's where you want to

1850
01:29:57.479 --> 01:29:59.779
go. But people were super excited with this idea

1851
01:29:59.790 --> 01:30:01.970
that this app on our phone is going to

1852
01:30:01.979 --> 01:30:03.979
allow us to open up society again.

1853
01:30:04.439 --> 01:30:06.299
Yeah. No, no, I have to tell you here

1854
01:30:06.310 --> 01:30:09.850
in Portugal, the government also put out an app

1855
01:30:09.859 --> 01:30:14.279
in 2021 if I'm not mistaken. And back then

1856
01:30:14.290 --> 01:30:17.819
they were moralizing people a lot. Oh, you should

1857
01:30:17.830 --> 01:30:20.060
install the app, blah, blah, blah, blah, it's a

1858
01:30:20.069 --> 01:30:23.810
health measure, whatever. Uh And I, and I was

1859
01:30:23.819 --> 01:30:26.140
like, so first of all, I never installed the

1860
01:30:26.149 --> 01:30:28.859
app because it was not mandatory. So I myself

1861
01:30:28.870 --> 01:30:31.401
never installed the app at all. Uh But, but

1862
01:30:31.412 --> 01:30:34.332
first of all, I was like, yeah, and if

1863
01:30:34.341 --> 01:30:37.972
certain people do not even have smartphones to begin

1864
01:30:37.981 --> 01:30:41.171
with, I mean, are you also going to moralize

1865
01:30:41.231 --> 01:30:45.062
those people? I mean, no one should be forced

1866
01:30:45.071 --> 01:30:47.251
to have a smartphone if they have one of

1867
01:30:47.262 --> 01:30:52.312
those older, uh, cell phones, I mean, who cares?

1868
01:30:52.321 --> 01:30:54.321
And, and then, and then I was like, I

1869
01:30:54.332 --> 01:30:57.514
was taking the pandemic very serious. I was masking

1870
01:30:57.523 --> 01:30:59.974
all the time. I was staying at home as

1871
01:30:59.983 --> 01:31:04.824
much as possible. Uh I was distancing as much

1872
01:31:04.833 --> 01:31:08.164
as possible. I got tested two or three times

1873
01:31:08.173 --> 01:31:11.613
during the pandemic. It always came out negative. Fortunately,

1874
01:31:11.753 --> 01:31:15.414
uh and I was like, doing everything apart from

1875
01:31:15.423 --> 01:31:17.563
the app and I was like, ok, if I'm

1876
01:31:17.574 --> 01:31:20.443
doing all of this, let's say that I uh

1877
01:31:20.454 --> 01:31:23.945
cross paths with someone who also has the app

1878
01:31:23.956 --> 01:31:26.596
installed and I get an alert on my phone

1879
01:31:26.605 --> 01:31:31.266
saying that I uh went by uh for uh

1880
01:31:31.275 --> 01:31:35.155
was less than 3 m or whatever away from

1881
01:31:35.166 --> 01:31:39.175
a person who got diagnosed with COVID. Yeah. What

1882
01:31:39.186 --> 01:31:42.485
am I going to do with that? Because let's

1883
01:31:42.496 --> 01:31:45.786
get real if I, even if I get COVID,

1884
01:31:45.795 --> 01:31:48.717
but I'm a symptomatic, I'm not going to get

1885
01:31:48.728 --> 01:31:52.857
tested. Let's get real. So I, I mean, what,

1886
01:31:52.868 --> 01:31:59.388
how uh valuable is that information for me? And,

1887
01:31:59.397 --> 01:32:03.007
and I, and if I am COVID negative, no,

1888
01:32:03.018 --> 01:32:06.768
no uh no one out there who goes by

1889
01:32:06.777 --> 01:32:11.018
me will get any alert saying that they crossed

1890
01:32:11.217 --> 01:32:16.020
paths with someone who has COVID. So, I mean,

1891
01:32:16.029 --> 01:32:20.149
and I got vaccinated as soon as possible. So

1892
01:32:20.589 --> 01:32:24.220
what, what can I gain or anyone who crosses

1893
01:32:24.229 --> 01:32:27.990
perhaps with me can gain from this? And I

1894
01:32:28.000 --> 01:32:28.310
never

1895
01:32:29.569 --> 01:32:32.149
though because like, like the, the sort of wanna

1896
01:32:32.160 --> 01:32:34.310
be scientist in me is like, I'm glad that

1897
01:32:34.319 --> 01:32:36.779
we tried it because like, I understand in those

1898
01:32:36.790 --> 01:32:39.080
pre vaccine days, like people were like, we have

1899
01:32:39.089 --> 01:32:42.810
to try whatever we can. That's understandable. Um I'm

1900
01:32:42.819 --> 01:32:44.540
glad we tried it in a number of different

1901
01:32:44.549 --> 01:32:48.069
countries with different political and cultural flavors. So, that

1902
01:32:48.080 --> 01:32:49.729
we could see like what words or what might

1903
01:32:49.740 --> 01:32:52.649
not work because we don't know again, uh wherever

1904
01:32:52.660 --> 01:32:54.609
the next pandemic will come from, we don't know

1905
01:32:54.620 --> 01:32:56.370
when that will happen and where it will be

1906
01:32:56.379 --> 01:32:58.700
with our technology. That's kind of why I was

1907
01:32:58.709 --> 01:33:00.490
really motivated to write the chapters. Like I want

1908
01:33:00.500 --> 01:33:03.069
to capture the UK case study to the best

1909
01:33:03.080 --> 01:33:05.629
of my ability now, not just the tech part

1910
01:33:05.640 --> 01:33:10.589
but the social cultural part. Because if this happens

1911
01:33:10.600 --> 01:33:12.839
again, you know, when it happened for us in

1912
01:33:12.850 --> 01:33:14.770
2020 I was going back to books on the

1913
01:33:14.779 --> 01:33:18.250
Spanish flu. In 1918, I was like, I need,

1914
01:33:18.259 --> 01:33:20.120
you know, I need, I need to skill up

1915
01:33:20.129 --> 01:33:21.990
fast. What do I need to know about this?

1916
01:33:22.000 --> 01:33:23.200
And I'm sure loads of people felt the same

1917
01:33:23.209 --> 01:33:25.180
way just as ordinary citizens. You don't have to

1918
01:33:25.189 --> 01:33:26.620
be a researcher to be interested in, you know,

1919
01:33:26.629 --> 01:33:29.410
learning what had happened in previous pandemics, but I

1920
01:33:29.419 --> 01:33:33.310
wanted to create something so that future future researchers

1921
01:33:33.319 --> 01:33:34.729
could go back and be like, well, what happened

1922
01:33:34.740 --> 01:33:36.259
in the UK? And you know, I'm sure loads

1923
01:33:36.270 --> 01:33:38.750
of people have written stuff on that um for

1924
01:33:38.759 --> 01:33:40.529
what it's worth, I will share this, the Ada

1925
01:33:40.540 --> 01:33:43.089
Lovelace Institute here in the United Kingdom is a

1926
01:33:43.100 --> 01:33:46.890
wonderful research institution and they've just come out with

1927
01:33:46.899 --> 01:33:50.819
their assessment of pandemic technology. I haven't had a

1928
01:33:50.830 --> 01:33:52.160
chance to read it yet because I just came

1929
01:33:52.169 --> 01:33:54.620
back from holiday. But it looks pretty interesting and

1930
01:33:54.629 --> 01:33:56.290
they do great work. So that might be something

1931
01:33:56.299 --> 01:34:00.001
for your viewers to check out if they want

1932
01:34:00.012 --> 01:34:01.651
to. I feel like the Turing Institute might have

1933
01:34:01.682 --> 01:34:05.082
as well. Um And definitely Oxford University has published

1934
01:34:05.091 --> 01:34:08.041
a lot of stuff on it, but I'm intrigued

1935
01:34:08.051 --> 01:34:11.532
by the ada Lovelace view because they often do

1936
01:34:11.541 --> 01:34:15.571
an international comparison. So there is cutting edge research

1937
01:34:15.582 --> 01:34:17.821
that I am unfortunately behind on at the moment.

1938
01:34:17.832 --> 01:34:19.472
But you know, we know it's there. So if

1939
01:34:19.481 --> 01:34:20.912
anyone wants to take a look at that, if

1940
01:34:20.921 --> 01:34:21.912
you don't want to hear what I have to

1941
01:34:21.921 --> 01:34:24.271
say by all means, don't go check out in

1942
01:34:24.282 --> 01:34:25.844
a lovely, they got some good stuff

1943
01:34:26.173 --> 01:34:28.594
and I mean, just to be clear, I'm not

1944
01:34:28.604 --> 01:34:34.124
completely dismissing these apps. I'm not saying 100% that

1945
01:34:34.133 --> 01:34:36.554
they didn't help at all that they weren't good

1946
01:34:36.633 --> 01:34:39.793
health measures. I'm just saying that first of all,

1947
01:34:40.124 --> 01:34:42.773
no one should be forced to have a smartphone.

1948
01:34:42.784 --> 01:34:48.554
That's the first point. Second of all, you shouldn't

1949
01:34:48.563 --> 01:34:53.266
moralize people for not having a smartphone or install,

1950
01:34:53.476 --> 01:34:56.666
really should moralize them when you're the British ministers

1951
01:34:56.675 --> 01:34:57.976
who were breaking all of their own

1952
01:34:58.036 --> 01:35:00.195
rules. Yeah, that's one

1953
01:35:00.215 --> 01:35:02.175
thing to moralize if you at least to walk

1954
01:35:02.186 --> 01:35:05.076
the walk. But if you're doing hypocrisy, like get

1955
01:35:05.085 --> 01:35:09.065
out and, and then my first and then the

1956
01:35:09.155 --> 01:35:11.965
third point and that's why I mentioned that I

1957
01:35:11.996 --> 01:35:15.445
really follow all the guidelines and all of that

1958
01:35:15.456 --> 01:35:20.259
to prevent COVID transmission is that you have to

1959
01:35:20.270 --> 01:35:24.029
convince me that it's worth it because I'm not

1960
01:35:24.040 --> 01:35:27.709
dumb and people are not dumb. Don't, don't treat

1961
01:35:27.720 --> 01:35:30.970
us as dumb like, oh, you should do this.

1962
01:35:30.979 --> 01:35:33.330
Yeah. Why, why you have

1963
01:35:34.160 --> 01:35:35.750
with anything? If you're asking people to make a

1964
01:35:35.759 --> 01:35:38.640
change, you have to show them why it is

1965
01:35:38.649 --> 01:35:40.759
worth it. Listen, I'm just aware of the fact

1966
01:35:40.770 --> 01:35:42.410
that it's approaching 11. I'm going to have to

1967
01:35:42.419 --> 01:35:44.359
let you go if that's ok because I unfortunately

1968
01:35:44.370 --> 01:35:45.759
have to talk to one of my clients.

1969
01:35:45.799 --> 01:35:47.759
Oh, yeah. No, no, sorry. I,

1970
01:35:48.419 --> 01:35:49.729
I, I love this chat but I was like,

1971
01:35:49.740 --> 01:35:51.939
oh, no, the time has flown. No,

1972
01:35:51.950 --> 01:35:54.279
no, I'm sorry, I wasn't aware that you had

1973
01:35:54.290 --> 01:35:58.680
that time limit. So, yeah. So just quickly before

1974
01:35:58.689 --> 01:36:00.680
we go, would you like to tell people where

1975
01:36:00.689 --> 01:36:02.660
they can find you and your work on the

1976
01:36:02.669 --> 01:36:03.220
internet?

1977
01:36:03.589 --> 01:36:07.450
Well, I mean, I'm a Google search away. Uh,

1978
01:36:07.549 --> 01:36:10.819
PROBABLY the easiest is my website, which is Habra,

1979
01:36:10.830 --> 01:36:15.390
uh, Hare brain.co. So you can find all my,

1980
01:36:15.399 --> 01:36:20.080
uh, television and radio and online writing. Um, AND

1981
01:36:20.089 --> 01:36:24.500
paper writing there. My book is available at all

1982
01:36:24.509 --> 01:36:26.569
good bookstores. You can just order it through your

1983
01:36:26.580 --> 01:36:29.379
local independent bookstore or Pay Il Amazon. It's up

1984
01:36:29.390 --> 01:36:32.069
to you your call, not mine how you want

1985
01:36:32.080 --> 01:36:33.970
to do it. So it's there. It's an audio

1986
01:36:33.979 --> 01:36:35.790
book too if you prefer to listen to it

1987
01:36:35.799 --> 01:36:37.379
rather than read it. But then you'll miss the

1988
01:36:37.390 --> 01:36:39.779
amazing date, this, which is in the book. So

1989
01:36:39.830 --> 01:36:42.629
it just depends on what you want. Um And

1990
01:36:42.640 --> 01:36:44.390
I'm on Twitter and linkedin in case anybody has

1991
01:36:44.399 --> 01:36:47.790
questions or wants to follow up or share something

1992
01:36:47.799 --> 01:36:49.839
that they think I've missed or that I need

1993
01:36:49.850 --> 01:36:51.990
to look at. I'm really, really lucky for some

1994
01:36:52.000 --> 01:36:55.950
reason, I have an incredible group of people from

1995
01:36:55.959 --> 01:36:58.180
the public who just send me stuff randomly tips

1996
01:36:58.189 --> 01:36:59.790
and things to look at or articles that are

1997
01:36:59.799 --> 01:37:02.120
actually really interesting or examples from their country that

1998
01:37:02.129 --> 01:37:03.859
I would never have heard about otherwise. So I

1999
01:37:03.870 --> 01:37:05.720
love to hear from people. If somebody wants to

2000
01:37:05.729 --> 01:37:07.580
get in touch, I would be very welcome. As

2001
01:37:07.589 --> 01:37:11.669
long as polite kind. No romance stuff, please. But

2002
01:37:11.680 --> 01:37:16.569
uh the marriage proposals get a bit weird uh

2003
01:37:16.620 --> 01:37:18.229
at the end. But no, I would love to

2004
01:37:18.240 --> 01:37:21.520
talk technology and ethics with um any of your

2005
01:37:21.529 --> 01:37:23.680
listeners or viewers and I'm so grateful to you

2006
01:37:23.689 --> 01:37:25.220
for the chance to have this chat.

2007
01:37:25.520 --> 01:37:27.470
No. Thank you so much for coming on the

2008
01:37:27.479 --> 01:37:30.459
show. Thank you for your time and hopefully somewhere

2009
01:37:30.470 --> 01:37:32.779
in the future we can have another conversation. I

2010
01:37:32.790 --> 01:37:34.350
really love this one. So

2011
01:37:34.505 --> 01:37:36.076
I would love that too. I will drop you

2012
01:37:36.085 --> 01:37:37.746
a note if I am ever in Portugal again,

2013
01:37:37.755 --> 01:37:41.536
which I hope I will be all be well

2014
01:37:41.545 --> 01:37:42.675
and let me know when it comes out. I'd

2015
01:37:42.686 --> 01:37:46.706
love to see it. Yeah. Sure. The marriage proposals

2016
01:37:46.715 --> 01:37:49.346
get a bit weird at the end. But no,

2017
01:37:49.355 --> 01:37:52.166
I would love to talk technology and ethics with

2018
01:37:52.175 --> 01:37:54.576
um, any of your listeners or viewers. And I'm

2019
01:37:54.585 --> 01:37:56.262
so grateful to you for the chance to have

2020
01:37:56.271 --> 01:37:57.452
this chat. No,

2021
01:37:57.461 --> 01:37:59.452
thank you so much for coming on the show.

2022
01:37:59.461 --> 01:38:02.251
Thank you for your time and hopefully somewhere in

2023
01:38:02.262 --> 01:38:04.952
the future we can have another conversation. I really

2024
01:38:04.961 --> 01:38:06.352
love this one. So I

2025
01:38:06.361 --> 01:38:07.782
would love that too. I will drop you a

2026
01:38:07.791 --> 01:38:09.682
note if I am ever in Portugal again, which

2027
01:38:09.691 --> 01:38:13.222
I hope I will be all right, be well

2028
01:38:13.231 --> 01:38:14.361
and let me know when it comes out. I'd

2029
01:38:14.372 --> 01:38:15.432
love to see it. Yeah,

2030
01:38:15.441 --> 01:38:19.520
sure. Hi guys. Thank you for watching this interview.

2031
01:38:19.529 --> 01:38:22.120
Until the end. If you liked it, please do

2032
01:38:22.129 --> 01:38:27.279
not forget to like it, share, comment and subscribe.

2033
01:38:27.319 --> 01:38:30.359
And if you like more generally, what I'm doing,

2034
01:38:30.450 --> 01:38:35.240
please consider support the show on Patreon or paypal.

2035
01:38:35.350 --> 01:38:38.009
You have all of the links in the description

2036
01:38:38.020 --> 01:38:40.810
of this interview. The show is brought to you

2037
01:38:40.819 --> 01:38:44.990
by En Lights learning and development. Done differently. Check

2038
01:38:45.000 --> 01:38:48.700
their website at alights.com. I would also like to

2039
01:38:48.709 --> 01:38:51.120
give a huge thank you to my main patrons

2040
01:38:51.129 --> 01:38:55.720
and paypal supporters per Larson Jerry Mueller and Frederick

2041
01:38:55.729 --> 01:39:00.020
Sunda Bernards, all of election and Weser, Adam Castle

2042
01:39:00.029 --> 01:39:03.700
Matthew Whitting Whitting bear. No wolf, Tim Hollis, Eric,

2043
01:39:03.759 --> 01:39:07.479
Alania, John Connors, Philip Forrest, Connelly, Robert Winde Ruin,

2044
01:39:07.490 --> 01:39:11.672
Nai Zoup, Mark Nevs Colin Hall, Simon, Columbus, Phil

2045
01:39:11.823 --> 01:39:15.663
Cavanagh, Mikel, Stormer, Samuel Andrea Francis for the Agd

2046
01:39:16.462 --> 01:39:20.913
Alexander Dan Bauer, Fergal, Ken Hall, Herzog Michel, Jonathan

2047
01:39:20.922 --> 01:39:25.812
Libra Jars and the Correa Eric Heine Marc Smith,

2048
01:39:25.982 --> 01:39:30.163
Jan We Amal Franz David Sloan Wilson Yasa, Des

2049
01:39:31.163 --> 01:39:36.726
Roma Roach Jan Punter Romani Charlotte. Bliss, Nicole Barbar

2050
01:39:37.525 --> 01:39:41.116
and Pao Ay Nele Guy Madison, Gary G Haman,

2051
01:39:41.516 --> 01:39:44.565
Samo Zal Arien Y Nick Golden Paul Talent in

2052
01:39:44.585 --> 01:39:47.965
John Bar was Julian Price Edward Hall, Eden Brown,

2053
01:39:48.186 --> 01:39:51.636
Douglas Fry Franca Beto Lotti Gabriel Pan Cortez, Lalit

2054
01:39:52.136 --> 01:39:57.089
Scott Zachary Fish, Tim Duffy, Sonny Smith, John Wiesman,

2055
01:39:57.250 --> 01:40:01.799
Martin Aland, Daniel Friedman, William Buckner, Paul George Arnold

2056
01:40:01.810 --> 01:40:06.870
Luke Lo A Georges off Chris Williamson, Peter Lawson,

2057
01:40:07.089 --> 01:40:12.160
David Williams Di Costa Anton Erickson Charles Murray, Alex

2058
01:40:12.520 --> 01:40:17.950
Shaw and Murray Martinez Le Chevalier bangalore atheists, Larry

2059
01:40:18.020 --> 01:40:23.160
Daley Junior Holt Eric B. Starry Michael Bailey. Then

2060
01:40:23.169 --> 01:40:27.640
Sperber, Robert Grassy Rough the RP MD I Goran

2061
01:40:27.729 --> 01:40:33.589
Jeff mcmahon, Jake Zul Barnabas Radix, Mark Campbell, Richard

2062
01:40:33.600 --> 01:40:38.709
Bowen Thomas the Dubner Luke Ni Andre Story, Manuel

2063
01:40:38.720 --> 01:40:43.629
Oliveira, Kimberly Johnson and Benjamin Gilbert. A special thanks

2064
01:40:43.640 --> 01:40:46.540
to my producers is our web gem Frank Luca

2065
01:40:46.620 --> 01:40:51.294
Stan, Tom Weam Bernard Eni Ortiz Dixon Benedict Mueller,

2066
01:40:51.484 --> 01:40:56.274
Vege Gli Thomas Trumble Catherine and Patrick Tobin John

2067
01:40:56.314 --> 01:41:00.254
Carlo Montenegro, Robert Lewis and Al Nick Ortiz. And

2068
01:41:00.265 --> 01:41:04.044
to my executive producers, Matthew Lavender, Serge Adrian and

2069
01:41:04.125 --> 01:41:06.245
Bogdan Kut. Thank you for all.

