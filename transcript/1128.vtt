WEBVTT

1
00:00:00.319 --> 00:00:03.349
Hello, everyone. Welcome to a new episode of the

2
00:00:03.349 --> 00:00:06.389
Dissenter. I'm your host, as always, Ricardo Lopez, and

3
00:00:06.389 --> 00:00:09.789
today I'm joined by Doctor Daniel Silverman. He's an

4
00:00:09.789 --> 00:00:12.869
assistant professor of political science in the Carnegie Mellon

5
00:00:12.869 --> 00:00:17.260
Institute for Strategy and Technology at Carnegie Mellon University.

6
00:00:17.510 --> 00:00:20.219
And today we're talking about his book Seeing His

7
00:00:20.219 --> 00:00:25.510
Disbelieving, Why People Believe Misinformation in War and When

8
00:00:25.510 --> 00:00:29.360
They Know Better. So, Doctor Silverman, welcome to the

9
00:00:29.360 --> 00:00:30.809
show. It's a pleasure to everyone.

10
00:00:31.649 --> 00:00:33.709
Thank you so much. Uh, GREAT to be here

11
00:00:33.709 --> 00:00:35.759
and, and it's, it's really a unique and and

12
00:00:35.759 --> 00:00:39.080
fascinating series that you, you do here, so.

13
00:00:40.029 --> 00:00:43.330
Thank you. So let me start by asking you

14
00:00:43.330 --> 00:00:45.950
perhaps just to give a little bit of background

15
00:00:45.950 --> 00:00:50.869
to the interview. What is misinformation and how do

16
00:00:50.869 --> 00:00:53.709
you sort pack from misinformation?

17
00:00:54.520 --> 00:00:58.770
Yeah, absolutely. Uh, SO, um, I think it's kind

18
00:00:58.770 --> 00:01:02.330
of critical in this space to differentiate between three

19
00:01:02.330 --> 00:01:08.930
concepts here. Um, ONE is, um, misinformation, another disinformation,

20
00:01:09.050 --> 00:01:11.330
and the third fake news. So we're, we're starting

21
00:01:11.330 --> 00:01:13.290
to get our definitional ducks in a row here

22
00:01:13.290 --> 00:01:18.180
in this literature, in this space, and, uh, misinfo

23
00:01:18.569 --> 00:01:23.699
really is the broadest. It it means Basically, information,

24
00:01:23.790 --> 00:01:29.230
claims that are false, uh, empirically false, um, Uh,

25
00:01:29.449 --> 00:01:34.489
regardless of their intention, intentionality. Disinformation, right, it's a

26
00:01:34.489 --> 00:01:38.360
subset of that that is the intentionally deceptive material,

27
00:01:38.650 --> 00:01:43.129
and then fake news is, uh, widely seen as

28
00:01:43.129 --> 00:01:46.769
sort of a piece of that, further, the smallest

29
00:01:46.769 --> 00:01:49.529
piece of the sort of Russian nesting doll that

30
00:01:49.529 --> 00:01:55.010
is uh intentionally deceptive information that also is meant

31
00:01:55.010 --> 00:01:59.629
to mimic the way news looks. Um, TO an

32
00:01:59.629 --> 00:02:03.110
audience. So, the book, I use the term misinformation

33
00:02:03.110 --> 00:02:05.620
in the book, which is the broadest of those,

34
00:02:06.019 --> 00:02:09.059
um, to, to, you know, make sure I'm encompassing

35
00:02:09.059 --> 00:02:11.589
everything I'm, I talk about, but I'm sure various

36
00:02:11.589 --> 00:02:12.949
terms will come up and there's a bunch of

37
00:02:12.949 --> 00:02:14.229
different terms in the book, yeah.

38
00:02:15.289 --> 00:02:17.500
And what would you say are the main, the

39
00:02:17.500 --> 00:02:22.690
main domains in society where misinformation is most present

40
00:02:22.690 --> 00:02:24.729
and the most pernicious?

41
00:02:25.479 --> 00:02:27.860
Hm. That's a, that's a great question. I mean,

42
00:02:27.899 --> 00:02:30.130
it is, it is such a, it is such

43
00:02:30.130 --> 00:02:37.130
a cross-cutting, um, problem and interdisciplinary problem, um, for,

44
00:02:37.250 --> 00:02:41.539
uh, you know, different fields, uh, that it can

45
00:02:41.539 --> 00:02:44.570
be hard to, to see the full expanse there.

46
00:02:44.910 --> 00:02:47.009
Um, AND, you know, when I teach on it,

47
00:02:47.039 --> 00:02:49.839
I really get, um, students from all sorts of

48
00:02:49.839 --> 00:02:54.800
areas. Um, I think that, um, we have to

49
00:02:54.800 --> 00:02:58.630
look at, um, I think health and public health

50
00:02:59.039 --> 00:03:03.000
as one of the, uh, the, the, the key

51
00:03:03.000 --> 00:03:05.410
areas here. Uh, WHEN I, I have three sort

52
00:03:05.410 --> 00:03:07.160
of special topics towards the end of the course,

53
00:03:07.320 --> 00:03:12.320
health, uh, uh, climate slash environment, and, uh, and

54
00:03:12.320 --> 00:03:15.119
conflict. I mean, but you know, you could go

55
00:03:15.119 --> 00:03:18.720
to elections, you could go to many areas. Um,

56
00:03:18.750 --> 00:03:21.220
AND I think we see it cropping up, um,

57
00:03:21.309 --> 00:03:23.229
in so many parts of our lives.

58
00:03:24.389 --> 00:03:27.210
In the book, you focus on misinformation in the

59
00:03:27.210 --> 00:03:30.990
context of war. So what types of conflict of

60
00:03:30.990 --> 00:03:33.720
violent conflict do you tackle in the book?

61
00:03:34.800 --> 00:03:39.029
Um, SO the book is really pitched broadly, um,

62
00:03:39.279 --> 00:03:41.240
you know, we can talk about what I empirically

63
00:03:41.240 --> 00:03:44.279
focused on in the, in the cases of Pakistan,

64
00:03:44.600 --> 00:03:48.520
Iraq, and Syria, um, there, but it's meant to

65
00:03:48.520 --> 00:03:53.520
encompass really all situations of, of violent, um, armed

66
00:03:53.520 --> 00:03:56.520
conflict. Um, THAT you can encounter because all you

67
00:03:56.520 --> 00:03:58.880
really need for my theory and argument, which we'll,

68
00:03:58.960 --> 00:04:01.809
I'm sure talk about to hold is that there's

69
00:04:01.809 --> 00:04:05.520
sort of a variation in sort of what civilians

70
00:04:05.520 --> 00:04:08.600
think and their preferences and loyalties, um, and sort

71
00:04:08.600 --> 00:04:11.399
of their media diets, which of course, there will

72
00:04:11.399 --> 00:04:14.399
be in every, every situation to some, you know,

73
00:04:14.520 --> 00:04:17.720
in different ways, and then some are closer and

74
00:04:17.858 --> 00:04:21.200
and actually live the conflict. And others are further

75
00:04:21.200 --> 00:04:24.079
and sort of watch it um and through the

76
00:04:24.079 --> 00:04:27.160
media, and if those basic conditions hold, you have

77
00:04:27.160 --> 00:04:29.279
the potential for this this argument.

78
00:04:30.209 --> 00:04:35.000
Right. And when and why is misinformation a problem

79
00:04:35.000 --> 00:04:37.589
or do you think it's always a problem?

80
00:04:38.589 --> 00:04:40.220
Yeah, and I think we, I think we have

81
00:04:40.220 --> 00:04:42.260
to be sort of careful and responsible here. I

82
00:04:42.260 --> 00:04:45.540
fully, uh, you know, embrace and welcome and tackle

83
00:04:45.540 --> 00:04:48.179
these sorts of challenges. I have students debate them

84
00:04:48.179 --> 00:04:51.739
in my, in my, uh, course on misinfo and

85
00:04:51.739 --> 00:04:54.380
fake news, they have several structured debates, and one

86
00:04:54.380 --> 00:04:57.660
of the motions is the threat of misinformation is

87
00:04:57.660 --> 00:05:01.500
overblown, um, and they come with evidence and arguments

88
00:05:01.500 --> 00:05:04.760
on each side. And so, um. I don't think

89
00:05:04.760 --> 00:05:07.000
we should be overstating the problem. That said, I

90
00:05:07.000 --> 00:05:08.700
do think it is a real problem. I think

91
00:05:08.700 --> 00:05:09.779
we've had a sort of a bit of a

92
00:05:09.779 --> 00:05:16.170
pendulum there, um, from maybe overamplification during the COVID

93
00:05:16.170 --> 00:05:20.140
phase or earlier research, and then now there's maybe

94
00:05:20.140 --> 00:05:22.489
a a a pendulum swing the other way, and,

95
00:05:22.540 --> 00:05:25.459
and clearly it's um it's in the middle, and

96
00:05:25.459 --> 00:05:29.179
I think you see it being um more especially

97
00:05:29.179 --> 00:05:31.179
pernicious in some areas, just circling back to your

98
00:05:31.179 --> 00:05:34.700
other question. Yeah. And I'd highlight areas like public

99
00:05:34.700 --> 00:05:38.420
health and like elections, um, and to some extent

100
00:05:38.420 --> 00:05:42.380
conflict where People were, because it's it's acting on

101
00:05:42.380 --> 00:05:46.149
the individual. Right, it's, it's, it's a question of

102
00:05:46.149 --> 00:05:49.869
individual beliefs and the propagation of those. And so

103
00:05:50.200 --> 00:05:54.510
sit sort of domains in which just decentralized individual

104
00:05:54.510 --> 00:05:59.670
behavior is really important, like whether individuals decide to

105
00:05:59.670 --> 00:06:02.190
get a vaccine shot or not, or how they

106
00:06:02.190 --> 00:06:04.989
choose to vote, um, and there are some analogs

107
00:06:04.989 --> 00:06:09.500
in conflict, um, or maybe where you see it,

108
00:06:09.989 --> 00:06:11.700
rear its head most powerfully.

109
00:06:13.799 --> 00:06:17.769
AND in the context of war, specifically, what kinds

110
00:06:17.769 --> 00:06:21.250
of misinformation can we find? I mean, which aspects

111
00:06:21.250 --> 00:06:24.450
of war are targets of misinformation?

112
00:06:25.679 --> 00:06:28.190
Um, YEAH, I, I think, um, and it, I

113
00:06:28.190 --> 00:06:29.410
think it is a real problem and more and

114
00:06:29.410 --> 00:06:31.809
I think you do see, um, of course I

115
00:06:31.809 --> 00:06:34.609
do. I wrote the book on that, um, for

116
00:06:34.609 --> 00:06:37.130
that reason. I think you do see some different

117
00:06:37.130 --> 00:06:41.250
sort of categories or buckets of, of, um, of

118
00:06:41.250 --> 00:06:43.170
it. And, and this isn't the primary argument in

119
00:06:43.170 --> 00:06:46.220
the book, but something I've just sort of observed

120
00:06:46.570 --> 00:06:48.450
in the context of studying it, I think there

121
00:06:48.450 --> 00:06:51.970
are two big ones I'd highlight. One I think

122
00:06:51.970 --> 00:06:55.549
is um Broadly, what I would say sort of

123
00:06:55.549 --> 00:07:00.600
call misinformation about, um, you could say power. Um,

124
00:07:00.769 --> 00:07:04.730
AND, and performance in war. So really, who's winning

125
00:07:04.730 --> 00:07:09.649
and losing, uh, gaining and, and, um, territory or

126
00:07:09.649 --> 00:07:13.209
retreating, uh, stronger and weaker and all those sorts

127
00:07:13.209 --> 00:07:16.239
of things. And the other one is sort of,

128
00:07:16.410 --> 00:07:20.929
um, deception and manipulation about, um, you know, you

129
00:07:20.929 --> 00:07:26.059
could say behavior or harm slash care, um. Or

130
00:07:26.059 --> 00:07:28.540
victimhood, whatever you wanna call it. This is really

131
00:07:28.540 --> 00:07:32.970
the the the bucket of atrocity propaganda. A lot

132
00:07:32.970 --> 00:07:35.730
of it, right? Where we're gonna highlight and emphasize

133
00:07:35.730 --> 00:07:38.929
all the terrible things, and of course many terrible

134
00:07:38.929 --> 00:07:42.559
things are done in war to our side, um,

135
00:07:42.570 --> 00:07:46.329
and, uh, deny them in reverse. And um I

136
00:07:46.329 --> 00:07:49.250
think though there's one that's one way to think

137
00:07:49.250 --> 00:07:54.040
about it, and you see across different cases, um,

138
00:07:54.410 --> 00:07:57.329
you know, that some one of those categories is

139
00:07:57.329 --> 00:08:00.920
more emphasized than than um another. Happy to talk

140
00:08:00.920 --> 00:08:02.700
about that if you like.

141
00:08:03.440 --> 00:08:07.320
Yes, and do we know if people easily fall

142
00:08:07.320 --> 00:08:10.309
for misinformation related to war?

143
00:08:10.839 --> 00:08:12.839
Um, THAT'S a good question. I mean, I think

144
00:08:12.839 --> 00:08:17.899
certainly they do fall for misinformation, wartime misinformation, just

145
00:08:17.899 --> 00:08:21.679
like we are all vulnerable to, uh, all sorts

146
00:08:21.679 --> 00:08:26.970
of different, um, falsehoods in our lives, uh. I

147
00:08:26.970 --> 00:08:29.839
think there are some features of war that may

148
00:08:29.839 --> 00:08:35.080
make The problem, particularly severe, um, you know, the

149
00:08:35.080 --> 00:08:38.960
intense emotional nature of war, especially some kinds of

150
00:08:38.960 --> 00:08:45.000
wars and early on. Um, Uh, YOU would I

151
00:08:45.000 --> 00:08:47.320
have to look at the, the, the powerful way

152
00:08:47.320 --> 00:08:51.119
media becomes a weapon that's controlled, co-opted or biased

153
00:08:51.119 --> 00:08:54.489
in war, um, because the combat, you know, parties

154
00:08:54.489 --> 00:09:00.059
have incentives to, to, to do that, um. You

155
00:09:00.059 --> 00:09:02.080
know, so some of, some of the ways that

156
00:09:02.080 --> 00:09:05.640
war is so cognitively difficult and challenging to even

157
00:09:06.000 --> 00:09:09.530
um navigate or accept, uh, Um, some of the

158
00:09:09.530 --> 00:09:11.289
things that are done or the idea of it

159
00:09:11.650 --> 00:09:14.330
hitting your community. So, I think there are some

160
00:09:14.330 --> 00:09:19.320
factors that may make it, um, you know, add

161
00:09:19.320 --> 00:09:22.200
to the problem. It's, it, you know, but baseline

162
00:09:22.200 --> 00:09:24.960
we should expect that there's susceptibility just as there

163
00:09:24.960 --> 00:09:28.400
is susceptibility elsewhere, um, though, as I argue in

164
00:09:28.400 --> 00:09:29.960
the book, there are some features of war that

165
00:09:29.960 --> 00:09:32.349
also if, if you're in a certain, if you're

166
00:09:32.349 --> 00:09:35.270
in certain parts of it, um, can cut against

167
00:09:35.270 --> 00:09:35.559
that.

168
00:09:36.869 --> 00:09:42.179
Mhm. Uh, BUT isn't misinformation sort of commonplace in

169
00:09:42.179 --> 00:09:45.059
war? I mean, we many times hear about war

170
00:09:45.059 --> 00:09:49.900
propaganda. Shouldn't we expect it from all sides in

171
00:09:49.900 --> 00:09:50.409
the war?

172
00:09:51.780 --> 00:09:53.489
I mean, I think so. I think that's right.

173
00:09:53.570 --> 00:09:57.849
I think that's a reasonable baseline expectation, um, that

174
00:09:57.849 --> 00:10:02.080
when you have these um societies or communities mobilized

175
00:10:02.409 --> 00:10:06.409
for this extremely high stakes armed struggle, they're going

176
00:10:06.409 --> 00:10:10.969
to have strong incentives to um engage in, to

177
00:10:10.969 --> 00:10:14.820
manipulate um the information space and engage in um

178
00:10:14.820 --> 00:10:19.349
strategic communications sort of warfare. Uh, AS, as well

179
00:10:19.349 --> 00:10:21.909
as offline warfare, and, and we just saw this

180
00:10:21.909 --> 00:10:28.380
with the India-Pakistan uh conflict, um. Where Pakistan, um,

181
00:10:28.400 --> 00:10:31.799
the Pakistani government had a, uh, a sort of

182
00:10:31.799 --> 00:10:36.679
a ban on um Twitter usage, um, due to,

183
00:10:37.280 --> 00:10:41.119
you know, sort of extremely polarized situation in their

184
00:10:41.119 --> 00:10:44.669
own society and the military, not wanting, um, supporters

185
00:10:44.669 --> 00:10:48.799
of, of the populist leader Imran Khan to Um,

186
00:10:48.880 --> 00:10:51.510
the agitating on there, and they lifted it during

187
00:10:51.510 --> 00:10:54.179
the, the war, the brief war saying we are,

188
00:10:54.239 --> 00:10:59.630
are getting blasted online, um, and overwhelmed with India's

189
00:10:59.630 --> 00:11:02.359
communication power. We need to make sure we're out

190
00:11:02.359 --> 00:11:05.590
there advocating for our side. India and in uh,

191
00:11:05.599 --> 00:11:08.869
you know, Indian nationalists were doing thinking similarly. So

192
00:11:09.440 --> 00:11:12.000
I think you see the, the incentives that even

193
00:11:12.000 --> 00:11:14.400
admitting of those incentives and that that will happen

194
00:11:14.400 --> 00:11:16.280
everywhere in all conflicts.

195
00:11:16.969 --> 00:11:21.840
Mhm. And what are the consequences of misinformation during

196
00:11:21.840 --> 00:11:24.789
war? What kinds of consequences can it have?

197
00:11:26.349 --> 00:11:30.590
Um, I think it overall is, uh, should be

198
00:11:30.590 --> 00:11:33.950
viewed as a, as a danger, um, as a

199
00:11:33.950 --> 00:11:37.539
threat, um. You know, it is generally, I think,

200
00:11:37.549 --> 00:11:42.989
designed to um provoke and to incite. Um, CERTAINLY

201
00:11:42.989 --> 00:11:46.109
the atrocity, all that, the second category I highlighted,

202
00:11:46.179 --> 00:11:50.830
all the atrocity propaganda, um, is to, um, you

203
00:11:50.830 --> 00:11:55.789
know, enrage and, and incite and mobilize, um, your

204
00:11:55.789 --> 00:11:59.239
followers and other audiences who can support you. Um,

205
00:11:59.440 --> 00:12:02.960
AND so from there we can think about how

206
00:12:02.960 --> 00:12:07.190
it can lead to greater, uh, support, um, for,

207
00:12:07.479 --> 00:12:12.000
uh, wartime combatants, um, you know, contributions in various

208
00:12:12.000 --> 00:12:14.599
ways, even, even people participating in violence, and I

209
00:12:14.599 --> 00:12:18.880
think Some of the, uh, you know, I think

210
00:12:18.880 --> 00:12:22.880
it's an issue across wars, but sometimes when there's

211
00:12:22.880 --> 00:12:26.159
sort of communal mass violence is when it can

212
00:12:26.159 --> 00:12:29.559
be really dangerous because, um, like we, I was

213
00:12:29.559 --> 00:12:32.679
sort of earlier saying, when, you know, you have

214
00:12:32.679 --> 00:12:37.919
individual decentralized behavior, that's when um people's beliefs can

215
00:12:37.919 --> 00:12:40.830
easily translate into action. So when you're looking at,

216
00:12:40.919 --> 00:12:45.669
um, you know, ethnic mob riots in India. Uh,

217
00:12:45.830 --> 00:12:49.630
OR Sri Lanka or wherever, um, you know, maybe

218
00:12:49.630 --> 00:12:52.190
that's, um, where you can even see it more

219
00:12:52.190 --> 00:12:57.619
directly, uh, precipitating violence, but I think, um, Contributing

220
00:12:57.619 --> 00:13:02.700
to wars, uh, lengthening and intensifying, you can see

221
00:13:02.700 --> 00:13:04.070
uh uh many cases.

222
00:13:05.710 --> 00:13:09.340
Do we have a good understanding of the extent

223
00:13:09.340 --> 00:13:15.429
to which wartime misinformation might translate into actual behaviors

224
00:13:15.429 --> 00:13:20.789
like wars getting started or sparking more violence or

225
00:13:20.789 --> 00:13:24.869
people participating in wars and other kinds of social

226
00:13:24.869 --> 00:13:25.500
conflict?

227
00:13:26.640 --> 00:13:28.179
Yeah, and that's a great question. I like how

228
00:13:28.179 --> 00:13:31.460
you phrased that just asking us, do we have

229
00:13:31.460 --> 00:13:34.020
that understanding, what do we know? I mean, I

230
00:13:34.020 --> 00:13:36.859
do think that that is that we can, first

231
00:13:36.859 --> 00:13:39.179
of all, I'll say, I mean, we can see

232
00:13:39.179 --> 00:13:43.940
their their connections and contributions there, um. You know

233
00:13:43.940 --> 00:13:47.049
that, first of all, there's, we should think theoretically

234
00:13:47.049 --> 00:13:50.219
that there's a reason that You know, wartime actors,

235
00:13:50.229 --> 00:13:54.390
combatants engage in, go to such lengths to manipulate

236
00:13:54.820 --> 00:13:58.099
uh public uh perceptions of the facts on the

237
00:13:58.099 --> 00:14:01.179
ground about pain and suffering and who's doing what.

238
00:14:01.580 --> 00:14:06.960
Um, SO, Just off the bat there, um, You

239
00:14:06.960 --> 00:14:10.080
know, there there's should privilege us or, you know,

240
00:14:10.280 --> 00:14:12.919
push us to think that there's um there's value

241
00:14:12.919 --> 00:14:18.270
there, um. And um and I think then that

242
00:14:18.280 --> 00:14:21.710
that also theoretically, you know, if you're creating grievances,

243
00:14:22.119 --> 00:14:24.030
you know, that's one of the most central things

244
00:14:24.030 --> 00:14:27.119
in conflict. If you're in, you know, facilitating and

245
00:14:27.119 --> 00:14:30.679
entrenching people's grievances towards each other, um, we have

246
00:14:30.679 --> 00:14:33.270
a lot of that research on how that matters.

247
00:14:33.700 --> 00:14:38.599
Um, I think in terms of specifically, like hard

248
00:14:38.599 --> 00:14:43.039
research, drawing, showing the consequences of misinformation, I think

249
00:14:43.039 --> 00:14:45.929
that's one of the areas that is Um, that

250
00:14:45.929 --> 00:14:48.380
there, there should absolutely be more work there that's

251
00:14:48.380 --> 00:14:51.580
one of the hardest things to demonstrate, to independently

252
00:14:51.580 --> 00:14:57.099
show. What a misinformation narrative, how it um changes

253
00:14:57.099 --> 00:15:00.150
behavior in any sphere, um, and I think some

254
00:15:00.150 --> 00:15:03.119
folks are working on it. Um, BUT I think

255
00:15:03.119 --> 00:15:05.280
we can look at some cases and really a

256
00:15:05.280 --> 00:15:09.030
detailed understanding of cases, whether that is. The, the,

257
00:15:09.039 --> 00:15:11.320
uh, your strong campaign in Pakistan, which we might

258
00:15:11.320 --> 00:15:14.440
talk about or that's Nazi propaganda and misinformation in

259
00:15:14.440 --> 00:15:17.280
World War 2, and I think we can all

260
00:15:17.280 --> 00:15:20.469
there flesh out a pretty compelling story about how

261
00:15:20.880 --> 00:15:22.719
some of this has mattered too.

262
00:15:23.719 --> 00:15:27.400
Yeah. By the way, before we delve into the

263
00:15:27.400 --> 00:15:31.030
main argument of your book, uh, when it comes

264
00:15:31.030 --> 00:15:35.760
to wartime misinformation, has there been lots of work

265
00:15:35.760 --> 00:15:39.080
done on it for a long time, or is

266
00:15:39.080 --> 00:15:41.070
it something more recent?

267
00:15:41.919 --> 00:15:44.229
Well, I certainly thought there was an opening there,

268
00:15:44.239 --> 00:15:46.840
and I think, I, I, I think that's, that's

269
00:15:46.840 --> 00:15:49.750
right. I mean, I think. You know, there's certainly,

270
00:15:49.919 --> 00:15:51.880
there's been, I, I saw these as these two

271
00:15:51.880 --> 00:15:55.489
sort of ships, you know, these big, big, uh,

272
00:15:56.409 --> 00:15:58.130
You know, ships that were out there on the

273
00:15:58.130 --> 00:16:01.609
on on the water, there's this vast body of

274
00:16:01.609 --> 00:16:05.010
work on um conflict and and especially kind of

275
00:16:05.010 --> 00:16:08.630
increasingly on the The sort of ground level dynamics

276
00:16:08.630 --> 00:16:12.000
of conflict and um even individual a lot of

277
00:16:12.000 --> 00:16:16.630
public opinion work now um on conflict and how

278
00:16:16.630 --> 00:16:19.309
sort of people really think in in in such

279
00:16:19.309 --> 00:16:22.700
situations. And on the other hand, there's, you know,

280
00:16:22.989 --> 00:16:25.590
there had been a really blowing up this body

281
00:16:25.590 --> 00:16:29.669
of research on misinformation. I hadn't seen. Um, THE

282
00:16:29.669 --> 00:16:31.349
collision of those very much. There are a couple

283
00:16:31.349 --> 00:16:34.059
of articles um that have come out, but, um,

284
00:16:34.070 --> 00:16:36.869
there hadn't really been a a real serious social

285
00:16:36.869 --> 00:16:41.070
science book, um, that I'd seen trying to. Really

286
00:16:41.080 --> 00:16:44.510
focus in on and tackle that problem. Certainly there

287
00:16:44.510 --> 00:16:46.640
um there's a lot that I have to say

288
00:16:46.640 --> 00:16:49.780
I I built on. There's old work on um

289
00:16:49.780 --> 00:16:54.530
wartime propaganda. There's work in um by people who

290
00:16:54.530 --> 00:16:58.200
are uh journalists and people in communications on, on

291
00:16:58.200 --> 00:17:01.140
uh media and war and propaganda and more. So,

292
00:17:01.400 --> 00:17:04.800
but on this, uh, uh, trying to look, really

293
00:17:04.800 --> 00:17:11.550
theorize and analyze belief and misinformation in war. Um,

294
00:17:11.819 --> 00:17:15.579
AND, and, and it, you know, more. Protracted way

295
00:17:15.579 --> 00:17:17.770
at a book length way, um, I think there

296
00:17:17.770 --> 00:17:19.729
was not that much on that.

297
00:17:21.280 --> 00:17:23.880
And why do you think that's the case?

298
00:17:25.348 --> 00:17:28.609
Um, I mean, I think sort of misinformation studies

299
00:17:28.609 --> 00:17:31.900
had only sort of blown up, uh, You know,

300
00:17:32.060 --> 00:17:37.170
some years earlier, um, with, um, Trump's election and

301
00:17:37.180 --> 00:17:40.310
and Brexit and, and then COVID. So, you know,

302
00:17:40.420 --> 00:17:43.459
that was only uh emerging. There had been, of

303
00:17:43.459 --> 00:17:47.420
course, studies of conspiracy theories for years in psychology,

304
00:17:47.500 --> 00:17:50.520
but You know, so that was picking up steam,

305
00:17:50.930 --> 00:17:54.130
um, at the same time, people were increasingly sort

306
00:17:54.130 --> 00:17:57.920
of digging into that micro level of conflict, um,

307
00:17:57.930 --> 00:18:00.329
because they had the tools to do so more

308
00:18:00.329 --> 00:18:04.479
in the last couple decades, um, to get really

309
00:18:04.479 --> 00:18:09.180
rich data from conflict, uh. At the individual level.

310
00:18:09.469 --> 00:18:12.349
And so I think there were some methods, reasons

311
00:18:12.349 --> 00:18:14.869
and and some new theory things that were coming

312
00:18:14.869 --> 00:18:17.750
out and um but uh but I hadn't seen

313
00:18:17.750 --> 00:18:20.229
them fully collide there there yet.

314
00:18:20.939 --> 00:18:25.869
Right, so let's. AN argument of your book then,

315
00:18:26.319 --> 00:18:31.430
do we know which factors contribute to people's susceptibility

316
00:18:31.430 --> 00:18:35.349
to embracing misinformation in war?

317
00:18:37.040 --> 00:18:39.760
Well, I certainly hope so. I, I, uh, yeah,

318
00:18:40.079 --> 00:18:43.439
I, I hone in on two key, um, sort

319
00:18:43.439 --> 00:18:49.040
of pieces. So one is motivation, um, what I

320
00:18:49.040 --> 00:18:52.599
call motivation, and the other is information. Um, I

321
00:18:52.599 --> 00:18:54.709
think these do build on two of the big

322
00:18:54.709 --> 00:18:58.719
branches of what influences people's sort of factual beliefs

323
00:18:59.000 --> 00:19:02.430
and beliefs and misinformation in general. Um, AND there

324
00:19:02.430 --> 00:19:04.180
are other branches, and I can, I can get

325
00:19:04.180 --> 00:19:06.510
to those if you like. But how they see

326
00:19:06.510 --> 00:19:08.910
how I see them playing out here, when I

327
00:19:08.910 --> 00:19:12.699
say motivation, what I mean is, Sort of how

328
00:19:12.699 --> 00:19:15.859
you approach new information. What's your, you know, your

329
00:19:15.859 --> 00:19:18.979
psychological motivation when you do so, and there's a

330
00:19:18.979 --> 00:19:22.339
lot of work on how people have often, um,

331
00:19:22.949 --> 00:19:25.000
Uh, sort of engage in in that through a

332
00:19:25.000 --> 00:19:30.619
motivated reasoning lens, um. Uh, AND often we want

333
00:19:30.619 --> 00:19:35.579
to, uh, protect our and entrench and reinforce our

334
00:19:35.579 --> 00:19:41.540
identities. Um, THERE'S something called IPC identity Protective cognition

335
00:19:41.880 --> 00:19:44.079
in, in the US it's often partisan identities, a

336
00:19:44.079 --> 00:19:45.410
lot of research on this, or it can be

337
00:19:45.410 --> 00:19:49.680
racial or ethnic identities. Um, AND, and so we

338
00:19:49.680 --> 00:19:52.079
often approach this from new info in a biased

339
00:19:52.079 --> 00:19:55.880
way, um, and, and try to align it with

340
00:19:55.880 --> 00:19:59.160
our, our factual beliefs and select our information sources

341
00:19:59.160 --> 00:20:02.479
as well to do so. Um, AND yet, I

342
00:20:02.479 --> 00:20:06.239
think all that research is right, um, is important.

343
00:20:06.550 --> 00:20:09.729
And it, yet it has somewhat um forgotten a

344
00:20:09.729 --> 00:20:11.650
little bit of a a piece of its roots

345
00:20:11.650 --> 00:20:16.770
in the classic social psychology side, where uh a

346
00:20:16.770 --> 00:20:19.849
motivated bias or a directional motive was always the

347
00:20:19.849 --> 00:20:25.060
term. WAS contrasted with having an accuracy motive, which

348
00:20:25.060 --> 00:20:29.339
means that, yes, you, we sometimes have bias biases

349
00:20:29.339 --> 00:20:32.339
of various strengths, but some we can also have

350
00:20:32.339 --> 00:20:36.119
a desire to really get it right. Um, AND

351
00:20:36.119 --> 00:20:39.209
the, the, the sort of classic theory there was

352
00:20:39.209 --> 00:20:43.449
that when the stakes are raised for us of

353
00:20:43.449 --> 00:20:47.530
the issue or topic or situation, we'll often engage

354
00:20:47.530 --> 00:20:50.530
in a more thorough search for information and in

355
00:20:50.530 --> 00:20:54.449
a more objective and even-handed processing processing of, and

356
00:20:54.449 --> 00:20:56.810
that's been shown in the lab. And so the

357
00:20:56.810 --> 00:21:00.229
application of that here is to say that Um,

358
00:21:00.239 --> 00:21:04.180
with misinformation in, in something like war. Uh, YES,

359
00:21:04.270 --> 00:21:07.270
we have these loyalties and attitudes in, in, in

360
00:21:07.270 --> 00:21:09.939
conflict, uh, you know, you know, if we're in

361
00:21:09.939 --> 00:21:13.989
a situation in a, a conflict, we may, uh,

362
00:21:14.030 --> 00:21:16.260
you know, like in, in support the rebels or

363
00:21:16.260 --> 00:21:19.229
the regime more or other actors or, or, you

364
00:21:19.229 --> 00:21:21.989
know, maybe that there's bombing done by an outside

365
00:21:21.989 --> 00:21:25.760
power that's, you know, maybe it's detested and and

366
00:21:25.770 --> 00:21:30.069
and a civilian thinks that power has, um, you

367
00:21:30.069 --> 00:21:33.650
know, a sort of sinister motives. And so we'll

368
00:21:33.650 --> 00:21:37.920
have a motivated bias, that person will, to believe

369
00:21:37.920 --> 00:21:42.170
that the actual events um and what happened matched

370
00:21:42.760 --> 00:21:45.280
their perception of the actor, right? And that they,

371
00:21:45.400 --> 00:21:48.189
the motivation that they think the actor had that

372
00:21:48.199 --> 00:21:52.670
that maybe the bombing was indiscriminate. Um, AND yet,

373
00:21:53.719 --> 00:21:55.630
There's an accuracy motive that kicks in, and I

374
00:21:55.630 --> 00:21:59.719
argue when people are are are really experiencing more

375
00:21:59.719 --> 00:22:03.199
because there's tremendous variation in that of You know,

376
00:22:03.400 --> 00:22:06.599
war is so mediatized and social mediatized with millions

377
00:22:06.599 --> 00:22:10.089
of people viewing it now. Um, FOR, for good

378
00:22:10.089 --> 00:22:13.849
and ill, and yet there's these frontline populations that

379
00:22:13.849 --> 00:22:16.650
really live with the horrors of war, um, in,

380
00:22:16.729 --> 00:22:19.849
in eastern Ukraine, in Gaza, and in, in, in

381
00:22:19.849 --> 00:22:23.229
Iraq, wherever it is. And, um, you know, I'm

382
00:22:23.229 --> 00:22:27.099
talking about not just countries but Swaths of countries,

383
00:22:27.229 --> 00:22:32.800
areas, communities, villages. And they will have a powerful

384
00:22:33.380 --> 00:22:37.560
manifestation of this accuracy motivation to say, because why?

385
00:22:37.920 --> 00:22:39.770
THEIR lives can depend on it, their welfare. They

386
00:22:39.770 --> 00:22:42.209
need to know, should we flee this bombing or

387
00:22:42.209 --> 00:22:46.020
not? Should I, uh, uh, you know, try to

388
00:22:46.410 --> 00:22:52.209
give information. To the state authorities against the Islamic

389
00:22:52.209 --> 00:22:56.359
State in my villages, well, is there an opportunity

390
00:22:56.359 --> 00:22:58.489
to do that? What's the the the Islamic State

391
00:22:58.489 --> 00:23:01.400
doing to us? Is it? Is that true or

392
00:23:01.400 --> 00:23:04.969
not? Um, WHAT are the beliefs, what am I

393
00:23:04.969 --> 00:23:08.420
understanding of the state's behavior towards? And so, When

394
00:23:08.420 --> 00:23:11.859
they have a more powerful accuracy motive to really

395
00:23:11.859 --> 00:23:13.219
make sure they have as much as they can

396
00:23:13.219 --> 00:23:16.979
to grasp of that information about what's happening um

397
00:23:16.979 --> 00:23:19.579
around in their community. So that can create a

398
00:23:19.579 --> 00:23:22.699
cleavage and then informationally, I argue you get a

399
00:23:22.699 --> 00:23:24.849
reinforcement of that because of course, we can have

400
00:23:24.849 --> 00:23:28.339
informational biases um of all sorts, and the media,

401
00:23:28.369 --> 00:23:30.260
as I said, can really be a weapon in

402
00:23:30.260 --> 00:23:33.869
more, um, and so, We all have our biased

403
00:23:33.869 --> 00:23:36.060
media spheres we can fall into and in more,

404
00:23:36.229 --> 00:23:40.130
of course, the same, but for those frontline populaces,

405
00:23:40.670 --> 00:23:43.380
um, they will also be able to get more

406
00:23:43.380 --> 00:23:48.650
accurate and direct and local information relatively, um, because

407
00:23:48.869 --> 00:23:50.270
they are close to the scene of the crime

408
00:23:50.270 --> 00:23:54.819
and information spreads, um, horizontally via word of mouth

409
00:23:55.150 --> 00:23:58.310
and communal accumulated knowledge as well. And so both

410
00:23:58.310 --> 00:24:01.290
of these kind of align. And there's one thing

411
00:24:01.290 --> 00:24:03.369
we can talk about where it's a two two-pronged

412
00:24:03.369 --> 00:24:06.319
theory, it can be hard to split those mechanisms,

413
00:24:06.609 --> 00:24:08.729
but they both align and they kind of can

414
00:24:08.729 --> 00:24:12.250
create this powerful gap where these uh sort of

415
00:24:12.250 --> 00:24:18.910
exposed communities both have the greater means. And motives

416
00:24:19.119 --> 00:24:22.359
to know what's happening in war, and the opposite's

417
00:24:22.359 --> 00:24:24.880
true with people that are removed, who are really

418
00:24:24.880 --> 00:24:28.359
powerful, of course, audience and fright, various audiences and

419
00:24:28.640 --> 00:24:32.189
conflict too, so. That leads to the ultimate conclusion

420
00:24:32.189 --> 00:24:33.989
of the book. Seeing is disbelieving, and it's not

421
00:24:33.989 --> 00:24:36.959
the only Dimension here, but I think it's a

422
00:24:36.959 --> 00:24:37.719
really important one.

423
00:24:39.000 --> 00:24:43.439
So do the media themselves then contribute to these

424
00:24:43.439 --> 00:24:44.770
informational biases?

425
00:24:45.949 --> 00:24:48.560
Yeah, they they absolutely do. I mean, we shouldn't

426
00:24:48.900 --> 00:24:51.810
take that as just this fixed uh uh thing,

427
00:24:52.199 --> 00:24:55.390
um, you know, or, you know, one way of

428
00:24:55.390 --> 00:24:57.640
thinking about this, I'm not saying that people who

429
00:24:57.640 --> 00:25:02.469
are removed from war will automatically be brainwashed. Um,

430
00:25:02.479 --> 00:25:04.650
THEY will just be susceptible. There will be more

431
00:25:04.650 --> 00:25:07.989
room or space for all of the sort of

432
00:25:08.760 --> 00:25:12.119
factual distortions and biases that we have in our

433
00:25:12.119 --> 00:25:17.719
lives about the events. So, uh, You know, They

434
00:25:17.719 --> 00:25:19.520
may, it will depend on the direction of the

435
00:25:19.520 --> 00:25:26.050
bias, the media's bias. And their own orientation, um,

436
00:25:26.060 --> 00:25:28.810
but they, they, if, if those things push them,

437
00:25:29.260 --> 00:25:31.339
um, to be biased about what's happening in a

438
00:25:31.339 --> 00:25:34.699
conflict, um, it, they can certainly fall prey to

439
00:25:34.699 --> 00:25:34.939
it.

440
00:25:36.109 --> 00:25:39.910
And on the more motivational side of things, which

441
00:25:39.910 --> 00:25:44.430
kinds of motivations can people have to that make

442
00:25:44.430 --> 00:25:49.459
them understand the information more accurately or not?

443
00:25:50.520 --> 00:25:54.239
Well, um, I think it's really this survival motive

444
00:25:54.239 --> 00:25:58.030
that is very powerful and unique to these communities

445
00:25:58.239 --> 00:26:00.650
in war. I mean, it's, it's an accuracy drive

446
00:26:00.959 --> 00:26:03.160
in general, but it's like a powerful version of

447
00:26:03.160 --> 00:26:05.680
it, you know, the in, in the, um, and

448
00:26:05.680 --> 00:26:08.719
you can see, um, glimmers of this. I mean,

449
00:26:08.760 --> 00:26:11.119
we all, we all experience it to some extent.

450
00:26:11.199 --> 00:26:14.880
When we get anxious. You know, about something, uh,

451
00:26:14.959 --> 00:26:17.400
it can be that we need to desperately search

452
00:26:17.400 --> 00:26:22.119
for some information um about for let's say, uh,

453
00:26:22.180 --> 00:26:24.510
uh, something we don't understand that we're gonna teach

454
00:26:24.510 --> 00:26:27.640
or do in an interview, um, or there's just

455
00:26:27.640 --> 00:26:30.439
a feeling of, of threat, and, and so, oh

456
00:26:30.439 --> 00:26:32.880
my God, there's gonna be these tariffs, or there

457
00:26:32.880 --> 00:26:36.790
was this incident, um, that happened, these crimes, or

458
00:26:37.160 --> 00:26:39.560
possibly even a terrorist attack. I need to know

459
00:26:39.560 --> 00:26:41.280
something about that. I need to know this information.

460
00:26:41.650 --> 00:26:45.180
And you know, this is sort of um anxiety-based

461
00:26:45.180 --> 00:26:48.359
learning. I'm forgetting the Aim of the theoretical model

462
00:26:48.359 --> 00:26:53.660
and um affective. Forget that one. I'll have to

463
00:26:53.660 --> 00:26:56.180
get back to you about that. But that's a

464
00:26:56.180 --> 00:27:00.180
key idea and Sort of how we learn, um,

465
00:27:00.469 --> 00:27:04.709
and so, um, when, when there's that that same

466
00:27:04.709 --> 00:27:08.699
process can occur, I think, even more powerfully, uh,

467
00:27:08.709 --> 00:27:11.109
in, in war when you're really, when your survival

468
00:27:11.109 --> 00:27:13.229
is at stake, when the lives of you, you

469
00:27:13.229 --> 00:27:16.540
yourself and your family are on the line. Um,

470
00:27:16.880 --> 00:27:20.760
THEY'RE, you're gonna be pretty unflinching in your desire

471
00:27:20.760 --> 00:27:23.589
to make sure you can understand the threats, and,

472
00:27:23.800 --> 00:27:25.640
you know, you can look at people and, um,

473
00:27:25.680 --> 00:27:28.479
you know, there's some amazing quotes, um, in all

474
00:27:28.479 --> 00:27:32.400
sorts of conflicts. Um, I remember one, from the

475
00:27:32.400 --> 00:27:35.880
blitz in Britain, um, where it was a, um,

476
00:27:36.579 --> 00:27:39.910
Uh, uh, I think a secret British intelligence report,

477
00:27:40.300 --> 00:27:42.640
um, noting that because early on with the Blitz,

478
00:27:42.800 --> 00:27:46.469
the, the Nazis scored some, uh, sort of successes

479
00:27:46.680 --> 00:27:49.680
in hitting British cities, and, um, the British government

480
00:27:49.680 --> 00:27:51.709
was sort of concealing and covering up the extent

481
00:27:51.709 --> 00:27:54.959
of the damage, um, and sort of projecting this

482
00:27:54.959 --> 00:28:00.439
stiff upper lip. Mentality and uh um the the

483
00:28:00.439 --> 00:28:03.400
intelligence report was saying that people there's demand for

484
00:28:03.400 --> 00:28:06.329
more true and accurate information. So people were, even

485
00:28:06.329 --> 00:28:08.319
though there was this great threat, they wanted to

486
00:28:08.319 --> 00:28:11.520
know more. There was an accuracy search. Um, AND

487
00:28:11.520 --> 00:28:12.839
then the same way you can look in, you

488
00:28:12.839 --> 00:28:17.819
know, maybe in US, uh, Pakistan, uh, drone case,

489
00:28:18.150 --> 00:28:20.750
uh, they're the people in the, the Northwest Territories

490
00:28:20.750 --> 00:28:23.949
that really experienced that. There's some amazing, uh, or

491
00:28:23.949 --> 00:28:28.280
striking quotes as well, um. Talking about how it's

492
00:28:28.280 --> 00:28:30.689
so different if it's a lived experience for for

493
00:28:30.699 --> 00:28:33.280
for them, um, and it affects their day to

494
00:28:33.280 --> 00:28:35.400
day decision making and these sort of broad moral

495
00:28:35.400 --> 00:28:39.150
narratives about it being a sovereignty violation and and

496
00:28:39.189 --> 00:28:44.270
and sort of a continuation of um US, you

497
00:28:44.270 --> 00:28:46.770
know, aggression and this and that, which, you know,

498
00:28:46.849 --> 00:28:49.810
we could debate, they might be right, um, morally,

499
00:28:49.849 --> 00:28:52.209
but they don't think about that morally that way,

500
00:28:52.219 --> 00:28:54.719
and they, and so there's this quote about how

501
00:28:55.010 --> 00:28:56.849
they only get sort of a wounded smile from

502
00:28:56.849 --> 00:29:00.010
a a tribesman, um, who has to live thinking

503
00:29:00.010 --> 00:29:01.849
about this in their daily choices.

504
00:29:02.479 --> 00:29:04.920
Mhm. So let me just ask you a little

505
00:29:04.920 --> 00:29:08.390
bit about methodology here before we get into a

506
00:29:08.390 --> 00:29:11.359
few examples of war conflicts that you explore in

507
00:29:11.359 --> 00:29:15.599
the book. So empirically, how do you study people's

508
00:29:15.599 --> 00:29:20.599
factual beliefs and biases in war? What kinds of

509
00:29:20.599 --> 00:29:22.760
methodological approaches are there?

510
00:29:23.520 --> 00:29:29.099
Yeah, great question. Um, I think that um the

511
00:29:29.099 --> 00:29:31.099
book, you know, you have to get to the

512
00:29:31.099 --> 00:29:34.650
micro level for sure with this. You're studying populations,

513
00:29:34.959 --> 00:29:38.780
individuals, and their uh perceptions and beliefs. So the

514
00:29:38.780 --> 00:29:40.800
tools that we have to do that, you know,

515
00:29:40.900 --> 00:29:44.420
you can look at qualitative and quantitative tools, quantitatively

516
00:29:44.420 --> 00:29:48.020
talking about public opinion surveys and maybe um survey

517
00:29:48.020 --> 00:29:52.280
experiments, um, and the book does deploy. There's a

518
00:29:52.280 --> 00:29:54.319
lot of opinion data that I try to pack

519
00:29:54.319 --> 00:29:58.180
in there from existing sources like Pew. You know,

520
00:29:58.349 --> 00:30:01.339
bringing just so we have some context and descriptive

521
00:30:01.339 --> 00:30:04.819
understanding of the attitudes in somewhere like Pakistan, um,

522
00:30:05.189 --> 00:30:07.050
and then some surveys that I was able to

523
00:30:07.050 --> 00:30:10.349
get my hands on myself or fielded myself, um,

524
00:30:10.390 --> 00:30:14.329
and then, um. Uh, YOU know, so you have

525
00:30:14.329 --> 00:30:17.209
that, that sort of quantitative side, and then, you

526
00:30:17.209 --> 00:30:22.489
know, qualitatively, um, there's interviews and, and focus groups

527
00:30:22.489 --> 00:30:24.609
and other things, and the book uses some interviews,

528
00:30:24.619 --> 00:30:27.729
uh, from that were done in Syria. They were

529
00:30:27.729 --> 00:30:30.810
actually thankfully, uh, um, made available to me by

530
00:30:30.810 --> 00:30:33.770
a colleague who um did them and used them

531
00:30:33.770 --> 00:30:36.050
in, in, in his book, a couple 100 interviews

532
00:30:36.050 --> 00:30:39.609
with Syrian refugees in Turkey for a really more

533
00:30:39.609 --> 00:30:44.160
dense qua qualitative picture. So, Both of those are

534
00:30:44.160 --> 00:30:46.550
really useful. It is a I think mixed methods

535
00:30:46.550 --> 00:30:49.640
can be powerful here. Um, AND, and then I'd

536
00:30:49.640 --> 00:30:52.550
say lastly that you also should just have a,

537
00:30:52.640 --> 00:30:55.680
a, a deep and well read, hopefully qualitative knowledge

538
00:30:55.680 --> 00:30:59.030
of the context and um you should really try

539
00:30:59.030 --> 00:31:03.439
to know the anecdotal empirical record. Um, WHICH is,

540
00:31:03.449 --> 00:31:06.959
I think, a term that another scholar, Stathis Kalyvas

541
00:31:06.959 --> 00:31:12.119
uses, who's a, a noted conflict scholar, um. I

542
00:31:12.119 --> 00:31:13.630
don't know if you've interviewed him. Did you interview?

543
00:31:13.760 --> 00:31:17.280
No, no, OK, you've interviewed so many great people

544
00:31:17.280 --> 00:31:19.910
and, and, and I think a number of, uh,

545
00:31:20.410 --> 00:31:25.000
of, of, you know, prolific conflict scholars, um. That

546
00:31:25.000 --> 00:31:26.920
you should be sort of hopefully dripping with that

547
00:31:26.920 --> 00:31:31.770
knowledge, um, that you can use to really Flesh

548
00:31:31.770 --> 00:31:35.260
out and breathe life into your theories, um, too.

549
00:31:36.189 --> 00:31:40.670
Mhm. So let's uh illustrate all of what we've

550
00:31:40.670 --> 00:31:45.150
been talking about here with some examples of war

551
00:31:45.150 --> 00:31:48.150
conflicts. So could you tell us about the example

552
00:31:48.150 --> 00:31:52.030
of the US drone campaign in the tribal regions

553
00:31:52.030 --> 00:31:52.939
of Pakistan?

554
00:31:54.119 --> 00:31:56.640
Yes, absolutely. This became a key case in the

555
00:31:56.640 --> 00:31:59.640
book, uh, it was sort of happenstance, um, but

556
00:31:59.640 --> 00:32:03.489
I wound up being connected and embedded with, um,

557
00:32:03.680 --> 00:32:05.119
you know, I was interested in the broader Middle

558
00:32:05.119 --> 00:32:08.280
East and Islamic world, um, with the Pakistani communities

559
00:32:08.280 --> 00:32:10.280
in the US and then traveling to Pakistan and

560
00:32:10.280 --> 00:32:13.849
have um some close collaborators there who helped. Um,

561
00:32:13.979 --> 00:32:16.569
AND, you know, it's a situation that was salient,

562
00:32:16.780 --> 00:32:18.410
you know, at at the time I was writing,

563
00:32:18.459 --> 00:32:20.540
there were these debates about the US drone campaign

564
00:32:20.540 --> 00:32:23.510
in Pakistan, and were they, were they sort of,

565
00:32:23.540 --> 00:32:26.180
was there a blowback or not, these terms. I

566
00:32:26.180 --> 00:32:29.020
started to realize there was just tremendous variation in

567
00:32:30.130 --> 00:32:33.170
Pakistani perceptions of what was happening and even sort

568
00:32:33.170 --> 00:32:36.410
of factual perceptions. And so what are the facts

569
00:32:36.410 --> 00:32:39.449
first of all, um, there, you know, this became

570
00:32:39.449 --> 00:32:42.290
sort of an extension of the Afghan war, um,

571
00:32:42.369 --> 00:32:45.760
it was, you know, started, we were militant groups,

572
00:32:46.250 --> 00:32:49.369
um, that were, uh, sort of based in or

573
00:32:49.369 --> 00:32:53.119
had or getting some sanctuary in the um The

574
00:32:53.119 --> 00:32:57.189
tribal regions of Pakistan, Pakistan's a large diverse country

575
00:32:57.729 --> 00:33:01.239
of 200, 250 million people, but there's just one

576
00:33:01.239 --> 00:33:05.109
slice of it, um, called, uh, the Northwest uh

577
00:33:05.140 --> 00:33:09.829
uh territories of tribal regions of Pakistan. Um. And

578
00:33:09.829 --> 00:33:12.869
it's commonly referred to as Fatah. So uh the

579
00:33:12.869 --> 00:33:16.709
federally administered tribal areas, um, and it's sort of

580
00:33:16.709 --> 00:33:21.300
these borderlands. This one small slice of Pakistan on

581
00:33:21.300 --> 00:33:25.890
the Afghan border, and it's long been relatively ungoverned

582
00:33:26.219 --> 00:33:30.760
and volatile and had significant challenges with Islamist militancy,

583
00:33:31.099 --> 00:33:33.500
um, and some groups like the Pakistani Taliban, as

584
00:33:33.500 --> 00:33:34.939
well as some of the groups really active in

585
00:33:34.939 --> 00:33:39.619
Afghanistan, um, were heavily based there. And so, As

586
00:33:39.819 --> 00:33:41.459
on through the course of this war and the

587
00:33:41.459 --> 00:33:44.060
Bush and and then you know, perhaps even more

588
00:33:44.060 --> 00:33:47.540
so the Obama years, um, there came to be

589
00:33:47.540 --> 00:33:52.689
this this significant um US um use of armed

590
00:33:53.060 --> 00:33:57.339
uh drones, unmanned vehicles as one of the ways

591
00:33:57.339 --> 00:34:01.339
along with the Pakistani military operations too, um, to

592
00:34:01.339 --> 00:34:03.219
sort of in their view, try to meet this

593
00:34:03.219 --> 00:34:07.329
challenge and target. Um, THE militant, uh, key leaders

594
00:34:07.599 --> 00:34:10.879
and degrade these groups, um, that were, uh, you

595
00:34:10.879 --> 00:34:15.840
know, key to destabilizing Afghanistan and, and Pakistan, um.

596
00:34:17.110 --> 00:34:19.188
To a degree. And so, you know, we can

597
00:34:19.188 --> 00:34:21.310
have all sorts of discussions and debates about this

598
00:34:21.310 --> 00:34:24.070
as well as sort of broader Use of drone

599
00:34:24.070 --> 00:34:27.550
warfare, in fact, not taking moral positions on that.

600
00:34:27.629 --> 00:34:31.688
What I'm looking at is this question of factually

601
00:34:31.688 --> 00:34:36.179
what happened and then You know, perceptions and misperceptions

602
00:34:36.179 --> 00:34:38.139
around that in Pakistan. And it became a really

603
00:34:38.139 --> 00:34:42.620
salient issue in Pakistani society. Of course, understandably, there's

604
00:34:42.620 --> 00:34:46.820
a lot of suspicion and um I think what

605
00:34:46.820 --> 00:34:51.789
word to use best here. Um, You know, mistrust

606
00:34:51.789 --> 00:34:56.728
and and uh baggage towards the US in Pakistan,

607
00:34:57.138 --> 00:34:59.898
um, as a result of US foreign policy towards

608
00:34:59.898 --> 00:35:04.059
the country over decades, and, um, and towards Afghanistan

609
00:35:04.059 --> 00:35:08.629
and so on. And so, um, and, and, and

610
00:35:08.629 --> 00:35:11.919
there came to be a real Uh, sort of

611
00:35:11.919 --> 00:35:16.840
explosion of of protests, um, hundreds if not thousands

612
00:35:16.840 --> 00:35:19.199
of protests against these drones during the height of

613
00:35:19.199 --> 00:35:24.219
the campaign, um, uh, and, and ultimately, and some

614
00:35:24.219 --> 00:35:26.159
of them became, you know, sort of armed or

615
00:35:26.159 --> 00:35:30.110
violent protests. There were a number of attacks stopping,

616
00:35:30.479 --> 00:35:33.969
um, Pakistan um was sort of the key. Um,

617
00:35:34.139 --> 00:35:39.659
uh, SUPPLY, um, route to Afghanistan from the Pakistani

618
00:35:39.659 --> 00:35:42.219
ports in the south of the country. Um, ULTIMATELY

619
00:35:42.219 --> 00:35:44.060
they had to be rerouted so that it went

620
00:35:44.060 --> 00:35:48.100
more extensively through Central Asia. Um, AND so the

621
00:35:48.100 --> 00:35:51.260
US scaled back its presence in Pakistan. Um, THERE

622
00:35:51.260 --> 00:35:53.939
were some other flash points too, but the, the

623
00:35:53.939 --> 00:35:57.699
drone campaign, the use of Pakistani territory for it

624
00:35:57.699 --> 00:36:02.510
and the uh killings in, um, The tribal regions

625
00:36:02.510 --> 00:36:07.860
became a political flashpoint, um, and ultimately helped, uh,

626
00:36:07.870 --> 00:36:10.229
were one factor that helped elect uh the gentleman

627
00:36:10.229 --> 00:36:12.830
I mentioned earlier, Imran Khan, who's played a key

628
00:36:12.830 --> 00:36:15.729
role and and still does in current Pakistani politics.

629
00:36:15.790 --> 00:36:20.699
So politically influential. The key with the misperceptions is

630
00:36:20.699 --> 00:36:25.639
that, um, in fact, uh, in this case, in,

631
00:36:25.719 --> 00:36:28.969
in despite what we might say about them, um,

632
00:36:28.979 --> 00:36:33.929
in other ways that they were a relatively targeted

633
00:36:34.179 --> 00:36:39.939
and low civilian casualty compared to militants, uh, instantiation

634
00:36:39.939 --> 00:36:43.870
of political violence. Um, IN the tribal regions, and

635
00:36:43.870 --> 00:36:45.830
that's not what people would have believed. You can

636
00:36:45.830 --> 00:36:49.550
imagine how their, their motivated biases, how their media

637
00:36:49.550 --> 00:36:52.100
environment would have pushed them in the other direction,

638
00:36:52.429 --> 00:36:54.229
um, with all the things the US has done

639
00:36:54.229 --> 00:36:57.709
in Pakistan and Afghanistan, they would have, most Pakistanis

640
00:36:57.709 --> 00:37:01.469
would, would have been easy to believe and easy

641
00:37:01.469 --> 00:37:04.310
for elites to whip up a sentiment that they're,

642
00:37:04.550 --> 00:37:09.389
they're indiscriminate uh death machines. And scourges killing scores

643
00:37:09.389 --> 00:37:11.870
of civilians all the time, and there there were

644
00:37:11.870 --> 00:37:15.110
mistakes, but by and large that's not true, and

645
00:37:15.110 --> 00:37:20.340
there's evidence from WikiLeaks where Pakistani officials uh admit

646
00:37:20.750 --> 00:37:25.510
um that that's not true. Um THERE'S um various

647
00:37:25.510 --> 00:37:28.989
forms, there's even some public admissions that are a

648
00:37:28.989 --> 00:37:32.919
few things as the campaign bore on. Um, AND

649
00:37:32.919 --> 00:37:36.639
of course, most people from the tribal areas do

650
00:37:36.639 --> 00:37:38.229
not think that is true and, and know that

651
00:37:38.239 --> 00:37:41.520
that is not true, and that's key here. If

652
00:37:41.520 --> 00:37:44.320
you actually listen and speak to them, they will

653
00:37:44.320 --> 00:37:47.000
say, look, we're no friend of the US, but

654
00:37:47.000 --> 00:37:50.479
mostly that was targeting the key militants, um, and

655
00:37:50.479 --> 00:37:52.399
it, and, you know, there were some mistakes and

656
00:37:52.399 --> 00:37:55.189
it and they were annoying and disruptive. They sometimes

657
00:37:55.560 --> 00:37:58.820
have a term referring to them as insects. Um,

658
00:37:59.149 --> 00:38:03.620
BUT they were not causing mass civilian deaths. Um,

659
00:38:03.750 --> 00:38:07.310
IT'S, and, and, and it was the Pakistani army's

660
00:38:07.310 --> 00:38:12.709
heavy-handed, uh, military campaigns, um, dropping heavy bombs on

661
00:38:12.709 --> 00:38:16.979
villages and having operations that cleared areas. Um, AND

662
00:38:16.979 --> 00:38:20.689
it was the Pakistani Taliban's use of, of terror

663
00:38:20.979 --> 00:38:24.419
and efforts to coercively control their society that they

664
00:38:24.419 --> 00:38:28.929
knew comparatively were much um more indiscriminate in nature.

665
00:38:28.979 --> 00:38:31.540
And, and now there are even some pretty rigorous

666
00:38:31.540 --> 00:38:33.500
research studies. At first this was sort of a

667
00:38:33.500 --> 00:38:39.530
hypothesis. Um, And you could hear different things, um,

668
00:38:39.800 --> 00:38:42.399
but by now the best, and there were some

669
00:38:42.399 --> 00:38:45.479
NGOs that had, I think, a political motive pushing

670
00:38:45.479 --> 00:38:49.750
back on it, um. There are now multiple research

671
00:38:49.750 --> 00:38:53.120
studies, the best research studies, not by me but

672
00:38:53.120 --> 00:38:56.229
by Pakistani political scientists. Two of them interviewing hundreds

673
00:38:56.229 --> 00:38:59.139
of people who were displaced from the tribal areas,

674
00:38:59.500 --> 00:39:02.229
um, one by a gentleman named Akhil Shah, um,

675
00:39:02.350 --> 00:39:04.870
that's published in their public pieces in the Washington

676
00:39:04.870 --> 00:39:09.649
Post and elsewhere, and another by, um, Uh, uh,

677
00:39:09.659 --> 00:39:13.780
female scholar Nehan Sari, um, who last I checked

678
00:39:13.780 --> 00:39:15.629
was a doctoral student at Harvard, may, may have

679
00:39:15.629 --> 00:39:19.060
graduated, um, has also written about this, and, and

680
00:39:19.060 --> 00:39:20.739
I think it's a part of her dissertation work.

681
00:39:20.820 --> 00:39:23.979
So, and, and, and various others in the country,

682
00:39:24.139 --> 00:39:26.739
journalists and scholars, and really when you look at

683
00:39:26.739 --> 00:39:29.699
this whole ball of evidence, and this whole understanding

684
00:39:29.699 --> 00:39:32.770
of what goes on there, um, it's quite clear

685
00:39:33.020 --> 00:39:36.419
that um there is this gap, a powerful gap

686
00:39:36.419 --> 00:39:39.739
where the local population. Um, IS thinking very differently

687
00:39:39.739 --> 00:39:43.770
than this broader population, um, that was mobilized against

688
00:39:43.770 --> 00:39:46.340
the campaign. And so it's just a very clear

689
00:39:46.340 --> 00:39:51.379
and, and fascinating and powerful case of of that

690
00:39:51.379 --> 00:39:55.090
sort of proximity based belief situation.

691
00:39:55.620 --> 00:40:00.179
Mhm. How about the Syrian civil war, how have

692
00:40:00.179 --> 00:40:04.649
the sorts of phenomena we talked about here, uh,

693
00:40:04.659 --> 00:40:05.820
manifested there?

694
00:40:06.959 --> 00:40:08.919
Yeah, I'm sure. I'm happy to talk about that

695
00:40:08.919 --> 00:40:10.860
one. THE other case was a rock and it

696
00:40:10.860 --> 00:40:13.149
points in a similar, um, direction, a little more

697
00:40:13.149 --> 00:40:16.219
quantitatively. I wound up studying that one. And then

698
00:40:16.219 --> 00:40:18.449
I was very lucky and fortunate to be able

699
00:40:18.449 --> 00:40:21.330
to study, to get my hands on some data

700
00:40:21.330 --> 00:40:24.260
information to let me dig into the case in

701
00:40:24.260 --> 00:40:27.739
Syria because it's such a different case. It's um

702
00:40:27.739 --> 00:40:31.219
Iraq and Pakistan, when, when people see what I

703
00:40:31.219 --> 00:40:32.699
looked at and analyzed there, and it was sort

704
00:40:32.699 --> 00:40:35.550
of Happenstance in a way, they say, well, you're

705
00:40:35.550 --> 00:40:38.000
just looking at sort of this US violence and

706
00:40:38.469 --> 00:40:42.709
people's perceptions about that maybe being overblown. And that

707
00:40:42.709 --> 00:40:45.830
can lead to some sort of questions and uh

708
00:40:46.229 --> 00:40:48.060
uh you know, how is this really a general?

709
00:40:48.250 --> 00:40:51.739
Syria is so different. It's a many-sided civil war.

710
00:40:52.030 --> 00:40:55.949
It was thankfully ended recently. Um, IT was not

711
00:40:55.949 --> 00:41:00.310
heavily about the US and and anti-US insurgency, um,

712
00:41:00.629 --> 00:41:04.620
and there were all sorts of misbeliefs, um, that,

713
00:41:04.629 --> 00:41:05.949
uh, I was able to look at. I was

714
00:41:05.949 --> 00:41:07.669
thankfully, I think I mentioned able to get my

715
00:41:07.669 --> 00:41:11.060
hands on a couple 100 really rich interviews. Done

716
00:41:11.060 --> 00:41:15.290
by um a a great uh scholar, uh, Justin

717
00:41:15.290 --> 00:41:17.820
Scho, and for his book Surviving the war in

718
00:41:17.820 --> 00:41:23.449
Syria. Um, And um he asked really about their

719
00:41:23.659 --> 00:41:26.939
detailed choices during the war, about their migration paths.

720
00:41:27.060 --> 00:41:29.939
He was interested, among other things, but he crucially

721
00:41:29.939 --> 00:41:33.610
did ask several questions about um their belief in

722
00:41:33.739 --> 00:41:36.449
rumors. And he wrote a nice piece on this,

723
00:41:36.580 --> 00:41:38.419
but I felt like there was more to mine

724
00:41:38.419 --> 00:41:39.939
and more to exploit. So I asked him for

725
00:41:39.939 --> 00:41:42.620
that, um, a colleague and collaborative and friend, he,

726
00:41:42.649 --> 00:41:45.419
he was happy to give them to me, and

727
00:41:45.419 --> 00:41:50.500
I sort of mined those transcripts. Qualitatively and quantitatively,

728
00:41:50.830 --> 00:41:53.780
and I was able to get info on people's

729
00:41:54.070 --> 00:41:56.899
really paint a picture of what rumors they believed.

730
00:41:57.729 --> 00:42:00.030
In Syria, and there were all sorts of rumors

731
00:42:00.030 --> 00:42:04.429
believed, um, rumors about the Assad's death constantly cropping

732
00:42:04.429 --> 00:42:06.669
up, and many people knew those were false, but

733
00:42:06.669 --> 00:42:09.989
there was manipulation about which, you know, sides were

734
00:42:09.989 --> 00:42:13.889
winning, people hiding atrocities, and, and it's harrowing stuff

735
00:42:13.889 --> 00:42:16.870
sometimes, and but you see glimmers of of people

736
00:42:16.870 --> 00:42:19.870
who are more exposed, um, you know, of course,

737
00:42:19.909 --> 00:42:22.770
you can see this in the text qualitatively. Saying

738
00:42:22.770 --> 00:42:24.610
that the regime told us that there was no

739
00:42:24.610 --> 00:42:26.810
massacre, but I went to the square and I

740
00:42:26.810 --> 00:42:28.290
saw the bodies in the trees and all these

741
00:42:28.290 --> 00:42:32.260
horrible things. But you see how people who really

742
00:42:32.260 --> 00:42:34.500
are there and are seeing things and and they

743
00:42:34.500 --> 00:42:36.300
know over time that the media is going to

744
00:42:36.300 --> 00:42:38.500
be lying to them, and they have these bases

745
00:42:38.500 --> 00:42:41.020
from which to form um more accurate and informed

746
00:42:41.020 --> 00:42:45.100
beliefs. And then quantitatively, he had a key question

747
00:42:45.100 --> 00:42:48.860
saying um how confident are you in your ability

748
00:42:48.860 --> 00:42:52.379
to discern fact of or whether rumors were true

749
00:42:52.379 --> 00:42:55.139
and false, and I could I I show, it's

750
00:42:55.139 --> 00:42:58.229
a couple 100 people, but there's very suggestive. And

751
00:42:59.010 --> 00:43:01.929
and I think nicely supportive, complimentary with the other.

752
00:43:02.790 --> 00:43:07.000
Piece of the book Relationships showing that people who

753
00:43:07.000 --> 00:43:10.560
were in Syria longer, people who saw, said they

754
00:43:10.560 --> 00:43:14.899
saw more different types of um like uh violence,

755
00:43:15.199 --> 00:43:18.429
all these things really strongly correlate with people saying

756
00:43:18.429 --> 00:43:22.000
they are uh more confident, have a greater uh

757
00:43:22.000 --> 00:43:26.439
discernment ability uh in the war. And so, it

758
00:43:26.439 --> 00:43:29.459
sort of paints this different picture. I think that

759
00:43:29.459 --> 00:43:32.139
helps, I hope, flesh out uh what is going

760
00:43:32.139 --> 00:43:34.459
on and show applies in a lot of different

761
00:43:34.459 --> 00:43:37.810
situations and to a lot of um different uh

762
00:43:37.810 --> 00:43:39.659
rumors and types of misinfo.

763
00:43:40.939 --> 00:43:44.659
Can you comment on what's been happening in Ukraine

764
00:43:44.659 --> 00:43:48.649
and Gaza? I mean, these are probably the most,

765
00:43:48.820 --> 00:43:52.500
uh, prominent or if not prominent, at least the

766
00:43:52.500 --> 00:43:55.780
ones that are the, the two armed conflicts that

767
00:43:55.780 --> 00:43:58.620
are the most salient on the news right now.

768
00:43:58.699 --> 00:44:02.459
So do we see similar phenomena playing out there?

769
00:44:03.290 --> 00:44:06.090
Of course, of course, and it depends how much

770
00:44:06.090 --> 00:44:09.090
time you have in terms of trying to comment

771
00:44:09.090 --> 00:44:12.320
on those, you could, you could have long discussions

772
00:44:12.320 --> 00:44:14.270
of each, and, and I, I, you know, I,

773
00:44:14.370 --> 00:44:15.810
I was making a face as you were doing

774
00:44:15.810 --> 00:44:20.590
that because they're both tragic, tragic situations, um. But

775
00:44:20.590 --> 00:44:24.229
I think you do see these dynamics, um, sort

776
00:44:24.229 --> 00:44:28.209
of manipulation of facts and misinformation has been powerful

777
00:44:28.469 --> 00:44:30.979
in both, um, and it was striking to me.

778
00:44:30.989 --> 00:44:32.669
I remember and I wrote about this, I think

779
00:44:32.669 --> 00:44:35.659
in the book's preface, because I was like completing

780
00:44:35.659 --> 00:44:39.239
this book. Um, THAT I'd started on these other

781
00:44:39.239 --> 00:44:42.590
conflicts way earlier, and I was like, wow, this,

782
00:44:42.979 --> 00:44:45.739
um, this is really powerful, what's happening? And I,

783
00:44:45.780 --> 00:44:47.939
and, and very emotional, and I'm connected to some

784
00:44:47.939 --> 00:44:50.379
of those conflicts, and I was like, it's, it

785
00:44:50.379 --> 00:44:52.899
was pretty wild to see all the people, and

786
00:44:52.899 --> 00:44:57.409
even myself sometimes, you know, being susceptible to misinfo,

787
00:44:57.939 --> 00:45:00.020
um, but also at the same time seeing some

788
00:45:00.020 --> 00:45:02.060
of those limits. So I mean in in the

789
00:45:02.060 --> 00:45:06.149
Russian Ukrainian conflict, um, I think there's been misinformation

790
00:45:06.149 --> 00:45:08.590
on both sides, but much more on the Russian

791
00:45:08.590 --> 00:45:11.590
by the Russian side. Um, THERE is something to

792
00:45:11.590 --> 00:45:14.820
that, by the way. And in terms of the

793
00:45:14.820 --> 00:45:19.550
variation in which side pours out more misinfo. I

794
00:45:19.550 --> 00:45:22.050
think you asked or you sort of got a

795
00:45:22.050 --> 00:45:24.790
maybe a question about this earlier. You know, I

796
00:45:24.790 --> 00:45:27.590
think that the parties and the combatants and where

797
00:45:27.590 --> 00:45:30.580
they have more to hide in terms of our

798
00:45:30.580 --> 00:45:35.550
committing more atrocities, and also maybe are not performing

799
00:45:35.550 --> 00:45:38.270
as well, are where you will see more factual

800
00:45:38.270 --> 00:45:44.110
manipulation, um, and so Russia's pushed, poured out plenty

801
00:45:44.110 --> 00:45:49.760
of that, um, about the The alleged Nazis and

802
00:45:49.760 --> 00:45:52.719
notification of of Ukraine and the leadership and all

803
00:45:52.719 --> 00:45:54.760
this, as well as hiding some of their setbacks

804
00:45:54.760 --> 00:45:57.489
and defeats and Um, some of the atroc they've

805
00:45:57.489 --> 00:46:01.199
had atrocity propaganda going back years in Ukraine, the,

806
00:46:01.209 --> 00:46:05.169
the quote unquote crucified boy. With something that they

807
00:46:05.169 --> 00:46:08.810
pushed in the Donbass War in 2014, 2015 um

808
00:46:08.810 --> 00:46:13.899
on uh um. Art, um, what's the channel, one

809
00:46:13.899 --> 00:46:17.000
of the state TV channels, Russian one, was it,

810
00:46:17.280 --> 00:46:19.969
um, claiming that, uh, there was a, you know,

811
00:46:20.129 --> 00:46:22.050
a, a boy in a Russian speaking boy in

812
00:46:22.050 --> 00:46:25.199
eastern Ukraine who'd been literally crucified by Ukrainian soldiers,

813
00:46:25.209 --> 00:46:27.850
and it turned out to be totally false and

814
00:46:27.850 --> 00:46:30.000
there was a whole scandal and apology and everything.

815
00:46:30.010 --> 00:46:34.919
And so, um. You know, there there clearly is,

816
00:46:34.929 --> 00:46:38.969
is this um massive propaganda pushed by Russia and,

817
00:46:39.129 --> 00:46:41.520
and some, some a little bit by Ukraine too,

818
00:46:41.530 --> 00:46:44.449
and, but you see that it's not been very

819
00:46:44.449 --> 00:46:48.879
effective and influential on Ukrainians, um, Ukrainian including especially,

820
00:46:48.889 --> 00:46:52.719
I think, eastern Ukrainians, um, and Ukrainians in the

821
00:46:53.129 --> 00:46:57.040
contested areas, um, where, you know, there are really

822
00:46:57.040 --> 00:47:00.310
striking quotes saying when you're bombed. It changes your

823
00:47:00.310 --> 00:47:03.030
mind about things, and those would be some of

824
00:47:03.030 --> 00:47:07.070
the populations that, you know, might have not been

825
00:47:07.070 --> 00:47:09.989
as much slamming the door in some ways on

826
00:47:09.989 --> 00:47:12.989
Russia in the past due to some more linguistic

827
00:47:12.989 --> 00:47:16.790
and ethnic and other ties. Um, SO that's a

828
00:47:16.790 --> 00:47:19.350
sensitive issue, of course, they're uh part of the

829
00:47:19.350 --> 00:47:23.360
Ukrainian community. But, uh, but I think we see

830
00:47:23.360 --> 00:47:25.090
some of that falling flat, and, and two, we

831
00:47:25.090 --> 00:47:28.399
see it falling flat um with Russian soldiers. That's

832
00:47:28.399 --> 00:47:32.199
another area. It's not all just civilians, um, and

833
00:47:32.199 --> 00:47:35.040
people debunking things on social media, but soldiers are

834
00:47:35.040 --> 00:47:38.840
in a way, there's also population that experiences war,

835
00:47:38.879 --> 00:47:41.320
and there there's variability there and how much, what

836
00:47:41.320 --> 00:47:45.330
they see. Um, AND how indoctrinated they are, but

837
00:47:45.330 --> 00:47:48.090
you get all these stories of Russian soldiers, and

838
00:47:48.090 --> 00:47:50.100
I view many of them as, as victims too,

839
00:47:50.250 --> 00:47:54.919
thrown into this meat grinder, um. And saying this

840
00:47:54.919 --> 00:47:57.060
isn't what we were sent to do. We realized

841
00:47:57.060 --> 00:47:59.000
as soon as we got there, we, there was

842
00:47:59.000 --> 00:48:02.040
this population with bristling hostility to us, and we

843
00:48:02.040 --> 00:48:04.909
weren't liberators, um, and the New York Times had

844
00:48:04.909 --> 00:48:08.399
some intercepted calls from Russian soldiers back home saying,

845
00:48:08.590 --> 00:48:10.159
Mom, this is horrible, we don't know what we're

846
00:48:10.159 --> 00:48:12.879
doing here. And so that's part of the reason

847
00:48:12.879 --> 00:48:17.110
Putin has had such a vicious clampdown on soldiers,

848
00:48:17.239 --> 00:48:22.979
um, political maybe Propagation and activity back home. There's

849
00:48:22.979 --> 00:48:26.429
was it's an NGO called the Committee for the

850
00:48:26.429 --> 00:48:29.419
Union of Soldiers' Mothers that has been historically active

851
00:48:29.419 --> 00:48:32.219
in Russia. If not, he's either disbanded it or

852
00:48:32.219 --> 00:48:35.979
suppressed it. Um, AND I think they represent one

853
00:48:35.979 --> 00:48:38.939
of the real ways, along with maybe people ethnic

854
00:48:38.939 --> 00:48:42.419
ties between Ukrainians and Russians, many of them have

855
00:48:42.419 --> 00:48:45.500
family, and they call each other, even still to

856
00:48:45.500 --> 00:48:47.620
this day through the war. Um, AND so there

857
00:48:47.620 --> 00:48:50.580
are ways through which the information spreads back into

858
00:48:50.580 --> 00:48:53.300
Russia, and you can see Putin trying and the

859
00:48:53.300 --> 00:48:56.260
Kremlin clamp down on that, um, and we could

860
00:48:56.260 --> 00:48:59.540
talk about the, the handful of Ukrainian, um, stories

861
00:48:59.540 --> 00:49:02.199
and conspiracy theories too. There's not been no misinformation

862
00:49:02.199 --> 00:49:06.159
on that side. um. But you can see some

863
00:49:06.159 --> 00:49:09.389
of that happening even even as It's not really

864
00:49:09.389 --> 00:49:12.280
one. Um, HAPPY to talk about Gaza too, of

865
00:49:12.280 --> 00:49:15.959
course, a terribly ugly tragic conflict, um, and I

866
00:49:15.959 --> 00:49:20.669
think you have uh misinfo, um, and, and conspiracy

867
00:49:20.669 --> 00:49:24.040
theories, um, and hate speech and all the other

868
00:49:24.040 --> 00:49:28.520
informational bads on all sides. Um, I will say

869
00:49:28.520 --> 00:49:31.239
both of these are are sort of interstate conflicts

870
00:49:31.239 --> 00:49:34.350
in my view. Israel Gaza is a difficult one,

871
00:49:34.360 --> 00:49:37.520
but You don't, in, in part of what it's

872
00:49:37.520 --> 00:49:42.649
Civil War. You know, you do have these population

873
00:49:43.060 --> 00:49:47.110
mixing more, um. And, and you get a little

874
00:49:47.110 --> 00:49:49.419
bit more, a little less scope for what I'm

875
00:49:49.419 --> 00:49:53.219
talking about in like Israel, Gaza, because It's all

876
00:49:53.219 --> 00:49:58.770
self-reinforcing, right? For Israelis, they've they saw this horrible

877
00:49:58.770 --> 00:50:02.620
atrocity on October 7th, and then their media, of

878
00:50:02.620 --> 00:50:05.179
course, and, and they, they had this trauma, and

879
00:50:05.179 --> 00:50:07.780
historical trauma maybe it built on and and then

880
00:50:07.780 --> 00:50:11.909
their media environment sort of ran with that. And

881
00:50:11.919 --> 00:50:15.560
um And so that's all sort of the the

882
00:50:15.600 --> 00:50:18.479
the the motivated biases and the media biases will

883
00:50:18.479 --> 00:50:21.840
reinforce the the real real events. And so you

884
00:50:21.840 --> 00:50:24.350
don't have, you know, there is some of this

885
00:50:25.040 --> 00:50:28.270
proximity thing, I think in Israel based on soldiers,

886
00:50:28.760 --> 00:50:31.540
some of them, what what they have seen. In

887
00:50:31.540 --> 00:50:34.909
Gaza, as well as uh hostages, what some of

888
00:50:34.909 --> 00:50:37.030
the hostages have seen and some of their dissent

889
00:50:37.030 --> 00:50:39.389
and saying, what are you doing? You're, you're bombing

890
00:50:39.389 --> 00:50:41.149
us and we see what you're doing and, you

891
00:50:41.149 --> 00:50:43.469
know, some of their agitation against the, the BB

892
00:50:43.469 --> 00:50:46.979
Netanyahu government. Um, BUT it's a little more of

893
00:50:46.979 --> 00:50:50.659
that mutually reinforcing set of issues. Um, OF course,

894
00:50:50.739 --> 00:50:52.870
you can see plenty of misinformation about what they've

895
00:50:52.870 --> 00:50:55.969
done. In in Gaza, and they, there's a lot

896
00:50:55.969 --> 00:50:58.129
they're trying to conceal and hide from the international

897
00:50:58.729 --> 00:51:01.260
community, as well as maybe even their own audiences,

898
00:51:01.540 --> 00:51:04.659
um, and all this stuff about Hollywood and saying

899
00:51:04.659 --> 00:51:09.780
they're um crisis actors, um, any narrative basically ever

900
00:51:09.780 --> 00:51:13.020
historically where you say that there's crisis actors is

901
00:51:13.020 --> 00:51:16.449
pretty much should baseline be viewed as false, um,

902
00:51:16.459 --> 00:51:20.620
because crisis actors means, you know, the term. Uh,

903
00:51:20.709 --> 00:51:24.229
YES, right, that that there's sort of actors pretending

904
00:51:24.229 --> 00:51:26.310
that to actually be suffering in in in in

905
00:51:26.310 --> 00:51:30.239
a war and emergency situation. It, it. It suggests

906
00:51:30.239 --> 00:51:32.719
that there's a false flag attack. And historically false

907
00:51:32.719 --> 00:51:36.360
flags are extremely hard to pull off and very

908
00:51:36.360 --> 00:51:38.919
rarely done, you know, Hitler tried them against Poland

909
00:51:38.919 --> 00:51:41.360
and all sorts of things. And so they're almost

910
00:51:41.360 --> 00:51:44.080
always the fodder of conspiracy theories and, and not

911
00:51:44.080 --> 00:51:48.510
reality, Sandy Hook and this and that. So, um,

912
00:51:48.520 --> 00:51:50.719
on the other side, there there, I think it's

913
00:51:50.719 --> 00:51:54.199
very sensitive and politically contentious, but um there is

914
00:51:54.199 --> 00:51:58.879
misinformation as well, um, and, and fake news, um.

915
00:51:59.239 --> 00:52:02.250
You know, there's a powerful international constituencies that are

916
00:52:02.250 --> 00:52:04.729
activated and mobilized about what's happened on both the

917
00:52:04.729 --> 00:52:09.129
Israeli and Palestinian sides. There are claims that uh

918
00:52:09.560 --> 00:52:12.449
107 was an inside job or that they're crisis

919
00:52:12.449 --> 00:52:15.570
actors, and there's, um, in these videos of, you

920
00:52:15.570 --> 00:52:19.209
know, the kids crying about their killed parents and

921
00:52:19.209 --> 00:52:22.939
so I mean that's misinformation too, and there's Extreme

922
00:52:22.939 --> 00:52:25.500
versions of what happened about sexual violence and this

923
00:52:25.500 --> 00:52:29.449
and that, um. That we'd have to look at

924
00:52:29.449 --> 00:52:33.320
is also fed by motivated and media biases, and

925
00:52:33.520 --> 00:52:34.889
the other one, I think the one where you

926
00:52:34.889 --> 00:52:39.120
can see the argument holding, well, maybe best is

927
00:52:39.709 --> 00:52:41.129
And it's really hard to know, and we should

928
00:52:41.129 --> 00:52:44.379
have humility and uncertainty about this, is public opinion

929
00:52:44.379 --> 00:52:48.429
within Gaza. Um, I think though there are some

930
00:52:48.429 --> 00:52:54.820
pretty strong indications that, uh, Gazans have a sort

931
00:52:54.820 --> 00:52:57.340
of a pox on both your house's mentality, many

932
00:52:57.340 --> 00:52:59.860
of them, which happens pretty commonly in war. There's

933
00:52:59.860 --> 00:53:03.739
a study of the Syrian civil war, um, about

934
00:53:03.739 --> 00:53:06.530
what happens when the Syrian regime uses barrel bombing

935
00:53:06.860 --> 00:53:09.889
on its, uh, used barrel bombing on its population.

936
00:53:10.179 --> 00:53:12.300
Of course, one of the worst tactics you can

937
00:53:12.300 --> 00:53:15.530
do in war, you'd expect it to, uh, generate

938
00:53:15.530 --> 00:53:19.189
immense animosity against the regime, and the authors find,

939
00:53:19.540 --> 00:53:21.770
um, with a very clever design that it created,

940
00:53:22.060 --> 00:53:25.060
um, Anger at both the regime and the rebels

941
00:53:25.060 --> 00:53:27.500
for their inability, their provoking of the regime, bringing

942
00:53:27.500 --> 00:53:29.300
the wrath of the regime down in these communities

943
00:53:29.300 --> 00:53:32.689
with an inability to protect them from that. Um,

944
00:53:32.780 --> 00:53:34.810
AND that's a common theme you see in war

945
00:53:35.100 --> 00:53:36.939
in Chechnya and elsewhere. And so I think you

946
00:53:36.939 --> 00:53:40.699
see that quite clearly in Gaza, um, where there,

947
00:53:40.820 --> 00:53:43.300
of course, there's tremendous anger and hate about what

948
00:53:43.300 --> 00:53:46.100
Israel has done, but there's no love lost and

949
00:53:46.100 --> 00:53:48.419
quite a bit of anger about what Hamas has

950
00:53:48.419 --> 00:53:53.949
done to, um, With a real understanding of uh

951
00:53:54.090 --> 00:53:57.929
motivated understanding of reality, cause the lived reality and

952
00:53:57.929 --> 00:54:00.659
experienced reality uh of what many of them have

953
00:54:00.659 --> 00:54:02.850
felt where Hamas hasn't been able to protect them.

954
00:54:02.889 --> 00:54:05.449
They provoked Israel to, you know, and then kind

955
00:54:05.449 --> 00:54:09.810
of hid hid selfishly in the shadows. Um, AND

956
00:54:09.810 --> 00:54:12.439
I, I do think there's really strong glimmers and,

957
00:54:12.500 --> 00:54:16.010
and, um, various, uh, Arab writers, Hussein I and

958
00:54:16.010 --> 00:54:19.939
others, many others, and Sort of media, detailed media

959
00:54:19.939 --> 00:54:22.030
investigations of this show that, as well as even

960
00:54:22.030 --> 00:54:25.070
public opinion patterns, um, that even the polling is

961
00:54:25.070 --> 00:54:26.989
hard to do now, but it suggests Hamas popularity

962
00:54:26.989 --> 00:54:30.260
is down in um Gaza up in the West

963
00:54:30.260 --> 00:54:34.100
Bank, where the experiences have been very different. Um,

964
00:54:34.110 --> 00:54:37.189
AND I think So you do see some powerful

965
00:54:37.189 --> 00:54:40.350
ways, Israel, Palestine is maybe a tricky case with

966
00:54:40.350 --> 00:54:43.949
some mutually reinforcing bubbles and biases, but that this

967
00:54:43.949 --> 00:54:46.510
does play out in that case, as difficult as

968
00:54:46.510 --> 00:54:48.189
it is for us to accept. And I think

969
00:54:48.189 --> 00:54:50.870
it leads to the conclusions and implications of the

970
00:54:50.870 --> 00:54:52.570
book, which is hard as it is for us

971
00:54:52.570 --> 00:54:54.550
to do, we have to try to look at

972
00:54:54.550 --> 00:54:57.629
and lift up these voices of these communities that

973
00:54:57.629 --> 00:55:00.850
actually experience the horrors and the complexities, and not

974
00:55:00.850 --> 00:55:04.939
just our own video game. Um, SENSATIONS of what

975
00:55:04.939 --> 00:55:08.419
we want to happen and which side we support.

976
00:55:09.239 --> 00:55:11.560
Mhm. So finally, I would like to ask you

977
00:55:11.560 --> 00:55:14.060
just a couple of questions about what we can

978
00:55:14.060 --> 00:55:17.020
do with the knowledge you present in your book.

979
00:55:17.100 --> 00:55:21.280
So, Can we learn something new about topics such

980
00:55:21.280 --> 00:55:26.199
as the duration of armed conflicts, the feasibility of

981
00:55:26.199 --> 00:55:31.879
pre prevailing counterinsurgency models and the depths and limits

982
00:55:31.879 --> 00:55:36.949
of misperceptions more broadly in social and political life.

983
00:55:38.010 --> 00:55:40.750
Yeah, I think so. I hope so, certainly, um,

984
00:55:40.879 --> 00:55:44.399
and uh there's several bits there. I'll try my

985
00:55:44.399 --> 00:55:46.840
best to talk about them. Um, THOSE are really

986
00:55:46.840 --> 00:55:48.010
some of the things I tried to run with

987
00:55:48.010 --> 00:55:52.520
in the book's conclusion. Um, AS far as implications

988
00:55:52.520 --> 00:55:57.280
for conflict, um, I think we can see how

989
00:55:57.280 --> 00:56:03.429
this model. Does impact things like um the duration

990
00:56:03.429 --> 00:56:07.600
of war, yes, and Things like counterinsurgency. So take

991
00:56:07.600 --> 00:56:11.239
war duration. Um, WHAT I tried to get at

992
00:56:11.239 --> 00:56:13.760
there is that there will be this gap very

993
00:56:13.760 --> 00:56:18.469
often. Uh, BETWEEN the local populations that have experienced

994
00:56:18.469 --> 00:56:21.379
the cost and fully recognized them of war, and

995
00:56:21.379 --> 00:56:24.110
the more removed populations that don't. And then you

996
00:56:24.110 --> 00:56:28.020
can imagine the strength and size of those two

997
00:56:28.020 --> 00:56:32.270
constituencies can vary, in particular, where you have powerful

998
00:56:32.270 --> 00:56:36.760
diasporas. It is one reason why you can, you

999
00:56:36.760 --> 00:56:39.879
can see how war can be perpetuated by those

1000
00:56:39.879 --> 00:56:44.040
diasporas who will be not experiencing, if you're aggrieved

1001
00:56:44.040 --> 00:56:47.639
about what's happening but removed from it, that's where

1002
00:56:47.639 --> 00:56:50.520
you'll be most susceptible to that factual manipulation towards

1003
00:56:50.520 --> 00:56:53.959
your side. Um, AND so diasporas can be a

1004
00:56:53.959 --> 00:56:56.550
big part of that, maybe areas with small conflict

1005
00:56:56.550 --> 00:57:02.620
zones, but large external sympathetic communities. Um, Uh, YOU

1006
00:57:02.620 --> 00:57:04.459
know, and so I think it shines a light

1007
00:57:04.459 --> 00:57:08.850
on, uh, some ways in which war is likely

1008
00:57:08.850 --> 00:57:13.239
to be um may may be perpetuated longer um

1009
00:57:13.370 --> 00:57:17.340
in new ways. Um, AND counterinsurgency, I think it

1010
00:57:17.340 --> 00:57:20.610
speaks to, you know, maybe that's a hopeful in

1011
00:57:20.610 --> 00:57:23.129
some ways faded term now, counterinsurgency at least as

1012
00:57:23.129 --> 00:57:26.209
it was such a hot topic of study in

1013
00:57:26.530 --> 00:57:30.169
Western circles, maybe during the post 9/11 wars, um.

1014
00:57:31.360 --> 00:57:35.100
But Um, but I think there were these models

1015
00:57:35.100 --> 00:57:36.780
that had some merit and they were backed up

1016
00:57:36.780 --> 00:57:41.320
by some rigorous research about how, um, About sort

1017
00:57:41.320 --> 00:57:43.949
of winning the winning hearts and minds and at

1018
00:57:43.949 --> 00:57:46.590
the local level and showing that various kinds of

1019
00:57:46.590 --> 00:57:51.229
actions, um, you know, avoiding um too much collateral

1020
00:57:51.229 --> 00:57:55.379
damage or providing services and payments to local communities

1021
00:57:55.709 --> 00:57:59.389
was pretty effective empirically in gaining more support and

1022
00:57:59.389 --> 00:58:02.070
tamping down violence in some of these conflict zones

1023
00:58:02.070 --> 00:58:04.989
like Iraq and Afghanistan and the Philippines and elsewhere,

1024
00:58:05.030 --> 00:58:08.889
not all the US based ones. Um. And there's

1025
00:58:08.889 --> 00:58:12.129
some rigorous sort of econ and poli sci research

1026
00:58:12.129 --> 00:58:14.800
on that, but it was very local. It was

1027
00:58:14.800 --> 00:58:17.959
always very localized. And I do think it's real,

1028
00:58:18.090 --> 00:58:20.010
but we have to reckon with the fact that

1029
00:58:20.020 --> 00:58:21.770
that those are the communities where those carrots and

1030
00:58:21.770 --> 00:58:25.330
sticks are being used, they're being recognized accurately, those

1031
00:58:25.330 --> 00:58:28.689
signals, and that's why we expect, we get the

1032
00:58:28.689 --> 00:58:35.229
expected behavioral consequences. Um, If you then have media

1033
00:58:35.229 --> 00:58:39.310
broadcasting those much more broadly, you can have the

1034
00:58:39.310 --> 00:58:41.750
exact opposite thing happening at the same time, and

1035
00:58:41.750 --> 00:58:43.409
that's what we see in a case like Pakistan,

1036
00:58:43.469 --> 00:58:47.219
where the best, I think empirical research suggests that

1037
00:58:47.750 --> 00:58:51.310
the US drone campaign was locally effective, not just

1038
00:58:51.310 --> 00:58:52.949
that it was pretty targeted it, but in this

1039
00:58:52.949 --> 00:58:57.419
case in Pakistan, it was pretty locally effective in,

1040
00:58:57.570 --> 00:59:02.550
um, you know, tamping down militancy, um. You know,

1041
00:59:02.679 --> 00:59:06.479
within these uh tribal agencies, very small part of

1042
00:59:06.479 --> 00:59:09.320
Pakistan. At the same time, I, I would venture

1043
00:59:09.320 --> 00:59:12.429
to say it was fairly counterproductive nationally and maybe

1044
00:59:12.429 --> 00:59:18.909
internationally and because partially of misperceptions. Um, FEEDING a

1045
00:59:18.909 --> 00:59:23.149
very anti-drone politics. Um, AND so I think you're

1046
00:59:23.149 --> 00:59:24.229
gonna have both at the same time and the

1047
00:59:24.229 --> 00:59:26.070
points towards some of the limits in ways we

1048
00:59:26.070 --> 00:59:28.070
should be pretty cautious about this sort of very

1049
00:59:28.070 --> 00:59:33.820
rational, rationalist counterinsurgency models that people think uh can

1050
00:59:33.830 --> 00:59:36.790
can work. Those are two implications for conflict and

1051
00:59:36.790 --> 00:59:39.669
conflict theories. Um, I think there are others and

1052
00:59:39.669 --> 00:59:41.949
we should think about this local national gap, but

1053
00:59:42.280 --> 00:59:43.360
what I wanted to get to is sort of

1054
00:59:43.360 --> 00:59:45.320
OK, what do we do about all this? What

1055
00:59:45.320 --> 00:59:47.439
does it lead us or suggest that maybe we

1056
00:59:47.439 --> 00:59:48.709
should do? I mean, it's a very hard problem.

1057
00:59:48.760 --> 00:59:50.379
I'm not saying we're gonna get out there and

1058
00:59:50.989 --> 00:59:54.020
You know, fix it immediately, but it does, I

1059
00:59:54.020 --> 00:59:56.820
think, point towards a little bit of a solution

1060
00:59:56.820 --> 00:59:58.979
set or or like a a a set of

1061
00:59:58.979 --> 01:00:02.639
strategies to try to mitigate things, which is that

1062
01:00:03.020 --> 01:00:06.709
um this local non-local gap can be not just

1063
01:00:06.709 --> 01:00:11.159
a problem but a possible solution. Because it suggests

1064
01:00:11.159 --> 01:00:15.100
that if you can elevate and amplify the volume

1065
01:00:15.449 --> 01:00:18.969
of these frontline populations, which are purveyors of truth

1066
01:00:18.969 --> 01:00:24.020
relatively towards uh uh relative to the screaming, uh.

1067
01:00:25.040 --> 01:00:29.100
Audiences thousands of miles away. They have strong passions

1068
01:00:29.100 --> 01:00:33.419
but little experience, you can hopefully um rebalance things

1069
01:00:33.419 --> 01:00:36.780
now. There are forces pushing against that, but I

1070
01:00:36.780 --> 01:00:39.979
think there are some interesting possible strategies to do

1071
01:00:39.979 --> 01:00:44.610
so. Um, FOR example, social media platforms. And I

1072
01:00:44.610 --> 01:00:47.649
recognize fully that there's a a retreat of social

1073
01:00:47.649 --> 01:00:51.040
media platforms wanting to do any interventions. Um, TO

1074
01:00:51.040 --> 01:00:56.429
shape the information environment, but, um, The they could

1075
01:00:56.429 --> 01:01:02.820
flag. Or label Sort of um local or frontline

1076
01:01:02.820 --> 01:01:06.719
sources. Um, IN a conflict, they even experimented with

1077
01:01:06.719 --> 01:01:09.280
this Twitter at the time it was Twitter, not

1078
01:01:09.280 --> 01:01:12.189
X under uh Jack Dorsey did have sort of

1079
01:01:12.189 --> 01:01:14.040
um I forget what they called on the ground

1080
01:01:14.040 --> 01:01:17.959
lists maybe, um, you could follow in Ukraine with

1081
01:01:17.959 --> 01:01:21.239
local journalists and and other influencers and who were

1082
01:01:21.239 --> 01:01:24.389
maybe a little bit vetted and um because the

1083
01:01:24.399 --> 01:01:27.040
the the platforms have in the geolocations of all

1084
01:01:27.040 --> 01:01:28.959
these people. You don't have that publicly. I don't

1085
01:01:28.959 --> 01:01:31.639
have that as a researcher, but they know, and

1086
01:01:31.639 --> 01:01:34.110
so, um. You know, we could talk about the

1087
01:01:34.110 --> 01:01:36.510
mechanics of that, but they could maybe better verify

1088
01:01:36.510 --> 01:01:40.510
people and have some um method of um even

1089
01:01:40.510 --> 01:01:44.070
algorithmically labeling people so that we got, you know,

1090
01:01:44.149 --> 01:01:46.510
an ability to, to know who was really a

1091
01:01:46.510 --> 01:01:50.739
local source um in conflict. Now, you know, again,

1092
01:01:50.939 --> 01:01:54.290
maybe we're pessimistic about platforms desire to do any

1093
01:01:54.290 --> 01:01:55.989
of that. I would argue if I were in

1094
01:01:55.989 --> 01:01:58.229
the room with any higher ups in on the

1095
01:01:58.229 --> 01:02:01.070
major social media platforms that that's that is an

1096
01:02:01.070 --> 01:02:04.649
information adding intervention. And it's pretty light touch, but

1097
01:02:04.649 --> 01:02:06.709
um, but still, so I think there are some

1098
01:02:06.709 --> 01:02:09.899
creative ways of things we can do. And then

1099
01:02:09.899 --> 01:02:13.399
broadly lastly I'd say, I do think the model

1100
01:02:14.120 --> 01:02:19.610
should hopefully be looked at and extrapolated back towards

1101
01:02:19.610 --> 01:02:24.689
other areas of misperception and misinformation. Um, I was

1102
01:02:24.689 --> 01:02:28.810
studying this case, this context, um, and I think

1103
01:02:28.810 --> 01:02:32.639
it was maybe an understudied context of factual manipulation

1104
01:02:32.639 --> 01:02:35.510
and misperception and war that had some distinctive features,

1105
01:02:35.530 --> 01:02:37.729
but you can see maybe how some of the

1106
01:02:37.729 --> 01:02:40.010
pieces of that that hadn't, I think, been as

1107
01:02:40.010 --> 01:02:43.239
honed in on. Could are still there are strong

1108
01:02:43.239 --> 01:02:47.159
parallels and echoes elsewhere. Um, SO, you know, anywhere

1109
01:02:47.159 --> 01:02:50.159
where there's high stakes stimuli that people are closer

1110
01:02:50.159 --> 01:02:55.790
to. Um, YOU know, uh, whether that's disease or

1111
01:02:55.790 --> 01:03:01.030
pollution, or crime, or whatever, you have the potential

1112
01:03:01.030 --> 01:03:04.629
for this local accuracy advantage. Now, I do think,

1113
01:03:04.669 --> 01:03:06.629
and there's other research looking at this, um, you

1114
01:03:06.629 --> 01:03:08.070
know, there's some research. I'm trying to put the

1115
01:03:08.070 --> 01:03:10.949
pieces together and say this can hold. Now I

1116
01:03:10.949 --> 01:03:16.580
do think that it will depend on um How

1117
01:03:16.590 --> 01:03:21.429
publicly visible it is. Um, AS well as its,

1118
01:03:21.560 --> 01:03:25.689
it's cost, because War, a lot of what's happening,

1119
01:03:25.719 --> 01:03:27.489
we're talking about people moving here and there and

1120
01:03:27.489 --> 01:03:29.169
shooting and killing and torturing each other and all

1121
01:03:29.169 --> 01:03:33.209
these horrible things. Uh, AND lies about it, but

1122
01:03:33.209 --> 01:03:36.729
some of this stuff is out of view. So,

1123
01:03:36.790 --> 01:03:39.830
or it's about science. So it's very hard for

1124
01:03:39.830 --> 01:03:42.949
people to see the germ theory of disease. Or

1125
01:03:42.949 --> 01:03:45.429
it's very hard for people to see the the

1126
01:03:45.429 --> 01:03:49.689
uh uh greenhouse effect. Now, that means that people

1127
01:03:49.689 --> 01:03:55.010
will, uh, who are closer will uh have a

1128
01:03:55.010 --> 01:03:59.129
better knowledge of what is happening descriptively, that their

1129
01:03:59.129 --> 01:04:03.409
areas are flooding or burning or shrinking or getting

1130
01:04:03.409 --> 01:04:07.850
sick. And so this kind of dynamic will apply

1131
01:04:07.850 --> 01:04:10.840
to that, but not maybe on the causal side,

1132
01:04:10.850 --> 01:04:13.330
it it depends there. So I think there's some

1133
01:04:13.330 --> 01:04:16.620
really interesting threads. I tried to He start to

1134
01:04:16.620 --> 01:04:19.939
unravel for others there, um, to think about when

1135
01:04:19.939 --> 01:04:24.280
this sort of kind of sharp constraint. Based on

1136
01:04:24.449 --> 01:04:27.979
people needing to know. Can sort of apply in

1137
01:04:27.979 --> 01:04:28.820
a lot of areas.

1138
01:04:30.860 --> 01:04:33.699
One final question then, do you think that this

1139
01:04:33.699 --> 01:04:37.820
knowledge could have also policy implications?

1140
01:04:39.209 --> 01:04:40.840
Yeah, I think so. I mean, I, I, I

1141
01:04:40.840 --> 01:04:42.199
guess that's what I was trying to, some of

1142
01:04:42.199 --> 01:04:43.600
what I was trying to get towards, although it

1143
01:04:43.600 --> 01:04:47.169
depends what you call policy implication is that um

1144
01:04:48.850 --> 01:04:54.590
You know, understanding, um, you know, this landscape of

1145
01:04:55.270 --> 01:04:57.949
Who's likely to be factually manipulated in conflict. I

1146
01:04:57.949 --> 01:05:00.469
do think it is important because it influences behavior,

1147
01:05:00.949 --> 01:05:05.290
uh, can influence behavior. Um, SO, You know, parties

1148
01:05:05.290 --> 01:05:09.439
in conflict, um, That we may view as, you

1149
01:05:09.439 --> 01:05:13.060
know, having, um, We may be sympathetic towards should

1150
01:05:13.070 --> 01:05:16.790
should try to navigate that effectively, or maybe the

1151
01:05:16.790 --> 01:05:18.590
international community or UN or others that are trying

1152
01:05:18.590 --> 01:05:20.820
to sort of stabilize conflicts need to be aware

1153
01:05:21.270 --> 01:05:24.070
of this ready to sort of counter, ready to

1154
01:05:24.070 --> 01:05:27.090
target the communities that are most susceptible based on

1155
01:05:27.090 --> 01:05:29.550
this theory, which are those that are removed but

1156
01:05:29.550 --> 01:05:34.689
aggrieved. Um, RATHER than leafletting and pamphleting and, and

1157
01:05:34.689 --> 01:05:37.530
radioing and all the frontline communities that already often

1158
01:05:37.530 --> 01:05:40.290
know, um, so I think there is some of

1159
01:05:40.290 --> 01:05:43.199
that. Um, I think some of the other policy

1160
01:05:43.199 --> 01:05:46.840
implications like I just talked about like, um, being

1161
01:05:46.840 --> 01:05:49.040
a little more cautious and pessimistic about some of

1162
01:05:49.040 --> 01:05:53.550
these interventionist models that sort of apply best locally.

1163
01:05:54.000 --> 01:05:55.760
And, and I, I think that stuff I was

1164
01:05:55.760 --> 01:05:58.239
talking about with the platforms, depends whether you call

1165
01:05:58.239 --> 01:06:00.870
it a policy implication, but um there are some

1166
01:06:00.870 --> 01:06:03.919
ways to try to lift up local voices and,

1167
01:06:04.120 --> 01:06:05.909
you know, other things related to that too, like,

1168
01:06:05.919 --> 01:06:08.760
um, I think I I have great respect and

1169
01:06:08.760 --> 01:06:14.199
admiration. Um, FOR the leading like open source, um,

1170
01:06:14.209 --> 01:06:19.810
investigative organizations, Osent organizations, um, like uh Bellingcat, um,

1171
01:06:19.850 --> 01:06:22.399
and fact checking organizations like Alt News in India,

1172
01:06:22.489 --> 01:06:26.209
or many others around the world, um, and all

1173
01:06:26.209 --> 01:06:28.840
the work that they do, which now is really,

1174
01:06:28.969 --> 01:06:30.570
you know, some of the funding if they were

1175
01:06:30.570 --> 01:06:32.850
getting funds from meta and elsewhere is dried up,

1176
01:06:32.889 --> 01:06:37.169
but that stuff and supporting it, um, looking to

1177
01:06:37.169 --> 01:06:41.540
it. Um, AS well as these local populations that,

1178
01:06:41.629 --> 01:06:44.709
um, it is part of what feeds it. I

1179
01:06:44.709 --> 01:06:46.149
think all of that is important.

1180
01:06:47.770 --> 01:06:50.790
Great. So the book is again seeing is this

1181
01:06:50.790 --> 01:06:54.750
believing why people believe misinformation in war and when

1182
01:06:54.750 --> 01:06:57.169
they know better. I'm leaving a link to it

1183
01:06:57.169 --> 01:07:00.429
in the description of the interview. And Doctor Silverman,

1184
01:07:00.510 --> 01:07:03.169
apart from the book, would you like to tell

1185
01:07:03.169 --> 01:07:05.830
people where they can find you and your work

1186
01:07:05.830 --> 01:07:06.840
on the internet?

1187
01:07:08.090 --> 01:07:10.409
Sure. Um, YOU can always, uh, look me up,

1188
01:07:10.489 --> 01:07:15.080
uh, um, have, uh, my website, uh, personal website,

1189
01:07:15.209 --> 01:07:19.719
uh. Was it Daniel M Silverman.com, I believe, um,

1190
01:07:19.969 --> 01:07:22.330
or, or my faculty my page at at CMU,

1191
01:07:22.370 --> 01:07:24.409
and I, I am active on, on social media,

1192
01:07:24.689 --> 01:07:27.610
perhaps unwisely. I was on Twitter slash X and

1193
01:07:27.610 --> 01:07:29.560
I, I have accounts on all the sites, but

1194
01:07:29.810 --> 01:07:31.760
I post on Blue Sky a little more now,

1195
01:07:32.040 --> 01:07:35.419
um. And so, um, but I, I continue to

1196
01:07:35.419 --> 01:07:37.929
work on all these problems and others, and um

1197
01:07:38.219 --> 01:07:39.820
thank you for interviewing me. I look forward to

1198
01:07:39.820 --> 01:07:40.540
any engagement.

1199
01:07:42.030 --> 01:07:44.070
Great. Thank you so much for taking the time

1200
01:07:44.070 --> 01:07:46.060
to come on the show. It's been a big

1201
01:07:46.060 --> 01:07:48.419
pleasure to talk with you. Thank you so much.

1202
01:07:49.770 --> 01:07:52.260
Hi guys, thank you for watching this interview until

1203
01:07:52.260 --> 01:07:54.439
the end. If you liked it, please share it,

1204
01:07:54.610 --> 01:07:57.399
leave a like and hit the subscription button. The

1205
01:07:57.399 --> 01:07:59.600
show is brought to you by Nights Learning and

1206
01:07:59.600 --> 01:08:03.679
Development done differently, check their website at Nights.com and

1207
01:08:03.679 --> 01:08:07.399
also please consider supporting the show on Patreon or

1208
01:08:07.399 --> 01:08:09.879
PayPal. I would also like to give a huge

1209
01:08:09.879 --> 01:08:13.270
thank you to my main patrons and PayPal supporters

1210
01:08:13.270 --> 01:08:17.200
Pergo Larsson, Jerry Mullerns, Fredrik Sundo, Bernard Seyches Olaf,

1211
01:08:17.319 --> 01:08:20.569
Alex Adam Castle, Matthew Whitting Berarna Wolf, Tim Hollis,

1212
01:08:20.700 --> 01:08:23.988
Erika Lenny, John Connors, Philip Fors Connolly. Then the

1213
01:08:23.988 --> 01:08:27.788
Matter Robert Windegaruyasi Zup Mark Nes called in Holbrookfield

1214
01:08:27.788 --> 01:08:32.548
governor Michael Stormir, Samuel Andre, Francis Forti Agnseroro and

1215
01:08:32.548 --> 01:08:36.349
Hal Herzognun Macha Joan Labrant John Jasent and Samuel

1216
01:08:36.349 --> 01:08:40.429
Corriere, Heinz, Mark Smith, Jore, Tom Hummel, Sardus France

1217
01:08:40.429 --> 01:08:44.167
David Sloan Wilson, asilla dearraujuru and Roach Diego Londono

1218
01:08:44.167 --> 01:08:50.099
Correa. Yannick Punteran Rosmani Charlotte blinikolbar Adamhn Pavlostaevsky nale

1219
01:08:50.099 --> 01:08:54.179
back medicine, Gary Galman Sam of Zallidrianei Poltonin John

1220
01:08:54.179 --> 01:08:58.738
Barboza, Julian Price, Edward Hall Edin Bronner, Douglas Fry,

1221
01:08:58.818 --> 01:09:03.499
Franco Bartolotti Gabrielon Corteseus Slelitsky, Scott Zachary Fish Tim

1222
01:09:03.499 --> 01:09:08.008
Duffyani Smith John Wieman. Daniel Friedman, William Buckner, Paul

1223
01:09:08.008 --> 01:09:12.917
Giorgneau, Luke Lovai Giorgio Theophanous, Chris Williamson, Peter Wozin,

1224
01:09:13.127 --> 01:09:17.698
David Williams, Diocosta, Anton Eriksson, Charles Murray, Alex Shaw,

1225
01:09:17.929 --> 01:09:22.087
Mary Martinez, Coralli Chevalier, Banggala atheists, Larry D. Lee

1226
01:09:22.087 --> 01:09:26.970
Junior, old Eringbo. Sterry Michael Bailey, then Sperber, Robert

1227
01:09:26.970 --> 01:09:31.970
Grayigoren, Jeff McMann, Jake Zu, Barnabas radix, Mark Campbell,

1228
01:09:32.129 --> 01:09:36.470
Thomas Dovner, Luke Neeson, Chris Storry, Kimberly Johnson, Benjamin

1229
01:09:36.470 --> 01:09:41.250
Gilbert, Jessica Nowicki, Linda Brandon, Nicholas Carlsson, Ismael Bensleyman.

1230
01:09:41.879 --> 01:09:47.040
George Eoriatis, Valentin Steinman, Perkrolis, Kate van Goller, Alexander

1231
01:09:47.040 --> 01:09:53.729
Hubbert, Liam Dunaway, BR Masoud Ali Mohammadi, Perpendicular John

1232
01:09:53.729 --> 01:09:59.169
Nertner, Ursulauddinov, Gregory Hastings, David Pinsoff Sean Nelson, Mike

1233
01:09:59.169 --> 01:10:02.819
Levin, and Jos Net. A special thanks to my

1234
01:10:02.819 --> 01:10:05.660
producers. These are Webb, Jim, Frank Lucas Steffinik, Tom

1235
01:10:05.660 --> 01:10:10.540
Venneden, Bernard Curtis Dixon, Benedic Muller, Thomas Trumbull, Catherine

1236
01:10:10.540 --> 01:10:13.819
and Patrick Tobin, Gian Carlo Montenegroal Ni Cortiz and

1237
01:10:13.819 --> 01:10:17.180
Nick Golden, and to my executive producers Matthew Levender,

1238
01:10:17.299 --> 01:10:20.450
Sergio Quadrian, Bogdan Kanivets, and Rosie. Thank you for

1239
01:10:20.450 --> 01:10:20.770
all.

