WEBVTT

1
00:00:00.340 --> 00:00:02.940
Hello, everyone. Welcome to a new episode of the

2
00:00:02.940 --> 00:00:06.170
Dissenter. I'm your host, as always, Ricardo Lopez, and

3
00:00:06.170 --> 00:00:09.180
today I'm joined by Doctor Alexander Thomas. He's a

4
00:00:09.180 --> 00:00:11.729
senior lecturer in media production and film at the

5
00:00:11.729 --> 00:00:15.050
University of East London, and today we're talking about

6
00:00:15.050 --> 00:00:19.649
his book, The Politics and Ethics of Transhumanism, Techno-human

7
00:00:19.649 --> 00:00:24.569
evolution and Advanced Capitalism. So Doctor Farmers, welcome to

8
00:00:24.569 --> 00:00:26.239
the show. It's a big pleasure to

9
00:00:26.239 --> 00:00:28.530
everyone. Thanks very much for the invite, Ricardo. It's

10
00:00:28.530 --> 00:00:29.719
a pleasure to be here. Thank you.

11
00:00:30.559 --> 00:00:32.880
So let's start perhaps with a bit of, with

12
00:00:32.880 --> 00:00:36.200
a bit of background here also for the people

13
00:00:36.200 --> 00:00:39.759
who are listening and watching us who are not

14
00:00:39.759 --> 00:00:43.729
familiar with the topic of transhumanism. So what is

15
00:00:43.729 --> 00:00:47.689
transhumanism, and I know that it is very associated

16
00:00:47.689 --> 00:00:51.700
with different kinds of technology. So what kinds of

17
00:00:51.700 --> 00:00:54.470
technology go associated with it?

18
00:00:55.310 --> 00:00:58.889
Um, OK, yeah, sure. So, um, transhumanism is, is

19
00:00:58.889 --> 00:01:03.159
basically the idea of, of self-directed human evolution. Um,

20
00:01:03.189 --> 00:01:05.989
SO it's the claim that we can and that

21
00:01:05.989 --> 00:01:10.269
we should, uh, radically enhance the human condition through

22
00:01:10.269 --> 00:01:14.209
the use of, of applied technoscience, essentially. And, and

23
00:01:14.209 --> 00:01:16.809
most transhumanists think that we're on the cusp of

24
00:01:16.809 --> 00:01:20.930
making this a reality reasonably soon. So, uh, one

25
00:01:20.930 --> 00:01:23.129
way of thinking about it is that if the

26
00:01:23.129 --> 00:01:27.610
history of scientific and, and technological progress, um, can

27
00:01:27.610 --> 00:01:30.050
be seen as an attempt to use nature to

28
00:01:30.050 --> 00:01:33.930
better serve human needs, transhumanism can be seen as

29
00:01:33.930 --> 00:01:36.970
the revision of human nature to better serve our

30
00:01:36.970 --> 00:01:40.330
fantasies. Um, AND, you know, as you pointed out

31
00:01:40.330 --> 00:01:43.199
there. There are a bunch of technologies that that

32
00:01:43.199 --> 00:01:45.239
they think will make this so, and, and that

33
00:01:45.239 --> 00:01:48.190
is the reason why after, you know, 300,000 years

34
00:01:48.190 --> 00:01:50.480
or so of, of our existence, they think maybe

35
00:01:50.480 --> 00:01:53.800
we're suddenly about to become something else. And it's

36
00:01:53.800 --> 00:01:56.680
um it's what they sometimes refer to as the

37
00:01:56.680 --> 00:02:01.029
converging NIC suite of technologies that make this thinkable.

38
00:02:01.059 --> 00:02:07.309
And NIC stands for nanotechnology, biotechnology, information technology, and,

39
00:02:07.339 --> 00:02:10.988
and cognitive science. So nanotech is technology on a

40
00:02:10.988 --> 00:02:14.069
very small scale, um, even on the scale of

41
00:02:14.069 --> 00:02:16.828
individual atoms and molecules. uh, SO they, they have

42
00:02:16.828 --> 00:02:21.468
a concept called um atomically precise manufacturing. Um, SO

43
00:02:21.468 --> 00:02:24.708
that's part of the transhumanist kind of nano nanotechnological

44
00:02:24.708 --> 00:02:27.748
dream that might allow us to turn smoke into

45
00:02:27.748 --> 00:02:31.098
strawberries and cancer tissues into healthy tissues and create

46
00:02:31.098 --> 00:02:35.589
radical abundance. Um, THEN there's biotechnology, which includes things

47
00:02:35.589 --> 00:02:39.460
like genetic engineering. Um, AND obviously information technology, which

48
00:02:39.460 --> 00:02:42.210
we're all very familiar with, computers, the digital world,

49
00:02:42.500 --> 00:02:46.110
developments in AI, the potential of quantum computing, and,

50
00:02:46.119 --> 00:02:48.740
uh, obviously cognitive science is the study of the

51
00:02:48.740 --> 00:02:51.979
mind. But in particular, it's the fusion of these

52
00:02:51.979 --> 00:02:57.100
technologies which really for transhumanists offer profound possibilities. So

53
00:02:57.100 --> 00:03:00.740
an example might be brain to computer interfaces. Such

54
00:03:00.740 --> 00:03:03.949
as those designed by Elon Musk's company, Euroink, and

55
00:03:03.949 --> 00:03:07.589
that contains, you know, biotech elements, infotech elements, cognotech,

56
00:03:07.669 --> 00:03:10.789
all within one system. So, so on the one

57
00:03:10.789 --> 00:03:14.750
hand, transhumanism is a kind of ideological commitment to

58
00:03:14.750 --> 00:03:19.139
being proactionary in, in using and utilizing these technologies

59
00:03:19.139 --> 00:03:22.380
to apply them to humanity and to evolve humanity

60
00:03:22.589 --> 00:03:25.589
into a kind of enhanced entity, and then continue

61
00:03:25.589 --> 00:03:28.059
with that process. Um, BUT on the other hand,

62
00:03:28.179 --> 00:03:31.580
it is sometimes, it's sometimes also used descriptively. So

63
00:03:31.580 --> 00:03:33.979
as a term for this process, the, the kind

64
00:03:33.979 --> 00:03:38.690
of material unfolding, the co-evolution of humans and technology.

65
00:03:39.020 --> 00:03:41.339
So, um, but personally, when, when I use the

66
00:03:41.339 --> 00:03:44.100
term, um, I, I tend to describe the process

67
00:03:44.100 --> 00:03:48.460
using terms such as technogenesis or techno-human evolution, and

68
00:03:48.460 --> 00:03:51.619
um I use transhumanism for the, the ideology saying

69
00:03:51.619 --> 00:03:52.710
yes, this is a good idea.

70
00:03:53.889 --> 00:03:57.839
And how all these transhumanism, because just looking at

71
00:03:57.839 --> 00:04:00.889
the ideas associated with it and particularly the kinds

72
00:04:00.889 --> 00:04:05.089
of technologies that go associated with it, we, one

73
00:04:05.089 --> 00:04:08.839
would think that perhaps it's just a very recent

74
00:04:08.839 --> 00:04:11.770
thing that came about over the last few decades

75
00:04:11.770 --> 00:04:15.410
or something like that, but maybe feel particularly from

76
00:04:15.410 --> 00:04:19.048
a philosophical standpoint, it might be a bit older.

77
00:04:19.309 --> 00:04:19.459
Yeah,

78
00:04:21.269 --> 00:04:23.510
absolutely. I mean, I, I would say humans have

79
00:04:23.510 --> 00:04:27.149
probably been dreaming about kind of transhumanist possibilities for

80
00:04:27.149 --> 00:04:29.630
pretty much as long as human culture has existed,

81
00:04:29.709 --> 00:04:32.589
I'd say. Um, YOU know, we, we, I'm sure

82
00:04:32.589 --> 00:04:34.829
throughout history, humans have been very aware of the

83
00:04:34.829 --> 00:04:36.959
limitations of, of what it is to be human,

84
00:04:37.059 --> 00:04:39.630
uh, you know, we die, we get disease, our

85
00:04:39.630 --> 00:04:42.309
bodies are frail, um, and I'm sure we've always

86
00:04:42.309 --> 00:04:45.149
kind of wanted to imagine these things away. Um,

87
00:04:45.299 --> 00:04:46.980
BUT obviously in the, in the modern sense of

88
00:04:46.980 --> 00:04:49.869
the word, transhumanism is, is much more recent. Um,

89
00:04:50.019 --> 00:04:54.859
NOW transhumanists often point to kind of the Enlightenment

90
00:04:54.859 --> 00:04:59.299
as the philosophical lineage of their thinking. So, um,

91
00:04:59.380 --> 00:05:02.309
you know, we had Enlightenment philosophers such as Francis

92
00:05:02.309 --> 00:05:07.010
Bacon. He imagined science leading to incredible possibilities. And

93
00:05:07.010 --> 00:05:08.619
then, you know, a bit later in the, in

94
00:05:08.619 --> 00:05:11.019
the 19th century, uh, there was a thinker called

95
00:05:11.019 --> 00:05:13.579
Wynwood Read, for example, and he, you know, wrote

96
00:05:13.579 --> 00:05:16.459
about most of the ideas that modern transhumanists talk

97
00:05:16.459 --> 00:05:19.859
about now. Um, THERE was also biologists in the,

98
00:05:19.929 --> 00:05:22.549
in the 20th century, the early 20th century, like,

99
00:05:22.559 --> 00:05:26.609
um, Haldane and Bernal, who, who provided very strong

100
00:05:26.609 --> 00:05:32.299
kind of proto-transhumanist visions. Um, BUT modern transhumanism is

101
00:05:32.299 --> 00:05:35.769
usually said to. Begin with Julian Huxley, um, and

102
00:05:35.769 --> 00:05:39.190
he's an evolutionary biologist and, and a eugenicist, and,

103
00:05:39.200 --> 00:05:41.899
and the brother of Aldous Huxley, uh, who wrote

104
00:05:41.899 --> 00:05:44.100
The Brave New World, obviously. Um, HE, he's the

105
00:05:44.100 --> 00:05:47.140
one who coined the term transhumanism in its modern

106
00:05:47.140 --> 00:05:50.220
sense, and that was in the early 1950s. But

107
00:05:50.309 --> 00:05:52.510
there is another kind of argument which says actually

108
00:05:52.510 --> 00:05:54.869
it's even more recent than that. Um, SO there's

109
00:05:54.869 --> 00:05:56.790
a guy called Max Moore, and he claims to

110
00:05:56.790 --> 00:06:00.190
have coined the term independently and around the 1980s

111
00:06:00.190 --> 00:06:02.670
and 1990s there was a a kind of transhumanist

112
00:06:02.670 --> 00:06:05.390
movement called the Extropian movement, and that was very

113
00:06:05.390 --> 00:06:08.549
influential, and there was a kind of extropian mailing

114
00:06:08.549 --> 00:06:11.440
list that included many of the, the very famous

115
00:06:11.440 --> 00:06:14.690
transhumanists that have emerged since then. Um, SO, you

116
00:06:14.690 --> 00:06:17.290
know, that you could argue that the Extroian movement

117
00:06:17.290 --> 00:06:20.679
has, has been very important in terms of conceptualizing

118
00:06:20.679 --> 00:06:23.730
the modern meaning and movement of transhumanism. So maybe

119
00:06:23.730 --> 00:06:26.529
transhumanism starts in the 80s and 90s with kind

120
00:06:26.529 --> 00:06:29.250
of Maxim more and extropianism. So those are the

121
00:06:29.250 --> 00:06:31.890
kind of, um, you know, depends how you define

122
00:06:31.890 --> 00:06:33.160
it, is how far you go back.

123
00:06:33.929 --> 00:06:37.010
And what are some of the most prominent figures

124
00:06:37.010 --> 00:06:39.929
associated with transhumanism today?

125
00:06:40.940 --> 00:06:44.790
Um, WELL, today, I, I mean, yeah, there's, there's

126
00:06:44.790 --> 00:06:46.279
lots. I mean, as, as I say, you could,

127
00:06:46.630 --> 00:06:49.750
if you think historically, you've got Francis Bacon, obviously.

128
00:06:49.890 --> 00:06:53.950
Um, SO, uh, I think actually Max Moore argued

129
00:06:53.950 --> 00:06:57.579
that transhumanists should forget the Christian calendar and start

130
00:06:57.579 --> 00:07:00.390
a new one where year zero is the year

131
00:07:00.390 --> 00:07:03.549
that Bacon uh published Noum or Ganum. So he

132
00:07:03.549 --> 00:07:05.950
thinks he's that important in terms of, in terms

133
00:07:05.950 --> 00:07:10.429
of transhumanism. Uh, SO, uh, so, um, yeah, um.

134
00:07:10.989 --> 00:07:13.549
Uh, SO yeah, so you could argue, bacon is

135
00:07:13.549 --> 00:07:16.369
very influential. There's a, there's a Russian philosophical called

136
00:07:16.369 --> 00:07:20.040
Nikolai Fedorov, who was the father of Russian cosmism,

137
00:07:20.049 --> 00:07:24.000
which is a kind of proto-transhumanist offshoot again, um,

138
00:07:24.010 --> 00:07:26.609
in the, you know, kind of 19th century. Wynwood

139
00:07:26.609 --> 00:07:29.459
Reid, who I've mentioned. His book The Masdom of

140
00:07:29.459 --> 00:07:33.100
Man in 1872 kind of imagined all the current

141
00:07:33.100 --> 00:07:36.820
ideas of transhumanism such as space colonization, new human

142
00:07:36.820 --> 00:07:41.089
bodies, um, humanity functioning as a hive mind, uh,

143
00:07:41.140 --> 00:07:43.660
the invention of immortality he talked about, and, and

144
00:07:43.660 --> 00:07:46.859
the belief that humans would one day run rule

145
00:07:46.859 --> 00:07:49.739
the universe essentially as a kind of godlike posthuman

146
00:07:49.739 --> 00:07:52.579
entity. So all of that was imagined in 1872.

147
00:07:52.970 --> 00:07:57.209
Um, JBS Haldane and and JD Bernal, um, they,

148
00:07:57.290 --> 00:08:01.679
they kind of wrote very important, uh, proto-transhumanist ideas.

149
00:08:02.089 --> 00:08:04.690
Uh, Julian Huxley in 1951 it was that he

150
00:08:04.690 --> 00:08:07.450
potentially coined the term transhumanism in the modern sense

151
00:08:07.450 --> 00:08:10.920
in his article, Knowledge, Morality and Destiny. Um, I

152
00:08:10.920 --> 00:08:14.130
would also say FM 2030 is very important. He

153
00:08:14.130 --> 00:08:16.760
influenced Max Moore and Natasha Vieter Moore, who kind

154
00:08:16.760 --> 00:08:19.760
of were key figures in this Exopian movement. FM

155
00:08:19.760 --> 00:08:24.239
2030 was a guy called FM Esfandiari, and he

156
00:08:24.239 --> 00:08:26.920
changed his name to FM 2030 because he thought

157
00:08:26.920 --> 00:08:28.399
in the year 2030, he was going to be

158
00:08:28.399 --> 00:08:31.440
100 and life would be completely changed and radically

159
00:08:31.440 --> 00:08:34.080
improved. Uh, SADLY he died in 2000 and was

160
00:08:34.080 --> 00:08:38.039
cryonically frozen. Um, I also think Ray Kurzfell is,

161
00:08:38.087 --> 00:08:40.938
is a very important and influential thinker, um, uh,

162
00:08:40.999 --> 00:08:44.318
on the transhumanist movement, a particular type of transhumanism

163
00:08:44.318 --> 00:08:45.999
that we might talk about later, which you could

164
00:08:45.999 --> 00:08:49.758
call singularitarianism. Um, IN terms of modern thinkers, I

165
00:08:49.758 --> 00:08:52.318
would then add, Nick Bostrom, I would say is

166
00:08:52.318 --> 00:08:55.278
probably the most influential transhumanist thinker of the 21st

167
00:08:55.278 --> 00:08:58.489
century, I would say. Um, AND other notable people

168
00:08:58.489 --> 00:09:00.729
that I haven't really mentioned so far, David Pearce,

169
00:09:00.830 --> 00:09:04.520
who co-founded the World Transhumanist Association, which later became

170
00:09:04.770 --> 00:09:07.650
Humanity Plus, um, Anders Sandberg, who was kind of

171
00:09:07.650 --> 00:09:10.450
Nick Bostrom's sidekick at the Future of Humanity Institute,

172
00:09:10.489 --> 00:09:13.559
which was an important transhumanist kind of academic institute.

173
00:09:13.950 --> 00:09:17.320
And James Hughes, who's, um, the main kind of

174
00:09:17.530 --> 00:09:20.450
uh figure on, on, uh, the left leaning side

175
00:09:20.450 --> 00:09:24.330
of transhumanism, so-called techno-progressivism, he's quite an important guy.

176
00:09:24.780 --> 00:09:28.890
Um, BUT the truth is today. I would say

177
00:09:28.890 --> 00:09:32.369
the most important transhumanist thinkers are really the billionaire

178
00:09:32.369 --> 00:09:34.969
elites of Silicon Valley. Um, I'm not sure we

179
00:09:34.969 --> 00:09:37.250
could call them thinkers exactly, they're more like robber

180
00:09:37.250 --> 00:09:40.820
barons than philosophers maybe. Um, BUT you know, the,

181
00:09:40.940 --> 00:09:44.179
the, um, Peter Thiel, Elon Musk, Sam Altman, Mark

182
00:09:44.179 --> 00:09:47.020
Andreessen, the, the, and, and, you know, other tech

183
00:09:47.020 --> 00:09:50.099
billionaires as well, they have been extremely forthright in

184
00:09:50.099 --> 00:09:54.309
their transhumanist aims and ideas. Um, THEY'RE absolutely transhumanist

185
00:09:54.309 --> 00:09:57.900
ideologues and, um, they're also heavily invested obviously in

186
00:09:57.900 --> 00:10:00.315
doing. What they can to extend their wealth and

187
00:10:00.315 --> 00:10:05.155
power, including creating techno authoritarian political formations, and they

188
00:10:05.155 --> 00:10:08.234
use transhumanism, I think, as a kind of justification

189
00:10:08.234 --> 00:10:12.385
to themselves, mainly for these extreme extremist political positions,

190
00:10:12.395 --> 00:10:14.234
um, because it kind of tells them they can

191
00:10:14.234 --> 00:10:18.625
be the architects of some grand utopian future. So,

192
00:10:18.755 --> 00:10:20.534
um, so yeah, that's a kind of, you know,

193
00:10:20.755 --> 00:10:23.650
the, the, the both the. They're kind of more

194
00:10:23.650 --> 00:10:27.849
established transhumanist intellectual figures, but also the, the most

195
00:10:27.849 --> 00:10:31.070
important ones in terms of um real world impact

196
00:10:31.070 --> 00:10:33.650
and and the ones that are really taking, taking

197
00:10:33.650 --> 00:10:35.039
transhumanism seriously today.

198
00:10:36.109 --> 00:10:39.690
And what are the main tenets of transhumanism or

199
00:10:39.690 --> 00:10:42.109
the main values associated with it?

200
00:10:43.520 --> 00:10:45.250
Well, I think one thing to point out here

201
00:10:45.250 --> 00:10:47.650
is there's a lot of disagreement and a lot

202
00:10:47.650 --> 00:10:51.640
of variety of transhuman transhumanisms if you like, um,

203
00:10:52.049 --> 00:10:55.440
they don't necessarily see the same techno human evolution,

204
00:10:55.530 --> 00:10:57.200
what that should look like, what it will look

205
00:10:57.200 --> 00:11:00.340
like, etc. Um, HOWEVER, there are a few things

206
00:11:00.340 --> 00:11:01.940
we could point to. There's a, there's a line

207
00:11:01.940 --> 00:11:04.299
in the Transhumanist Reader, which is edited by Max

208
00:11:04.299 --> 00:11:07.140
Moore and Natasha Vitemore, uh, where they claim that

209
00:11:07.140 --> 00:11:11.380
transhumanism should be inclusive, pluralistic, and lead to the

210
00:11:11.380 --> 00:11:14.369
continuous questioning of knowledge. And, uh, for my book,

211
00:11:14.419 --> 00:11:16.619
I use that as a kind of jumping off

212
00:11:16.619 --> 00:11:18.619
point, because I, I kind of, what I tried

213
00:11:18.619 --> 00:11:20.989
to do was argue, well, those values are not

214
00:11:20.989 --> 00:11:24.539
going to be realized if transhumanism is developed in

215
00:11:24.539 --> 00:11:27.260
the context of advanced capitalism, which we, we can

216
00:11:27.260 --> 00:11:31.119
talk about later maybe. Um, SO, so those are

217
00:11:31.119 --> 00:11:33.599
values that I don't think are realizable for transhumanism

218
00:11:33.599 --> 00:11:37.359
in a capitalist context. Um, BUT, you know, you

219
00:11:37.359 --> 00:11:40.159
could also say that those aren't really foundational tenets

220
00:11:40.159 --> 00:11:42.919
or values. They aren't something that all transhumanists would

221
00:11:42.919 --> 00:11:46.359
ascribe to. Um, CERTAINLY these kind of new techno

222
00:11:46.359 --> 00:11:49.559
authoritarian formations would be strongly opposed to all of

223
00:11:49.559 --> 00:11:54.789
those principles, in truth, um. But another three kind

224
00:11:54.789 --> 00:11:58.869
of popular ideas amongst transhumanisms, which you could see

225
00:11:58.869 --> 00:12:01.270
as kind of values or or kind of, you

226
00:12:01.270 --> 00:12:04.640
know, um, tenets I guess. Um, AND those would

227
00:12:04.640 --> 00:12:10.145
be the proactionary principle, a morphological. Freedom and existential

228
00:12:10.145 --> 00:12:13.864
risk. So the proactionary principle is a kind of

229
00:12:13.864 --> 00:12:16.914
counter stance to the precautionary principle. Um, THE precautionary

230
00:12:16.914 --> 00:12:20.135
principle argues that we should be cau cautious not

231
00:12:20.135 --> 00:12:24.145
to cause harm when undertaking, you know, scientific practice.

232
00:12:24.539 --> 00:12:27.130
Um, BUT the proactionary principle argues, well, no, we

233
00:12:27.130 --> 00:12:29.969
should count the cost of not undertaking kind of

234
00:12:29.969 --> 00:12:32.890
risky measures, as well as the focus on potential

235
00:12:32.890 --> 00:12:37.239
harm. So that's the proactionary principle. The morphological freedom

236
00:12:37.609 --> 00:12:40.849
that emphasizes the right of each individual to have

237
00:12:40.849 --> 00:12:43.330
a free choice as to whether to adopt or

238
00:12:43.330 --> 00:12:47.380
reject kind of human enhancement possibilities. But in doing

239
00:12:47.380 --> 00:12:50.380
that, it kind of characterizes each human as having

240
00:12:50.380 --> 00:12:53.750
equal agency, uh, kind of almost by default, and

241
00:12:53.750 --> 00:12:56.739
effectively it fails, therefore to consider questions of power,

242
00:12:57.070 --> 00:13:01.030
social context, and so on. And Max Moore, who

243
00:13:01.030 --> 00:13:03.500
I mentioned, he, he was the progenitor, I think,

244
00:13:03.510 --> 00:13:06.510
of both of those ideas. But the concept of

245
00:13:06.510 --> 00:13:09.780
existential risk was really developed primarily by Nick Bostrom,

246
00:13:09.989 --> 00:13:13.109
and this was a kind of response to transhumanists

247
00:13:13.109 --> 00:13:16.609
realizing that the very technologies they wanted to develop

248
00:13:16.989 --> 00:13:19.429
may not create this kind of utopian future that

249
00:13:19.429 --> 00:13:22.179
they dreamed of, but rather it could bring about

250
00:13:22.590 --> 00:13:26.500
the destruction of humanity. So existential risk was a

251
00:13:26.500 --> 00:13:29.500
way of applying reason, uh, in a kind of

252
00:13:29.500 --> 00:13:31.179
a with a kind of uh I guess an

253
00:13:31.179 --> 00:13:33.909
academic gravitas, if you like, to say, don't worry,

254
00:13:33.979 --> 00:13:36.020
we're in control of this. Uh, WE shouldn't just

255
00:13:36.020 --> 00:13:39.299
give up on the development of dangerous technologies, we

256
00:13:39.299 --> 00:13:42.669
can manage the risk technocratically. AND and kind of

257
00:13:42.669 --> 00:13:46.190
employer a quantifying attitude to risk and and think

258
00:13:46.190 --> 00:13:48.409
about things in a very measured way. So those

259
00:13:48.409 --> 00:13:51.869
three ideas of of pro-actionary principle, morphological freedom and

260
00:13:51.869 --> 00:13:55.750
existential risk are very much uh central to transhumanism

261
00:13:55.750 --> 00:13:57.789
today, I would say most transhumanist discourse today.

262
00:13:58.830 --> 00:14:02.679
And are there also at least some common goals

263
00:14:02.679 --> 00:14:05.789
across the different types of transhumanism out there?

264
00:14:06.500 --> 00:14:09.590
Um, AGAIN, I would say there's not necessarily a

265
00:14:09.590 --> 00:14:13.030
complete consensus, in truth, um, but, uh, one way

266
00:14:13.030 --> 00:14:15.909
transhumanists sometimes frame their goals is, is to talk

267
00:14:15.909 --> 00:14:19.239
about the three supers. So there's super longevity, uh,

268
00:14:19.349 --> 00:14:22.190
so transhumanists would like us to have radically expanded

269
00:14:22.190 --> 00:14:24.900
lifespans, potentially even to live forever, some of them,

270
00:14:25.109 --> 00:14:27.030
or at least until we choose to stop dying

271
00:14:27.030 --> 00:14:29.549
ourselves. Some of them are also focused there on

272
00:14:29.549 --> 00:14:31.789
a health span, so increasing the human health span

273
00:14:31.789 --> 00:14:34.280
rather than the lifespan per se. Um, THEN there's

274
00:14:34.280 --> 00:14:37.190
super intelligence, so that's the aim of vastly increasing

275
00:14:37.440 --> 00:14:40.400
the cognitive capacities of the human race, or potentially

276
00:14:40.400 --> 00:14:42.510
the post-human race, which might be a different thing.

277
00:14:42.539 --> 00:14:45.090
We can, we can maybe get into that. Um,

278
00:14:45.330 --> 00:14:47.599
AND super wellbeing, so they would like us to

279
00:14:47.599 --> 00:14:49.289
improve on what it feels like to be human,

280
00:14:49.320 --> 00:14:51.669
you know, they talk about us being better than

281
00:14:51.669 --> 00:14:56.099
well. Perhaps we could, uh, radiate pure joy. Or

282
00:14:56.099 --> 00:14:58.580
we could have also maybe more choice and freedom

283
00:14:58.580 --> 00:15:01.090
about what our physical bodies are like and what

284
00:15:01.090 --> 00:15:03.340
they enable us to do. So why shouldn't we,

285
00:15:03.359 --> 00:15:05.979
we be able to, I don't know, echolocate like

286
00:15:05.979 --> 00:15:08.780
a bat or be stronger than a bear or

287
00:15:08.780 --> 00:15:10.580
fly like a bird or run faster than a

288
00:15:10.580 --> 00:15:12.900
cheetah, you know, so these kind of things as

289
00:15:12.900 --> 00:15:14.979
well, so, uh, that would come under there as

290
00:15:14.979 --> 00:15:18.090
well. Um, BUT, you know, I would also again

291
00:15:18.090 --> 00:15:21.109
point out that given the emphasis on morphological freedom,

292
00:15:21.409 --> 00:15:24.710
some, some transhumanists would even reject these three supers

293
00:15:25.010 --> 00:15:26.770
and would rather say, well, it's up to each

294
00:15:26.770 --> 00:15:29.609
person to decide what enhancement is for them. So

295
00:15:29.609 --> 00:15:30.890
some transhumanists would say that.

296
00:15:32.570 --> 00:15:34.890
So you mentioned that there are different kinds of

297
00:15:34.890 --> 00:15:38.489
transhumanism, of course, we're also going to get into

298
00:15:38.489 --> 00:15:42.210
more detail about some of them, particularly when later

299
00:15:42.210 --> 00:15:45.679
on in our conversation, we talk about task realism

300
00:15:45.679 --> 00:15:48.650
and things like that. But what would you say

301
00:15:48.650 --> 00:15:52.450
are at least the main kinds of transhumanism?

302
00:15:53.330 --> 00:15:57.059
Um, YEAH, I mean, there's, there is a lot

303
00:15:57.059 --> 00:16:00.700
of subcategories, increasing numbers of splinter groups and, and

304
00:16:00.700 --> 00:16:03.849
lots of kind of transhumanist adjacent ideas as well.

305
00:16:03.940 --> 00:16:05.859
So, you know, you could kind of name almost,

306
00:16:06.580 --> 00:16:08.890
there's just loads of them, proliferating all the time.

307
00:16:09.219 --> 00:16:12.619
Um, BUT there are certainly different political positions within

308
00:16:12.619 --> 00:16:16.010
transhumanism, so there's a kind of more inclusive left

309
00:16:16.010 --> 00:16:20.140
leaning version of transhumanism, which is usually called techno-rogressivism,

310
00:16:20.190 --> 00:16:22.539
which is largely associated with James Hughes, who I've

311
00:16:22.539 --> 00:16:25.650
mentioned. Um, ON the right, there's, uh, there's a

312
00:16:25.650 --> 00:16:27.880
more, there's the, the extropian movement, which I also

313
00:16:27.880 --> 00:16:29.489
mentioned, for example, that tends to be much more

314
00:16:29.489 --> 00:16:32.140
techno libertarian. So that's more of a kind of

315
00:16:32.140 --> 00:16:36.020
right wing um transhumanist philosophy. There are also religious

316
00:16:36.020 --> 00:16:39.780
and spiritualist kind of transhumanist groups. There's a Christian

317
00:16:39.780 --> 00:16:44.140
Transhumanist Association, a Mormon Transhumanist Association, there are Buddhist

318
00:16:44.140 --> 00:16:48.260
transhumanists, um, and there are also, you know, designations,

319
00:16:48.299 --> 00:16:50.010
some of which you pointed to there, things like

320
00:16:50.010 --> 00:16:54.219
singularitarianism, cosmism, long-termism. I'm sure we'll speak about some

321
00:16:54.219 --> 00:16:57.119
of these later on. Yes. And also now there's

322
00:16:57.119 --> 00:17:01.520
kind of newer related philosophies I would say, so

323
00:17:01.520 --> 00:17:03.239
we'll talk about those I'm sure later, but things

324
00:17:03.239 --> 00:17:07.800
like effective accelerationism, neo-reaction, these have, um, you know,

325
00:17:07.880 --> 00:17:10.118
a lot of transhumanist kind of influence in there

326
00:17:10.118 --> 00:17:11.839
as well, and they can be seen as kind

327
00:17:11.839 --> 00:17:14.280
of subcategories of transhumanism as well, potentially.

328
00:17:14.868 --> 00:17:17.308
Mhm. So, just a minute ago when I asked

329
00:17:17.308 --> 00:17:20.308
you about the goals of transhumanism, you mentioned the

330
00:17:20.308 --> 00:17:24.308
word improvement, and I guess that attached to it

331
00:17:24.308 --> 00:17:28.659
lots of times goes the word uh enhancement. So

332
00:17:28.659 --> 00:17:32.869
what does enhancement mean in the context of transhumanism?

333
00:17:33.750 --> 00:17:36.550
Yeah, it's a very good question and, and bizarrely,

334
00:17:36.619 --> 00:17:39.260
I don't think it's completely clear that that's the

335
00:17:39.260 --> 00:17:42.739
truth. So again, transhumanists don't necessarily agree on, on

336
00:17:42.739 --> 00:17:47.020
this. Um, SO some emphasize again morphological freedom, which

337
00:17:47.020 --> 00:17:50.685
means enhancement is a question of individual choice. Whereas

338
00:17:50.685 --> 00:17:54.045
others kind of think, well, objectively, there are, we

339
00:17:54.045 --> 00:17:56.224
can point to certain things and say that's an

340
00:17:56.224 --> 00:17:58.564
enhancement, so they, you know, it might be better

341
00:17:58.564 --> 00:18:00.324
to be able to move quicker or to be

342
00:18:00.324 --> 00:18:02.765
stronger or to be healthy for longer or to

343
00:18:02.765 --> 00:18:04.844
be more intelligent, they would say, well, that's just

344
00:18:04.844 --> 00:18:08.060
objectively better. So that, that, that kind of this,

345
00:18:08.310 --> 00:18:11.630
this kind of um almost contradiction between this objective

346
00:18:11.630 --> 00:18:15.630
assumption uh assumption and this kind of um individual

347
00:18:15.630 --> 00:18:18.869
choice is is a contradiction that most transhumanists don't

348
00:18:18.869 --> 00:18:21.069
even acknowledge in truth, but I I think it's

349
00:18:21.069 --> 00:18:24.050
definitely there. Um, AND I think, you know, maybe

350
00:18:24.050 --> 00:18:26.329
an even more important question is not just what

351
00:18:26.329 --> 00:18:30.329
does enhancement mean to transhumanists, but what does enhancement

352
00:18:30.329 --> 00:18:32.609
mean in the context of the social world we

353
00:18:32.609 --> 00:18:34.010
live in, you know, which is again what my

354
00:18:34.010 --> 00:18:36.959
book was exploring, this, this question of capitalism. So,

355
00:18:37.130 --> 00:18:40.560
so that's the question again that transhumanists don't tend

356
00:18:40.560 --> 00:18:43.089
to answer. They, they've they kind of neglect to

357
00:18:43.089 --> 00:18:45.209
think about that we live in an actual context,

358
00:18:45.290 --> 00:18:50.020
you know, they imagine. There's uh completely imaginary futures

359
00:18:50.020 --> 00:18:51.780
that are divorced from the reality of our, of

360
00:18:51.780 --> 00:18:55.459
our times. Um, SO absolutely, it's true that context

361
00:18:55.459 --> 00:18:58.140
shapes our conception of what we want, what we

362
00:18:58.140 --> 00:19:02.579
need, um, who we are, and so. Uh, YOU

363
00:19:02.579 --> 00:19:04.900
know, much of what we'd like to enhance is

364
00:19:04.900 --> 00:19:07.660
about really our competitive relationships with each other, for

365
00:19:07.660 --> 00:19:10.650
example, our, our ability to compete in the marketplace.

366
00:19:11.020 --> 00:19:13.819
So, of course, you know, here, um, the capitalist

367
00:19:13.819 --> 00:19:16.369
context means we're unlikely to be able to afford

368
00:19:16.369 --> 00:19:19.020
all the same level of enhancements, um, and, and

369
00:19:19.020 --> 00:19:21.219
the implications of that could be quite extreme. The

370
00:19:21.219 --> 00:19:23.099
more you can afford, the more you can enhance,

371
00:19:23.180 --> 00:19:24.859
the more you can enhance, the more you can

372
00:19:24.859 --> 00:19:27.699
afford. It's, it's, so it's kind of true already

373
00:19:27.699 --> 00:19:29.900
that we have, you know, social mobility has always

374
00:19:29.900 --> 00:19:33.239
been extremely limited for that very reason. But transhumanism

375
00:19:33.239 --> 00:19:37.650
I think could social stagnation and the class differences

376
00:19:37.650 --> 00:19:40.170
we already see. So I think transhumanists need to

377
00:19:40.170 --> 00:19:43.089
spend much more time thinking about what should enhancement

378
00:19:43.089 --> 00:19:45.329
mean if they are really committed to, you know,

379
00:19:45.410 --> 00:19:49.449
these values we mentioned earlier of inclusivity, plurality, and

380
00:19:49.449 --> 00:19:53.050
how we might restructure society in ways that ensure

381
00:19:53.050 --> 00:19:55.410
that that does become the reality, because I, I

382
00:19:55.410 --> 00:19:57.250
don't think it will in, in the context of

383
00:19:57.250 --> 00:19:59.770
capitalism. So, so yeah, that's a big challenge for

384
00:19:59.770 --> 00:20:00.770
transhumanists, I would say.

385
00:20:01.569 --> 00:20:06.130
And transhumanism, transhumanist suggest different kinds of enhancement as

386
00:20:06.130 --> 00:20:09.329
you mentioned there, there's, for example, physical enhancement or

387
00:20:09.329 --> 00:20:14.050
biological enhancement, psychological enhancement of different kinds of traits.

388
00:20:14.369 --> 00:20:19.050
And very interestingly, they also talk about moral enhancement.

389
00:20:19.130 --> 00:20:21.250
So what is that exactly?

390
00:20:22.020 --> 00:20:24.140
Yeah, um, that's again a a a very good

391
00:20:24.140 --> 00:20:27.550
question. So, um, interestingly, I would say there's a,

392
00:20:27.569 --> 00:20:30.770
a guy called Julian Savulescu, and he's probably the,

393
00:20:30.859 --> 00:20:33.410
the thinker that's most strongly related to this kind

394
00:20:33.410 --> 00:20:37.250
of claim or or idea of moral enhancement. Um,

395
00:20:37.260 --> 00:20:39.760
I don't think he actually identifies as a transhumanist,

396
00:20:39.780 --> 00:20:42.380
but to all intents and purposes, he, he really

397
00:20:42.380 --> 00:20:44.319
is one. I can't, I can't see quite how

398
00:20:44.319 --> 00:20:47.239
he's different, but um. He, he argues that, yeah,

399
00:20:47.329 --> 00:20:50.430
we need to upgrade the moral nature of the

400
00:20:50.430 --> 00:20:53.670
human species in order to survive. So he says

401
00:20:53.670 --> 00:20:56.469
we're facing, um, he calls it a Bermuda triangle

402
00:20:56.469 --> 00:21:00.469
of extinction. So the three things that threaten catastrophe

403
00:21:00.829 --> 00:21:05.430
are radical technological power, liberal democracy and human moral

404
00:21:05.430 --> 00:21:08.270
nature. So he argues, well, there's nothing we can

405
00:21:08.270 --> 00:21:12.099
do about radical technological development, it's coming. Um, SO,

406
00:21:12.160 --> 00:21:14.069
you know, it's the other two we need to

407
00:21:14.069 --> 00:21:16.349
kind of mess with for him. So, you know,

408
00:21:16.430 --> 00:21:19.109
liberal humanism might have to give way to a

409
00:21:19.109 --> 00:21:24.079
surveillance society for him and human moral nature. Should,

410
00:21:24.170 --> 00:21:27.650
well, we should maybe reprogram ourselves to kind of

411
00:21:27.650 --> 00:21:33.040
more desirable ends, um. So essentially Savulescu believes our

412
00:21:33.040 --> 00:21:35.790
moral natures are kind of now at odds with

413
00:21:35.790 --> 00:21:39.719
this modern socio-technical world that we've developed, this globalized

414
00:21:39.719 --> 00:21:42.310
world where we're all interconnected. So he, he points

415
00:21:42.310 --> 00:21:44.439
to our empathy and says it is limited and

416
00:21:44.439 --> 00:21:46.734
out of step with the global reach. We now

417
00:21:46.734 --> 00:21:49.275
have. He points out that we're short-termist in our

418
00:21:49.275 --> 00:21:52.035
thinking and we tend to only cooperate in smaller

419
00:21:52.035 --> 00:21:55.055
groups when, you know, we're being watched, essentially, um,

420
00:21:55.064 --> 00:21:56.925
and, you know, maybe that's why we can't fix

421
00:21:56.925 --> 00:21:58.964
climate change for him. Uh, HE points out that

422
00:21:58.964 --> 00:22:01.125
we tend to be distrustful of strangers and that

423
00:22:01.125 --> 00:22:04.579
we're naturally xenophobic. But the truth is all of

424
00:22:04.579 --> 00:22:08.339
these ideas are actually highly debatable and clearly socially

425
00:22:08.339 --> 00:22:11.739
dependent. Many of us aren't really xenophobic and um

426
00:22:11.739 --> 00:22:14.900
some people are highly empathetic and prosocial, and some

427
00:22:14.900 --> 00:22:18.099
societies develop these tendencies much more than others. So

428
00:22:18.099 --> 00:22:21.969
again, capitalism with its focus on individual self-interest, um,

429
00:22:21.979 --> 00:22:25.500
it's insistence that life is a competitive struggle of

430
00:22:25.500 --> 00:22:28.939
all against all, that kind of produces these shortcomings

431
00:22:28.939 --> 00:22:31.739
that Savulescu is is saying are essential to human

432
00:22:31.739 --> 00:22:35.089
nature. Um, SO, so, you know, he therefore wants

433
00:22:35.089 --> 00:22:36.979
us, he thinks that you can't fix it with

434
00:22:37.290 --> 00:22:40.209
social changes, it has to be rewriting our, our

435
00:22:40.209 --> 00:22:45.040
code effectively, rewriting our biology, um. Yeah, so, so

436
00:22:45.040 --> 00:22:48.680
Savulescu claims that these enhancements, um, you know, actually

437
00:22:48.680 --> 00:22:52.239
should be imposed potentially against people's will as well,

438
00:22:52.280 --> 00:22:55.359
if necessary, he thinks. So again, that obviously contravenes

439
00:22:55.359 --> 00:22:57.959
this principle of morphological freedom, but but as I

440
00:22:57.959 --> 00:22:59.800
say, none of these values are really held by

441
00:22:59.800 --> 00:23:02.000
all transhumanists. There's a, you know, a bit of

442
00:23:02.000 --> 00:23:05.339
play with all of them. So, um, yeah, Savulescu,

443
00:23:05.349 --> 00:23:07.780
what he doesn't seem to recognize, I think, is

444
00:23:07.780 --> 00:23:12.060
that moral perspectives differ incommensurably. We can't make them

445
00:23:12.060 --> 00:23:14.380
all agree. So he, he kind of almost makes

446
00:23:14.380 --> 00:23:16.859
an assumption that what is moral and what therefore

447
00:23:16.859 --> 00:23:21.099
what constitutes moral enhancement can be somehow universally agreed.

448
00:23:21.849 --> 00:23:25.209
Uh, WITH reason, rationality, um, but in reality there

449
00:23:25.209 --> 00:23:28.560
is no transcendent kind of view from nowhere, um,

450
00:23:28.689 --> 00:23:31.719
that can, you know, justify this, this authoritarian position.

451
00:23:31.770 --> 00:23:34.170
He, he kind of creates this imaginary thing he

452
00:23:34.170 --> 00:23:36.729
calls a god machine which could arbitrate with perfect

453
00:23:36.729 --> 00:23:39.670
fairness, but of course it doesn't exist. So this,

454
00:23:39.709 --> 00:23:44.180
this typifies, I think, um, a misguided transhumanism presumption

455
00:23:44.430 --> 00:23:49.030
that technological progress can actually solve moral problems. It

456
00:23:49.030 --> 00:23:52.069
it can't. Values can only be situated from a,

457
00:23:52.150 --> 00:23:54.469
from a particular perspective, and in the context of

458
00:23:54.469 --> 00:23:57.390
new technologies, of course, they would likely be enacted

459
00:23:57.390 --> 00:24:00.150
through a filter of, of kind of powerful vested

460
00:24:00.150 --> 00:24:03.699
interests. So again, Savulescu misses this influence of power

461
00:24:03.699 --> 00:24:07.290
in determining moral norms. Um, SO his naive hope

462
00:24:07.290 --> 00:24:09.810
of kind of fixing moral nature, I think, points

463
00:24:09.810 --> 00:24:13.489
to this really important flaw in transhumanist thought, essentially,

464
00:24:13.530 --> 00:24:16.810
you know, technological progress does not guarantee moral or

465
00:24:16.810 --> 00:24:19.290
ethical progress. Two world wars of the 20th century

466
00:24:19.290 --> 00:24:21.890
tell us that, and all the ensuing conflicts since

467
00:24:21.890 --> 00:24:24.689
and the ongoing climate catastrophe, you know, facts can

468
00:24:24.689 --> 00:24:27.574
only tell us. So much they can direct our

469
00:24:27.574 --> 00:24:30.895
means, but they can't in in themselves effectively determine

470
00:24:30.895 --> 00:24:34.175
moral ends. So Savulescu's idea that morality is a,

471
00:24:34.255 --> 00:24:37.324
is a kind of a potential site for, for,

472
00:24:37.334 --> 00:24:39.974
um, instrumental reason, I think, you know, something we

473
00:24:39.974 --> 00:24:43.295
can just fix, is symptomatic of this failing in

474
00:24:43.295 --> 00:24:46.449
so much transhumanist thought that. The simplistic idea that

475
00:24:46.449 --> 00:24:51.130
instrumental technical progress can fix or solve moral problems

476
00:24:51.130 --> 00:24:52.969
and so yeah, I think that's uh it's it's

477
00:24:52.969 --> 00:24:56.089
worth, you know, thinking through that because it's, it's

478
00:24:56.089 --> 00:24:58.290
something that just recurs again and again in transhumanist

479
00:24:58.290 --> 00:24:58.930
thought, that error.

480
00:25:00.099 --> 00:25:02.390
So there are two questions here that I think

481
00:25:02.390 --> 00:25:05.599
are very important for us to address, uh, particularly

482
00:25:05.599 --> 00:25:08.760
after we talked about enhancement, because I think it

483
00:25:09.000 --> 00:25:13.599
can bring them to mind is or does transhumanism

484
00:25:13.599 --> 00:25:16.000
imply hierarchy in any way?

485
00:25:17.150 --> 00:25:20.160
Um, YEAH, I mean, given that the notion of

486
00:25:20.160 --> 00:25:23.479
enhancement is really at the center of transhumanism, it's

487
00:25:23.479 --> 00:25:25.839
difficult to suggest that doesn't kind of have an

488
00:25:25.839 --> 00:25:28.079
assumption that comes along with it of one thing

489
00:25:28.079 --> 00:25:30.800
being better than another, which of course then implies

490
00:25:30.800 --> 00:25:34.609
hierarchy. Um, AGAIN, savvy transhumanists will deny it by

491
00:25:34.609 --> 00:25:37.170
pointing to morphological freedom, that's always their get out

492
00:25:37.170 --> 00:25:39.880
clause. Um, BUT to me that that's kind of,

493
00:25:40.050 --> 00:25:43.439
it's totally unconvincing because without taking the further step

494
00:25:43.439 --> 00:25:46.010
of recognizing that we live in a given social

495
00:25:46.010 --> 00:25:50.640
context, which may also dictate a hierarchical structure, um,

496
00:25:50.810 --> 00:25:53.329
transhumanists are simply kind of, you know, using that

497
00:25:53.329 --> 00:25:56.119
morphological freedom as a piece of rhetoric to avoid

498
00:25:56.119 --> 00:26:00.930
the real challenge. So. You know, could we create

499
00:26:00.930 --> 00:26:05.489
a form of transhumanism that was genuinely inclusive, non-hierarchical,

500
00:26:05.640 --> 00:26:08.380
pluralistic, I don't know. I think that's the great

501
00:26:08.380 --> 00:26:11.780
challenge, but it certainly demands a kind of ethical

502
00:26:11.780 --> 00:26:15.420
rethinking of our social structures, as well as, you

503
00:26:15.420 --> 00:26:17.900
know, as well as those kind of technological developments

504
00:26:17.900 --> 00:26:20.339
that transhumanism vision. So I think if you focus

505
00:26:20.339 --> 00:26:23.219
just on the latter without the former, you're actually

506
00:26:23.219 --> 00:26:26.900
likely to radicalize the hierarchical structures and the potential

507
00:26:26.900 --> 00:26:31.640
for. You know, unjust, inhumane and, and potentially catastrophic

508
00:26:31.640 --> 00:26:35.119
outcomes. So, so yeah, I do think transhumanism has

509
00:26:35.119 --> 00:26:38.239
a tendency towards hierarchy, absolutely implicit within it.

510
00:26:39.150 --> 00:26:42.839
OK. And the second question then is, is transhumanism

511
00:26:42.839 --> 00:26:44.560
an elitist movement?

512
00:26:45.420 --> 00:26:48.050
Yeah, I mean, um, again, you know, similar I

513
00:26:48.050 --> 00:26:52.079
would say there are transhumanists who would characterize their

514
00:26:52.079 --> 00:26:55.829
politics and aims as, as definitely anti-elitist. Um, AND

515
00:26:55.829 --> 00:26:57.150
in fact, I think, you know, if I'm honest,

516
00:26:57.229 --> 00:27:00.030
most of them would espouse some kind of inclusive

517
00:27:00.030 --> 00:27:04.900
anti-elitist values. Um, BUT the problem is how transhumanism

518
00:27:04.900 --> 00:27:07.709
will actually manifest itself in the real world. How

519
00:27:07.709 --> 00:27:10.150
do we ensure, you know, that there is no

520
00:27:10.150 --> 00:27:13.619
hint of elitism in the real world process, um,

521
00:27:13.670 --> 00:27:16.680
the kind of. The techno human evolution is taking,

522
00:27:16.750 --> 00:27:19.550
that's taking place at the moment is absolutely, it's

523
00:27:19.550 --> 00:27:24.390
reminiscent of the colonialist, exploitative, highly elitist, racist, patriarchal

524
00:27:24.390 --> 00:27:27.079
structures of the past. So for me, I, I

525
00:27:27.079 --> 00:27:29.089
don't know, I, I think any, any kind of

526
00:27:29.089 --> 00:27:32.410
respectable form of transhumanism would actually begin with that

527
00:27:32.410 --> 00:27:34.930
problem. That should be the starting point. So you

528
00:27:34.930 --> 00:27:37.500
know, rather than super longevity and the singularity and

529
00:27:37.500 --> 00:27:40.130
radical abundance and all of that, the real ethical

530
00:27:40.130 --> 00:27:43.969
challenges of rethinking society in an equitable and just

531
00:27:43.969 --> 00:27:46.449
way, in the face of the development of these

532
00:27:46.449 --> 00:27:49.569
radically potent technologies, I think should be the starting

533
00:27:49.569 --> 00:27:52.150
point of a, of a kind of ethically responsible

534
00:27:52.150 --> 00:27:52.849
transhumanism.

535
00:27:53.989 --> 00:27:57.739
So, ideologically speaking, what would you say are perhaps

536
00:27:57.739 --> 00:28:02.369
some of the most prominent arguments against transhumanism coming

537
00:28:02.369 --> 00:28:06.859
from people like, for example, the bioconservatives and others

538
00:28:06.859 --> 00:28:09.140
that oppose transhumanism.

539
00:28:10.089 --> 00:28:13.079
Yeah, well, I mean, that's a, a good question

540
00:28:13.079 --> 00:28:16.219
and, and absolutely, you know, you mentioned the bioconservatives

541
00:28:16.219 --> 00:28:18.660
there and, and that has been their, their vision

542
00:28:18.660 --> 00:28:21.270
has been one of the most stringent critiques of

543
00:28:21.270 --> 00:28:24.829
transhumanism and also perhaps the most famous critique of

544
00:28:24.829 --> 00:28:27.895
transhumanism. Um, ESSENTIALLY what they say is that they,

545
00:28:27.944 --> 00:28:30.385
they kind of wish to advocate for the integrity

546
00:28:30.385 --> 00:28:33.814
of modern humanity. So they, they criticize transhumanism on

547
00:28:33.814 --> 00:28:36.824
the grounds that it is in some way unnatural

548
00:28:36.824 --> 00:28:39.584
or in some way insults the integrity or dignity

549
00:28:39.584 --> 00:28:42.505
of the current human race. But that really depends

550
00:28:42.505 --> 00:28:45.694
on a kind of essentializing of some particular facet

551
00:28:45.694 --> 00:28:48.369
of the human. And I think therefore it's actually

552
00:28:48.369 --> 00:28:51.489
quite a weak critique because we've always developed alongside

553
00:28:51.489 --> 00:28:54.770
our technologies. We're, we're always changing and becoming something

554
00:28:54.770 --> 00:28:58.540
new. Life is processed. So I think clinging on

555
00:28:58.540 --> 00:29:01.810
to some imaginary essentialist quality of the human is

556
00:29:01.979 --> 00:29:04.859
is quite a misguided way to criticize transhumanism, to

557
00:29:04.859 --> 00:29:07.459
be honest. Um, SO that is the most famous

558
00:29:07.459 --> 00:29:09.140
critique, but I don't think it's the best. I

559
00:29:09.140 --> 00:29:11.780
think instead, much more effective critiques are coming to

560
00:29:11.780 --> 00:29:13.939
the fore now, and they're ones that, you know,

561
00:29:14.099 --> 00:29:17.650
really kind of focus on ethical questions around power,

562
00:29:17.770 --> 00:29:23.229
ecology, complexity, pluralism and inclusiveness, ideas I've mentioned. And

563
00:29:23.229 --> 00:29:25.099
when we think in, in these terms, we can

564
00:29:25.099 --> 00:29:28.989
see how transhumanism could become highly discriminatory, uh, it

565
00:29:28.989 --> 00:29:31.270
could radically increase inequality, it could lead to the

566
00:29:31.270 --> 00:29:34.670
development of technologies that threaten the existence, especially of

567
00:29:34.670 --> 00:29:38.449
vulnerable and disenfranchised people. So, um, so I think

568
00:29:38.449 --> 00:29:40.589
those kind of critiques that think through power and

569
00:29:40.589 --> 00:29:43.310
justice are much more effective, uh, when directed at

570
00:29:43.310 --> 00:29:45.430
the, at, you know, at transhumanism as a critique.

571
00:29:46.489 --> 00:29:49.290
So earlier on, you mentioned the a tie or

572
00:29:49.290 --> 00:29:53.609
a potential tie between transhumanism and capitalism particularly and

573
00:29:53.609 --> 00:29:58.410
more specifically advanced capitalism. So in what ways does

574
00:29:58.410 --> 00:30:04.569
transhumanism tied to capitalism, are there specific ideas, principles

575
00:30:04.569 --> 00:30:08.250
of capitalism that get manifested in transhumanism?

576
00:30:09.150 --> 00:30:11.520
Yeah, I think, um, I think definitely, I think

577
00:30:11.520 --> 00:30:14.150
it's worth, you know, kind of going through a

578
00:30:14.150 --> 00:30:17.760
few of the logics of capitalism and thinking about

579
00:30:17.760 --> 00:30:22.239
how transhumanism mirrors these logics, or how the implications

580
00:30:22.239 --> 00:30:26.140
of transhumanism could worsen the dangers that are inherent

581
00:30:26.319 --> 00:30:30.199
within capitalism. So, um, you know, I, I'll, I'll

582
00:30:30.199 --> 00:30:33.199
just list 6 things now and kind of explain

583
00:30:33.199 --> 00:30:36.170
the relationship, if you like, between transhumanism and capitalism

584
00:30:36.170 --> 00:30:38.839
in these ways. So the first is that, you

585
00:30:38.839 --> 00:30:41.069
know, capitalism is, as we all know, it's dependent

586
00:30:41.069 --> 00:30:44.319
on growth. So without growth, the system stalls and

587
00:30:44.319 --> 00:30:47.489
falls into crisis. And this growth fetish kind of

588
00:30:47.489 --> 00:30:50.760
motivates the drive to constantly bring as much of

589
00:30:50.760 --> 00:30:54.079
life as possible into the kind of um the

590
00:30:54.079 --> 00:30:57.400
auspices, the, the, the, the tentacles of capitalism if

591
00:30:57.400 --> 00:31:00.479
you like. um. So it is always for that

592
00:31:00.479 --> 00:31:04.199
reason, consuming new frontiers. And of course the possibility

593
00:31:04.199 --> 00:31:07.510
of endless growth on a finite planet is dependent

594
00:31:07.510 --> 00:31:10.359
on a notion of perpetual progress, cos otherwise it

595
00:31:10.359 --> 00:31:13.550
just doesn't make sense. And of course progress, growth

596
00:31:13.550 --> 00:31:17.010
and conquering new frontiers. Uh, WHETHER it's outward into

597
00:31:17.010 --> 00:31:19.569
space or inward into the secret codes of human

598
00:31:19.569 --> 00:31:23.130
beings, those things are integral to transhumanism too. So

599
00:31:23.130 --> 00:31:27.599
transhumanism kind of helps to, to, to justify or,

600
00:31:27.609 --> 00:31:29.859
or, uh, you know, enable this myth of, of

601
00:31:29.859 --> 00:31:34.270
perpetual growth on which uh capitalism depends. Um, SECONDLY,

602
00:31:34.469 --> 00:31:37.989
capitalism isn't just an economic system. SO that growth

603
00:31:37.989 --> 00:31:41.510
for progress and, and, uh, that, that, that, that

604
00:31:41.510 --> 00:31:44.579
kind of, um, desire for, for growth and progress

605
00:31:44.829 --> 00:31:49.709
means capitalism kind of, it, it cannibalizes non-economic zones.

606
00:31:49.819 --> 00:31:52.339
Um, SO it's, it's, for example, dependent on a

607
00:31:52.339 --> 00:31:54.770
history of colonial looting. Um, AND of course there

608
00:31:54.770 --> 00:31:59.089
are constant ongoing privatizations and enclosures of public forms

609
00:31:59.089 --> 00:32:02.420
of wealth. Um, IT also consumes nature and con

610
00:32:02.729 --> 00:32:06.050
conceptualizes the, the kind of, um, uh, the resources

611
00:32:06.050 --> 00:32:08.089
of nature as limitless and and free for the

612
00:32:08.089 --> 00:32:10.130
taking, so it sees nature as both a sink

613
00:32:10.130 --> 00:32:13.920
and a tap. And transhumanist in a, in a

614
00:32:13.920 --> 00:32:17.560
kind of capitalist context repeats this relationship, but explicitly

615
00:32:17.560 --> 00:32:20.280
for the human body too, which is then broken

616
00:32:20.280 --> 00:32:24.199
up, turned into data objectified. So bodies are needed

617
00:32:24.199 --> 00:32:27.800
for experimentation, data analysis. And just as bodies that

618
00:32:27.800 --> 00:32:30.839
are deemed surplus to the requirements of capital capitalism

619
00:32:30.839 --> 00:32:34.719
tend to be excluded or marginalized or incarcerated or

620
00:32:34.719 --> 00:32:38.239
often even killed, this might also become true of

621
00:32:38.239 --> 00:32:42.729
bodies surplus to transhumanist progress as well. Um, SO

622
00:32:42.729 --> 00:32:49.079
thirdly, capitalism conceptualizes humans as free, rational, autonomous individuals

623
00:32:49.319 --> 00:32:51.439
where each of us is, is responsible for our

624
00:32:51.439 --> 00:32:53.900
own position in the market, and we're at liberty

625
00:32:53.900 --> 00:32:57.349
to choose what to buy and when. And transhumanism

626
00:32:57.349 --> 00:33:01.000
absolutely echoes this, this kind of vision with, with

627
00:33:01.000 --> 00:33:03.839
its concept of morphological freedom, which which we've discussed

628
00:33:03.839 --> 00:33:05.920
already a lot. So the claim that each of

629
00:33:05.920 --> 00:33:08.239
us is at liberty to pursue our own version

630
00:33:08.239 --> 00:33:11.589
of enhancement. We're essentially all entrepreneurs of the self,

631
00:33:12.250 --> 00:33:15.349
as Foucault might put it. So, um, this, this

632
00:33:15.349 --> 00:33:18.310
responsibility for our position in the market also means

633
00:33:18.310 --> 00:33:21.310
that all humans are in competition with all other

634
00:33:21.310 --> 00:33:24.229
humans. So that's the fourth point. Our fundamental being

635
00:33:24.229 --> 00:33:27.869
is defined by the logics of competition rather than,

636
00:33:27.910 --> 00:33:32.510
say, collaboration. So it's rivalry and contestation, not solidarity

637
00:33:32.510 --> 00:33:36.319
and care. So this closes the possibility for transhumanism

638
00:33:36.319 --> 00:33:40.000
to become inclusive and pluralistic, and it also becomes

639
00:33:40.000 --> 00:33:43.119
rivalrous and subject to the demands of of capitalist

640
00:33:43.119 --> 00:33:46.869
progress which we might talk about. Um, 5th, for

641
00:33:46.869 --> 00:33:50.800
anything to be capitalizable, it needs a calculable value,

642
00:33:50.920 --> 00:33:54.790
uh, an exchange value. So effectively everything exists in

643
00:33:54.790 --> 00:33:57.910
a new empirical reality with an imagined price tag.

644
00:33:58.199 --> 00:34:01.430
So, um, you know, incomparable things are incorporated into

645
00:34:01.430 --> 00:34:04.010
the to a kind of system of equivalents. Uh,

646
00:34:04.390 --> 00:34:07.359
EVERYTHING becomes an object that way as well. And

647
00:34:07.359 --> 00:34:10.060
this is also true of people who are objectified

648
00:34:10.060 --> 00:34:11.929
both by the role they play in the system,

649
00:34:12.159 --> 00:34:14.760
but also their very being is an object for

650
00:34:14.760 --> 00:34:18.320
exploitation by capital. So again, our data, our genes,

651
00:34:18.438 --> 00:34:21.760
our desires, all are abstracted into products for profit

652
00:34:21.760 --> 00:34:25.120
making. And this objectification of the human is absolutely

653
00:34:25.120 --> 00:34:28.320
integral to uh to transhumanism as well, you know,

654
00:34:28.438 --> 00:34:31.000
it it it's, it needs it for, for transhumanist

655
00:34:31.000 --> 00:34:34.300
progress to exist. Um, FINALLY, I would say that

656
00:34:34.300 --> 00:34:37.179
capitalism is in a way, it's ethically indifferent. It

657
00:34:37.179 --> 00:34:41.300
doesn't promote an innate conceptualization of human flourishing. It

658
00:34:41.300 --> 00:34:43.458
just asks, is there a buyer, is there a

659
00:34:43.458 --> 00:34:46.060
seller, what's the price? That that's it's kind of

660
00:34:46.060 --> 00:34:51.050
ultimate position. So it projects and generalizes instrumental reason,

661
00:34:51.260 --> 00:34:53.129
uh, by which I mean the how of things,

662
00:34:53.300 --> 00:34:55.500
and not ethical reason, which, which might help us

663
00:34:55.500 --> 00:34:59.209
ask why, um, beyond simply the profit motive. Um,

664
00:34:59.379 --> 00:35:01.750
SO as we've seen with our analysis of Savulescu.

665
00:35:02.179 --> 00:35:04.850
Um, THIS is also a transhumanist trait, the belief

666
00:35:04.850 --> 00:35:08.120
instrumental progress can solve the question of moral progress.

667
00:35:08.330 --> 00:35:11.370
So it doesn't neither asks deeper questions about human

668
00:35:11.370 --> 00:35:14.969
flourishing, really. They just both assume a kind of

669
00:35:14.969 --> 00:35:20.449
individualized, progress based, growth-based model of enhancement. So, um.

670
00:35:21.219 --> 00:35:22.350
So yeah, I mean, I don't know if you

671
00:35:22.350 --> 00:35:23.750
want me to talk a little bit more about

672
00:35:23.750 --> 00:35:25.949
advanced capitalism specifically or or.

673
00:35:26.550 --> 00:35:28.469
Yes, I was going to ask you now about

674
00:35:28.469 --> 00:35:32.239
that. What is advanced capitalism? What does that mean

675
00:35:32.239 --> 00:35:32.760
exactly?

676
00:35:33.110 --> 00:35:33.270
Yeah,

677
00:35:33.429 --> 00:35:35.669
so, so I use the term advanced capitalism in

678
00:35:35.669 --> 00:35:38.070
the, in the title of my book and, and

679
00:35:38.070 --> 00:35:40.310
really what I'm pointing out to there is the

680
00:35:40.310 --> 00:35:42.850
fact that capitalism has been around for some time.

681
00:35:42.949 --> 00:35:45.939
So it has advanced its logics of development have

682
00:35:45.939 --> 00:35:48.790
developed. So it, it is a process itself. It's

683
00:35:48.790 --> 00:35:51.310
not um something that's set in stone and forever

684
00:35:51.310 --> 00:35:55.340
the same. It's always moving and and changing essentially.

685
00:35:55.639 --> 00:35:58.810
And, um, for the last 45 years or or

686
00:35:58.810 --> 00:36:01.889
around about, we've had a particularly toxic form of

687
00:36:01.889 --> 00:36:05.250
capitalism called neoliberalism. Um, AND, you know, that's a

688
00:36:05.250 --> 00:36:06.850
term that many people don't know what it means.

689
00:36:07.040 --> 00:36:09.520
Most transhumanists have no idea what it means. Um,

690
00:36:09.530 --> 00:36:11.320
AND it's interesting as well that at the moment,

691
00:36:11.399 --> 00:36:14.199
this, this kind of version of capitalism may actually

692
00:36:14.199 --> 00:36:16.419
be dying, and it might even be getting replaced

693
00:36:16.419 --> 00:36:18.929
by something much worse, uh, whether it's a kind

694
00:36:18.929 --> 00:36:22.080
of techno feudalism or tech authoritarianism, we will see,

695
00:36:22.139 --> 00:36:23.770
and maybe we can speak about those terms a

696
00:36:23.770 --> 00:36:26.870
little bit. Later as well. Um, BUT there are

697
00:36:26.870 --> 00:36:29.070
a few more logics, I would say I'll, I'll

698
00:36:29.070 --> 00:36:30.830
probably go just through two, just for the sake

699
00:36:30.830 --> 00:36:33.790
of time, um, which, uh, where these things tend

700
00:36:33.790 --> 00:36:36.989
to be true of capitalism generally, but they're made

701
00:36:36.989 --> 00:36:39.550
much more extreme by this version of of capitalism,

702
00:36:39.629 --> 00:36:42.989
this neoliberal version. So, um, the first is, is

703
00:36:42.989 --> 00:36:46.229
huge increases in inequality. So, you know, maybe the

704
00:36:46.229 --> 00:36:49.709
most significant trend that has kind of taken place

705
00:36:49.709 --> 00:36:52.979
during this most recent incarnation of, of global capitalism

706
00:36:53.229 --> 00:36:56.820
is a growth in inequality within developed Western countries

707
00:36:56.820 --> 00:36:59.979
and between the wealthiest 1% and the rest globally.

708
00:37:00.270 --> 00:37:03.155
So. These dynamics kind of completely undermine the idea

709
00:37:03.155 --> 00:37:05.554
that a process such as the development of transhumanist

710
00:37:05.554 --> 00:37:09.695
technologies, um, will be an inclusive process. We see

711
00:37:09.695 --> 00:37:13.195
in modern capitalism incredible concentrations of wealth and at

712
00:37:13.195 --> 00:37:16.354
the same time exclusions and expulsions of those who

713
00:37:16.354 --> 00:37:18.715
are not productive to the kind of wheels of

714
00:37:18.715 --> 00:37:22.419
capital. So. Um, YOU know, think about what happens

715
00:37:22.419 --> 00:37:24.500
at the moment to the marginalized, for example, the

716
00:37:24.500 --> 00:37:26.219
number of migrants who are allowed to die at

717
00:37:26.219 --> 00:37:29.300
sea every year. Um, AND if improvements in AI

718
00:37:29.300 --> 00:37:32.820
lead to significant automation unemployment, you could have vast

719
00:37:32.820 --> 00:37:36.449
swathes of society becoming the marginalized and the excluded.

720
00:37:36.820 --> 00:37:38.540
And at the same time, a small group of

721
00:37:38.540 --> 00:37:41.739
billionaires who own these technologies may have an almost

722
00:37:41.739 --> 00:37:44.620
total concentration of wealth with access to the most

723
00:37:44.620 --> 00:37:48.770
powerfully transformative technologies in world history. Alongside this kind

724
00:37:48.770 --> 00:37:51.729
of redundant mass of people. So that's, uh, you

725
00:37:51.729 --> 00:37:54.610
know, one potential danger. Um, THE other aspect of

726
00:37:54.610 --> 00:37:56.729
neoliberalism that's worth a quick mention here is the

727
00:37:56.729 --> 00:38:00.729
notion of financialization. So finance is, is pivotal in

728
00:38:00.729 --> 00:38:06.050
the increasingly kind of pervasive, complex, decentralized, um, and

729
00:38:06.050 --> 00:38:10.139
global character of capitalism. So if wages stagnate, the

730
00:38:10.139 --> 00:38:13.739
economy itself needs financialization because if if workers don't

731
00:38:13.739 --> 00:38:16.100
have the means to purchase consumer goods, the economy

732
00:38:16.100 --> 00:38:19.580
would collapse. So debt has become so pervasive, it

733
00:38:19.580 --> 00:38:22.439
has pretty much defined this, this kind of era

734
00:38:22.439 --> 00:38:26.179
of economic history. And and transhumanist narratives are actually

735
00:38:26.179 --> 00:38:29.500
extremely useful for a debt-based system because debt relies

736
00:38:29.500 --> 00:38:33.209
on the idea of speculation and future returns. So

737
00:38:33.209 --> 00:38:37.010
as climate crisis deepens, um, and political instability becomes

738
00:38:37.010 --> 00:38:39.770
more entrenched, the promise of a bright tomorrow looks

739
00:38:39.770 --> 00:38:42.929
more and more fanciful, but transhumanism, uh, you know,

740
00:38:43.010 --> 00:38:45.689
and the related technologies that it depends on, it

741
00:38:45.689 --> 00:38:49.050
promises a kind of unbelievable return on investment. So

742
00:38:49.050 --> 00:38:51.209
the AI bubble we're seeing right now is a

743
00:38:51.209 --> 00:38:54.260
great example. The AI industry is constantly saying, oh,

744
00:38:54.330 --> 00:38:57.129
AGI is just around the corner, super intelligence is

745
00:38:57.129 --> 00:38:59.770
on its way. AI will solve all problems. These

746
00:38:59.770 --> 00:39:03.709
claims kind of draw investment. And despite currently disappointing

747
00:39:03.709 --> 00:39:06.070
returns on that investment and the limited use of

748
00:39:06.080 --> 00:39:08.669
of current AI technologies now, it is these stories

749
00:39:08.669 --> 00:39:12.030
of radical progress around the corner which keep that

750
00:39:12.030 --> 00:39:15.929
debt bubble buoyant. So transhumanist stories are absolutely key

751
00:39:15.929 --> 00:39:18.590
to this kind of debt-based model of neoliberal capitalism.

752
00:39:19.850 --> 00:39:22.889
So let me ask you now about long-termism. What

753
00:39:22.889 --> 00:39:26.689
is it and how does it relate to transhumanism?

754
00:39:27.590 --> 00:39:31.320
Um, YEAH, so, so long-termism is, is essentially a

755
00:39:31.320 --> 00:39:35.399
fusion, uh, between a movement called effective altruism, or

756
00:39:35.399 --> 00:39:40.320
EA and and transhumanism. So basically, effective altruism was

757
00:39:40.320 --> 00:39:44.159
trying to rationally determine uh what was the most

758
00:39:44.159 --> 00:39:47.469
effective forms of, of doing good, essentially. So how

759
00:39:47.469 --> 00:39:50.770
do we do altruism well? Again, I would say

760
00:39:50.770 --> 00:39:52.929
it's a fairly, it's fairly misguided from the start,

761
00:39:52.969 --> 00:39:55.209
in my opinion, because it it doesn't understand that

762
00:39:55.209 --> 00:39:59.290
ethics and values are situated and perspectivible and rather

763
00:39:59.290 --> 00:40:03.449
assumes a kind of calculable, rationally determinal, uh almost

764
00:40:03.449 --> 00:40:06.330
utilitarian logic. OK, so I think it's flawed from

765
00:40:06.330 --> 00:40:09.979
its inception. But um the first iteration of, of

766
00:40:09.979 --> 00:40:12.370
EA uh came up with bed nets, I think

767
00:40:12.370 --> 00:40:14.340
that was what they said we needed, more bed

768
00:40:14.340 --> 00:40:17.669
nets, um, because mosquitoes were the great killer. Um,

769
00:40:17.679 --> 00:40:20.080
THEN it focused on the meat industrial complex, I

770
00:40:20.080 --> 00:40:22.120
think, uh, uh, a huge amount of suffering of

771
00:40:22.120 --> 00:40:24.639
animals. Um, IT, I kind of identified that as

772
00:40:24.639 --> 00:40:27.120
the greatest source of suffering in the world. Um,

773
00:40:27.199 --> 00:40:29.840
SO those were the two initial projects. But then

774
00:40:29.840 --> 00:40:34.030
transhumanism interjected into this kind of rationalist, uh, analysis

775
00:40:34.030 --> 00:40:37.280
of, of doing good. And the key transhumanist thinker

776
00:40:37.280 --> 00:40:39.949
in long-termism is Nick Bostrom, who I said is,

777
00:40:40.000 --> 00:40:42.760
is the most influential, uh, transhumanist bostrom of the

778
00:40:42.760 --> 00:40:47.300
21st century, I think. And what Bostrom argues essentially

779
00:40:47.300 --> 00:40:49.449
is that we are on the verge of making

780
00:40:49.780 --> 00:40:54.060
posthuman digital consciousnesses that are at least equivalent to

781
00:40:54.060 --> 00:40:56.780
human lives. Um, AND I think he has different

782
00:40:56.780 --> 00:40:59.379
numbers in different articles, but one of them says

783
00:40:59.379 --> 00:41:02.739
that, um, 10 to 29, so 10 with 290s

784
00:41:02.739 --> 00:41:06.389
after it, potential human lives are wasted every second

785
00:41:06.580 --> 00:41:10.379
that we are not colonizing the Virgo supercluster with

786
00:41:10.379 --> 00:41:13.679
computer generated minds of human equivalents. So the number

787
00:41:13.679 --> 00:41:15.629
of people on Earth right now is just 8.2

788
00:41:15.629 --> 00:41:19.709
billion or so. And this number is so vastly

789
00:41:19.709 --> 00:41:23.030
smaller than the potential what he called cos cosmic

790
00:41:23.030 --> 00:41:25.209
endowment is the term he used. So what we

791
00:41:25.209 --> 00:41:27.310
can build as as a human race, this kind

792
00:41:27.310 --> 00:41:30.750
of post-digital empire that we can build amongst the

793
00:41:30.750 --> 00:41:34.780
stars. So, so this, you know, put simply, the

794
00:41:34.790 --> 00:41:37.235
the the. The comparison here is that these 8.2

795
00:41:37.235 --> 00:41:39.784
billion people just don't matter. Their lives are what

796
00:41:39.784 --> 00:41:42.824
he calls mere ripples, um, you know, so climate

797
00:41:42.824 --> 00:41:47.014
crises, genocides, wars, all of them are minor episodes,

798
00:41:47.024 --> 00:41:48.985
as long as some survive and are able to

799
00:41:48.985 --> 00:41:51.415
pass on the baton of technological expertise to create

800
00:41:51.415 --> 00:41:54.169
this cosmic endowment. And of course what that means

801
00:41:54.169 --> 00:41:57.199
is that um you know, it's those who hold

802
00:41:57.199 --> 00:41:59.729
that that uh that kind of the baton of

803
00:41:59.729 --> 00:42:02.610
technological expertise are the people that matter. In other

804
00:42:02.610 --> 00:42:04.729
words, it's the Silicon Valley billionaires and their big

805
00:42:04.729 --> 00:42:07.449
tech companies. Um, THEY'RE much more valuable than the

806
00:42:07.449 --> 00:42:10.129
rest of the 8.2 billion people who, who just

807
00:42:10.129 --> 00:42:13.110
don't really matter in comparison. And so of course,

808
00:42:13.560 --> 00:42:18.000
for that reason, long-termism has proved extremely appealing, unsurprisingly,

809
00:42:18.159 --> 00:42:21.199
to the Silicon Valley elites, because it, it says

810
00:42:21.199 --> 00:42:23.639
to them that they're the, the central protagonists in

811
00:42:23.639 --> 00:42:27.550
the most important moment in human history, effectively. Um,

812
00:42:27.600 --> 00:42:30.040
Toby Ord who I think co coined the term

813
00:42:30.040 --> 00:42:33.610
long-termism, I think. Um, HE, he wrote a book

814
00:42:33.610 --> 00:42:35.889
called The Precipice, so the idea that we're, we're

815
00:42:35.889 --> 00:42:37.729
right on the edge of, of, you know, either

816
00:42:37.729 --> 00:42:42.290
going, falling to existential risk and disappearing, or fulfilling

817
00:42:42.290 --> 00:42:45.360
our cosmic endowment amongst the stars. And again, you

818
00:42:45.360 --> 00:42:47.729
know, Elon Musk, he, he, um, there's a guy,

819
00:42:47.850 --> 00:42:50.810
Will McCaskill is another long-termist thinker. He wrote a

820
00:42:50.810 --> 00:42:52.600
book called What We Oe the Future, and Musk

821
00:42:52.600 --> 00:42:54.469
um tweeted that it was a close match for

822
00:42:54.469 --> 00:42:57.010
his own philosophy. And Musk also tweeted one of

823
00:42:57.010 --> 00:42:59.610
Bostrom's articles saying it's likely the most important paper

824
00:42:59.610 --> 00:43:02.439
ever written. So, so you can see the real

825
00:43:02.439 --> 00:43:05.030
influence of long-termism on, on people like Elon Musk.

826
00:43:05.449 --> 00:43:08.360
Emile P. Torres, who's done, he's written extensively on

827
00:43:08.360 --> 00:43:10.840
this, and very effectively as well, and he calls

828
00:43:10.840 --> 00:43:14.800
radical long-termism um the most influential ideology in the

829
00:43:14.800 --> 00:43:17.110
world today that most people have never heard about,

830
00:43:17.120 --> 00:43:19.199
and that's for, for that reason of its influence

831
00:43:19.199 --> 00:43:20.439
on people like Elon Musk.

832
00:43:21.810 --> 00:43:25.790
How about accelerationism and I know that uh some

833
00:43:25.790 --> 00:43:30.030
prominent figures in the effective altruism movement have also

834
00:43:30.030 --> 00:43:34.419
recently embraced accelerationism. So what is the link there

835
00:43:34.419 --> 00:43:39.429
and also the link between accelerationism and capitalism and

836
00:43:39.429 --> 00:43:40.500
transhumanism.

837
00:43:40.909 --> 00:43:42.989
OK, yeah, that's, uh, that's a very good question,

838
00:43:43.110 --> 00:43:46.370
bit of a complex one, but um. So essentially,

839
00:43:46.399 --> 00:43:50.139
in, in capitalism, labor is both the source of

840
00:43:50.139 --> 00:43:52.860
all value, so all profits are generated from the

841
00:43:52.860 --> 00:43:56.219
exploitation of labor. And and yet labor is also

842
00:43:56.219 --> 00:44:00.659
constantly squeezed out or replaced by automating technologies. So

843
00:44:00.659 --> 00:44:03.580
that that is uh for accelerationism, that's the central

844
00:44:03.580 --> 00:44:07.510
contradiction in capitalism. Um, AND so accelerationism is a,

845
00:44:07.550 --> 00:44:10.669
is a philosophy which essentially tries to solve this

846
00:44:10.669 --> 00:44:14.909
contradiction. Benjamin Noyes says it's, it's, um, it's by

847
00:44:14.909 --> 00:44:18.070
alchemizing labor with the machine. That's what accelerationism is

848
00:44:18.070 --> 00:44:20.310
trying to do. And it has, it has quite

849
00:44:20.310 --> 00:44:23.030
a lot of different manifestations actually, and, and proponents

850
00:44:23.030 --> 00:44:25.189
on both the left of the political spectrum and

851
00:44:25.189 --> 00:44:28.030
the right. So, uh, Nick Sernerchek and Alex Williams,

852
00:44:28.110 --> 00:44:34.320
who once wrote an accelerationist manifesto. They claim that

853
00:44:34.320 --> 00:44:37.120
um Marx and Nick Land are the two kind

854
00:44:37.120 --> 00:44:41.479
of paradigmatic uh accelerationist thinkers, so Marx obviously on

855
00:44:41.479 --> 00:44:43.600
the left and and Nick Land on the right.

856
00:44:44.070 --> 00:44:47.179
Um, SO the left version of this might see

857
00:44:47.179 --> 00:44:50.540
technology as bringing about a kind of post-work utopia,

858
00:44:50.830 --> 00:44:54.949
something like fully automated luxury communism, that's uh Aaron

859
00:44:54.949 --> 00:44:57.270
Bustai wrote a book called that. So, so the

860
00:44:57.270 --> 00:44:58.870
idea we'd no longer have to work, the machines

861
00:44:58.870 --> 00:45:00.350
would do it all and all for us, and

862
00:45:00.350 --> 00:45:03.379
we'd all live happily together in, in kind of,

863
00:45:03.389 --> 00:45:06.060
uh, you know, abundance and luxury. So that that's

864
00:45:06.060 --> 00:45:09.080
the kind of left wing version. The right sees

865
00:45:09.080 --> 00:45:11.169
a kind of um what Nick Lam calls a

866
00:45:11.169 --> 00:45:14.689
meat grinder future, where it's the pure pure kind

867
00:45:14.689 --> 00:45:19.209
of um spinning wheels of capital frenzy, uh, that

868
00:45:19.209 --> 00:45:22.330
creates a humanless future essentially. It's pure growth and

869
00:45:22.330 --> 00:45:24.889
efficiency. So the human is just a kind of

870
00:45:24.889 --> 00:45:27.649
detritus, it's a drag to this process, and it

871
00:45:27.649 --> 00:45:30.530
could be made much purer without the messy human.

872
00:45:30.939 --> 00:45:32.939
So in a sense, it's, it's not very transhumanist

873
00:45:32.939 --> 00:45:35.459
at all because it's, it's not at all anthropocentric.

874
00:45:35.469 --> 00:45:37.629
It doesn't put the human at the center of

875
00:45:37.629 --> 00:45:39.340
things, it puts capital at the center of things.

876
00:45:39.419 --> 00:45:42.020
So it's a, it's a very capital centric idea,

877
00:45:42.060 --> 00:45:44.610
the right wing version. But for that very reason,

878
00:45:44.739 --> 00:45:48.209
actually, this right wing version has proved very popular

879
00:45:48.209 --> 00:45:51.860
with techno utopian libertarians. Uh, AND as I mentioned

880
00:45:51.860 --> 00:45:56.370
earlier, extropianism, this kind of 1980s, 1990s original transhumanist

881
00:45:56.370 --> 00:45:59.560
modern movement. That was exactly that. It was a

882
00:45:59.560 --> 00:46:03.879
techno optimistic, libertarian movement. It was hugely influenced by

883
00:46:03.879 --> 00:46:06.760
people like Ayn Rand and and Hayek, etc. So

884
00:46:06.760 --> 00:46:10.750
there's this huge overlap between this transhumanist techno libertarianism

885
00:46:10.750 --> 00:46:14.629
and this kind of accelerationist techno libertarianism, essentially. Um,

886
00:46:14.639 --> 00:46:18.610
AND, and now, as you say, accelerationism is. Inspiring

887
00:46:18.939 --> 00:46:21.850
new kind of tech inflected movements on the right,

888
00:46:22.100 --> 00:46:25.060
uh, which are also very informed by transhumanism. The

889
00:46:25.060 --> 00:46:29.100
most notable ones are effective accelerationism, or EAC for

890
00:46:29.100 --> 00:46:32.540
short, and neo-reaction, um, of which actually Nick Land

891
00:46:32.540 --> 00:46:35.020
is also one of the, the central thinkers along

892
00:46:35.020 --> 00:46:37.780
with uh Curtis Yarvin, who's been, you know, noted

893
00:46:37.780 --> 00:46:40.699
as a, as an important neo-reactionary thinker.

894
00:46:41.929 --> 00:46:44.350
So it's interesting that you mentioned that in the

895
00:46:44.350 --> 00:46:49.310
case of acceleration is, we can find accelerationist takes

896
00:46:49.310 --> 00:46:52.030
on the left and the right with figures like

897
00:46:52.030 --> 00:46:55.590
Marxx and Nick Land. So when it comes to

898
00:46:55.590 --> 00:47:01.110
the political side of things, is transhumanism, not accelerationism

899
00:47:01.110 --> 00:47:06.040
but transhumanism associated with any specific kind of political

900
00:47:06.040 --> 00:47:09.110
poll or movement? I mean, can we see it

901
00:47:09.110 --> 00:47:11.429
both on the left and the right or not?

902
00:47:11.820 --> 00:47:14.909
Um, YEAH, yeah, so, um, I think I mentioned

903
00:47:14.909 --> 00:47:17.909
that you've got techno-progressivism on the left and techno

904
00:47:17.909 --> 00:47:20.189
libertarianism on the right, and they can be seen

905
00:47:20.189 --> 00:47:23.709
as two holes within transhumanism. Um, THERE have also

906
00:47:23.709 --> 00:47:26.989
been transhumanist political parties, OK, I think um there

907
00:47:26.989 --> 00:47:30.060
was one transhumanist Italian politician who was elected, actually,

908
00:47:30.469 --> 00:47:31.669
um, but I think, I think there was some

909
00:47:31.669 --> 00:47:34.790
sort of scandal that made his, his political career

910
00:47:34.790 --> 00:47:37.870
slightly short-lived. Famously, also, there's a, there's a guy

911
00:47:37.870 --> 00:47:41.550
called Zoltanistan who was another very famous American transhumanist,

912
00:47:41.560 --> 00:47:43.989
and he toured the US in a, in an

913
00:47:43.989 --> 00:47:46.629
immortality bus, he called it, to campaign for the

914
00:47:46.629 --> 00:47:51.469
2016 election, uh, very unsuccessfully, of course. Um. But

915
00:47:51.469 --> 00:47:54.860
what transhumanists, I think, have essentially realized is, uh,

916
00:47:55.389 --> 00:47:57.620
is, you know, kind of the democratic route to

917
00:47:57.620 --> 00:48:00.379
political success is, is not for them. So, um,

918
00:48:00.689 --> 00:48:03.110
transhumanists, however, at the same time have, have kind

919
00:48:03.110 --> 00:48:05.870
of uh they've they've got more power than ever

920
00:48:05.870 --> 00:48:07.429
before, and it's, it's like I say, it's not

921
00:48:07.429 --> 00:48:10.510
through campaigning on a transhumanist agenda or being democratic.

922
00:48:10.745 --> 00:48:14.665
Elected, it's, it's it's essentially by hijacking democracy. So

923
00:48:14.665 --> 00:48:17.945
Elon Musk and Peter Thiel have been the architects

924
00:48:17.945 --> 00:48:21.465
of this. Thiel is JD Vance's benefactor, and Musk,

925
00:48:21.504 --> 00:48:24.625
as we've seen, seems to be incredibly influential and

926
00:48:24.625 --> 00:48:27.560
active in the new Trump government. Um, AND indeed

927
00:48:27.560 --> 00:48:30.739
the, the neo-reactionary ideas of Curtis Yarvin, which I've

928
00:48:30.739 --> 00:48:34.889
mentioned, in particular, these appear as essentially the intellectual

929
00:48:34.889 --> 00:48:37.770
backbone for a kind of strain within the American

930
00:48:37.770 --> 00:48:41.250
government right now. So it is not pure transhumanism,

931
00:48:41.290 --> 00:48:43.409
of course. Um, I would say it's a kind

932
00:48:43.409 --> 00:48:46.129
of almost a cancerous offshoot, uh, but it's taken

933
00:48:46.129 --> 00:48:48.929
its place right at the center of global power,

934
00:48:48.969 --> 00:48:51.760
which is another reason I think it's incredibly important

935
00:48:51.929 --> 00:48:56.709
to understand what transhumanism is. I think also um

936
00:48:56.709 --> 00:48:59.580
another kind of interesting political poll that might be

937
00:48:59.580 --> 00:49:02.699
worth mentioning uh comes from a thinker I mentioned

938
00:49:02.699 --> 00:49:08.090
earlier, FM 2030. So, um, in 1973 he published

939
00:49:08.090 --> 00:49:11.370
a book called Upingers, a Futurist Manifesto, and in

940
00:49:11.370 --> 00:49:14.169
it he claims that the traditional politics of right

941
00:49:14.169 --> 00:49:17.850
and left are all down politics because they're all

942
00:49:17.850 --> 00:49:21.590
concerned with limitation. Um, BUT, you know, transhumanism and,

943
00:49:21.629 --> 00:49:24.590
and this kind of the transcendent possibilities of the

944
00:49:24.590 --> 00:49:27.939
upwing means that we will, we will just progress

945
00:49:27.939 --> 00:49:31.750
beyond ethical con contestations, we'll progress beyond the right

946
00:49:31.750 --> 00:49:34.979
and left. Again, this false assumption that technological progress

947
00:49:35.360 --> 00:49:40.679
solves all ethical contestation. And building on Esfandieri's notion,

948
00:49:40.760 --> 00:49:44.600
FM 2030's notion, um, some transhumanists called Steve Fuller

949
00:49:44.600 --> 00:49:47.199
and Monica Lipinska, they later claim in their book

950
00:49:47.199 --> 00:49:50.080
The Pro-actionary imperative that that up down politics are

951
00:49:50.280 --> 00:49:52.919
are they're kind of the new political polls for

952
00:49:52.919 --> 00:49:56.439
the future really, uh, with Up being transhumanist and,

953
00:49:56.610 --> 00:50:00.739
and, and pro-actionary and. Techno utopian and down being

954
00:50:00.739 --> 00:50:04.939
posthumanist and precautionary and environmentally minded. So, so there's

955
00:50:04.939 --> 00:50:06.810
a, a kind of, you know, a version of,

956
00:50:06.820 --> 00:50:10.020
of a new political polarity where transhumanism is seen

957
00:50:10.020 --> 00:50:14.100
as the upwing and kind of environmentalism, etc. IS

958
00:50:14.100 --> 00:50:15.100
seen as as the down.

959
00:50:16.639 --> 00:50:19.270
So tell us now about this term, which I

960
00:50:19.270 --> 00:50:24.360
think was coined by Emil Porres task realism, which

961
00:50:24.360 --> 00:50:26.800
is, I think we could say a collection of

962
00:50:26.800 --> 00:50:29.679
different kinds of ideology. Some of them we've already

963
00:50:29.679 --> 00:50:36.534
talked about. It includes Transhumanism, extropianism, singularitarianism, cosmism, rationalism,

964
00:50:36.945 --> 00:50:40.334
effective altruism, and long-termism. I mean, tell us about

965
00:50:40.334 --> 00:50:43.225
the term why and why do all of these

966
00:50:43.225 --> 00:50:46.544
different kinds of ideologies go together here.

967
00:50:47.000 --> 00:50:50.379
Yeah, OK, good, good question. So, so Tesreel is

968
00:50:50.379 --> 00:50:53.219
essentially, it's an acronym that was invented, as you

969
00:50:53.219 --> 00:50:55.770
say, by uh Emil P. Torres and and Tim

970
00:50:55.770 --> 00:50:58.739
Gebru. And as I understand it, it came from

971
00:50:58.739 --> 00:51:01.739
a conversation between them where Emil was, was, he

972
00:51:01.739 --> 00:51:03.929
was trying to describe the kind of the lineage

973
00:51:03.929 --> 00:51:07.209
of transhumanist philosophies which had led to a current

974
00:51:07.209 --> 00:51:10.959
obsession with artificial general intelligence in the AI industry.

975
00:51:11.219 --> 00:51:13.260
And whenever he was, you know, referring to, he

976
00:51:13.260 --> 00:51:14.909
would talk about, oh well, this person who was

977
00:51:14.909 --> 00:51:16.790
an extropian, and it would just get very, very

978
00:51:16.790 --> 00:51:19.070
confusing, so he kind of, you know, uh sorry,

979
00:51:19.149 --> 00:51:21.780
they, they coined this, this concept of tests reel.

980
00:51:22.030 --> 00:51:23.870
So the list, as you say, it starts with

981
00:51:23.870 --> 00:51:28.300
transhumanism, and here they're referring to Julian Huxley's notion

982
00:51:28.300 --> 00:51:31.750
and identifying, um, you know, his connection with eugenics

983
00:51:31.750 --> 00:51:33.459
actually, which they write about a lot as well.

984
00:51:33.889 --> 00:51:37.050
Um, NEXT emerged extropianism, which I've mentioned, that's the

985
00:51:37.050 --> 00:51:39.570
movement in the 80s and 90s, uh, really the

986
00:51:39.570 --> 00:51:42.969
start of the modern transhumanist movement, very libertarian, fairly

987
00:51:42.969 --> 00:51:46.290
juvenile philosophy and truth, um, complete obsession with, with

988
00:51:46.290 --> 00:51:49.830
Ayn Rand and and Hayek, etc. After that, you

989
00:51:49.830 --> 00:51:53.949
get singularitarianism, that's mainly inspired by Ray Kurzweil. It's

990
00:51:53.949 --> 00:51:56.669
the idea that humans will merge with technologies and

991
00:51:56.669 --> 00:51:58.870
super intelligence will kind of bring about a kind

992
00:51:58.870 --> 00:52:01.550
of event horizon where we can't even imagine what's

993
00:52:01.550 --> 00:52:03.350
on the other side of that of that event

994
00:52:03.350 --> 00:52:07.790
horizon. Then there's cosmism, which is not a Russian

995
00:52:07.790 --> 00:52:10.030
cosmism, which some people have cited it as Russian

996
00:52:10.030 --> 00:52:13.040
cosmism, that's a different philosophy. Uh, THIS is um

997
00:52:13.040 --> 00:52:18.219
uh cosmism, it's um. Uh, IT'S particularly associated with

998
00:52:18.219 --> 00:52:21.409
a transhumanist thinker called Ben Goetzel, and he's key

999
00:52:21.409 --> 00:52:25.379
to popularizing the term artificial general intelligence. Um, THEN

1000
00:52:25.379 --> 00:52:28.459
after that you get rationalism, that's mainly related to

1001
00:52:28.459 --> 00:52:30.659
the less wrong wiki and the work of Eliezer

1002
00:52:30.659 --> 00:52:33.800
Yudkovsky. Uh, WHO again also, by the way, uh,

1003
00:52:34.000 --> 00:52:36.040
you know, he was part of the Estroian mailing

1004
00:52:36.040 --> 00:52:37.479
list back in the day. So again, these are

1005
00:52:37.479 --> 00:52:39.479
all, these people are all connected and have been

1006
00:52:39.479 --> 00:52:42.679
for decades. Um, AND then you get effective altruism,

1007
00:52:42.689 --> 00:52:45.429
which I've mentioned, which is this utilitarian rationalist approach

1008
00:52:45.429 --> 00:52:48.139
to morality, and it's got a. Huge overlap with

1009
00:52:48.139 --> 00:52:50.659
the rationalist community, same kind of group of people

1010
00:52:50.659 --> 00:52:53.659
essentially. And finally, long-termism, which, as I said, is

1011
00:52:53.659 --> 00:52:55.540
a, is a kind of fusing of transhumanism and

1012
00:52:55.540 --> 00:52:58.260
effective altruism, a kind of short circuit to the

1013
00:52:58.260 --> 00:53:01.620
movement which makes transhumanism the ultimate form of moral

1014
00:53:01.620 --> 00:53:04.939
good in the universe. Now, essentially what Emil and

1015
00:53:04.939 --> 00:53:08.449
Teamn are trying to uh kind of signal or

1016
00:53:08.459 --> 00:53:11.590
or suggest um with this term is, well, firstly,

1017
00:53:11.649 --> 00:53:14.939
it's the historical links to eugenics, which they see

1018
00:53:14.939 --> 00:53:19.270
manifest all over the current AI industry. Um, THERE'S

1019
00:53:19.270 --> 00:53:21.629
also, uh, the point that there's an incredible amount

1020
00:53:21.629 --> 00:53:24.709
of overlap and through line of the characters involved

1021
00:53:24.709 --> 00:53:28.669
in these movements, especially from Extropianism onwards. So Bostrom,

1022
00:53:28.760 --> 00:53:32.629
Yudkovsky, Moore, they're all there on the original Extropian

1023
00:53:32.629 --> 00:53:36.229
mailing lists. Goetzel too is a long-term transhumanist. They

1024
00:53:36.229 --> 00:53:39.229
have been members of the same organizations and going

1025
00:53:39.229 --> 00:53:41.189
to the same conferences for years, so all these

1026
00:53:41.189 --> 00:53:42.870
people are, you know, a small little clique that

1027
00:53:42.870 --> 00:53:47.679
are interconnected, um. And whilst the ideas of transhumanism

1028
00:53:47.679 --> 00:53:50.080
have always been maybe a little bit niche, a

1029
00:53:50.080 --> 00:53:52.639
little bit crackpot on the edges, uh, you know,

1030
00:53:52.959 --> 00:53:56.199
suddenly big tech is the most hegemonic sector of

1031
00:53:56.199 --> 00:53:58.780
the economy and its leaders are the richest people

1032
00:53:58.780 --> 00:54:01.560
in the world. And that, that whole industry and

1033
00:54:01.560 --> 00:54:04.669
in particular the AI part of it, are absolutely

1034
00:54:04.669 --> 00:54:07.805
steeped in the mythology. Of these ideologies. So it's

1035
00:54:07.805 --> 00:54:09.716
the water they swim in, it's the air they

1036
00:54:09.716 --> 00:54:12.355
breathe. If you want to understand the most powerful

1037
00:54:12.355 --> 00:54:14.676
forces on planet Earth right now, you can't do

1038
00:54:14.676 --> 00:54:17.275
it without understanding the influence of this this strain

1039
00:54:17.275 --> 00:54:21.395
of transhumanist philosophies. It's why OpenAI's stated aim is

1040
00:54:21.395 --> 00:54:24.676
to build artificial general intelligence, for example. So that's

1041
00:54:24.676 --> 00:54:27.152
what Tere was it was a temp. Thing to

1042
00:54:27.152 --> 00:54:30.271
do, um, Emil is kind of quite keen to

1043
00:54:30.271 --> 00:54:33.261
point out that you can be a transhumanist without

1044
00:54:33.261 --> 00:54:35.511
being a test realist, uh, which might seem like

1045
00:54:35.511 --> 00:54:38.352
a contradiction in terms, but this test realal notion

1046
00:54:38.352 --> 00:54:40.552
is, is kind of, it, it both points to

1047
00:54:40.552 --> 00:54:43.832
a historical through line, though, those, those names kind

1048
00:54:43.832 --> 00:54:45.672
of follow an order, so that's the historical order

1049
00:54:45.672 --> 00:54:50.780
in which they emerged. Um, AND also. Um, uh,

1050
00:54:50.860 --> 00:54:52.429
YOU know, the, the, it, it, it's the, it's

1051
00:54:52.429 --> 00:54:55.189
the form of those, uh, philosophies that, that kind

1052
00:54:55.189 --> 00:54:59.139
of influence the AI industry and, and, um, it

1053
00:54:59.139 --> 00:55:03.860
kind of create this obsession with artificial general intelligence

1054
00:55:03.860 --> 00:55:06.659
in particular. So, uh, so yeah, it's that, that

1055
00:55:06.659 --> 00:55:10.100
particular type of of transhumanist mindset which they're drawing

1056
00:55:10.100 --> 00:55:10.580
attention to.

1057
00:55:11.110 --> 00:55:14.280
Mhm. But since you can be a transhumanist, a

1058
00:55:14.280 --> 00:55:17.300
transhumanist and not a task realist, and at a

1059
00:55:17.300 --> 00:55:20.459
certain point there you mentioned the link that Emil

1060
00:55:20.459 --> 00:55:25.580
Pitter is establishes between task realism and the eugenics.

1061
00:55:25.620 --> 00:55:30.590
Is there also a link between transhumanism and eugenics?

1062
00:55:31.510 --> 00:55:35.300
Uh, YES, um, I, I think there is, um,

1063
00:55:35.810 --> 00:55:39.300
so. Well, for one thing, I think I mentioned

1064
00:55:39.300 --> 00:55:44.050
earlier that um er Julian Huxley is, is often

1065
00:55:44.050 --> 00:55:47.899
identified as, as the kind of progenitor of, of

1066
00:55:47.899 --> 00:55:53.040
transhumanist ideology. And um Julian Huxley was a member

1067
00:55:53.040 --> 00:55:55.939
of the Eugenics Society, for example. So, so that's

1068
00:55:55.939 --> 00:56:00.260
one very obvious link between transhumanism and and eugenics.

1069
00:56:00.649 --> 00:56:05.080
Um, SOME transhumanists even just embrace the term eugenics.

1070
00:56:05.379 --> 00:56:07.020
They, they say, yep, that's what we are, it's

1071
00:56:07.020 --> 00:56:10.080
great. Others play it down. Um, SO some, uh,

1072
00:56:10.219 --> 00:56:13.540
again, they point to morphological freedom to differentiate their

1073
00:56:13.540 --> 00:56:16.110
form of eugenics to state sponsored forms of eugenics

1074
00:56:16.110 --> 00:56:19.969
of the past, such as Nazism. Um, uh, YEAH,

1075
00:56:20.060 --> 00:56:21.820
I mean, Tim Neat and Emil have been doing

1076
00:56:21.820 --> 00:56:24.979
some great work on the links between transhumanist ideologies

1077
00:56:24.979 --> 00:56:28.129
and eugenics. Um, I think what is particularly worrying

1078
00:56:28.129 --> 00:56:31.129
at the moment is that there is a kind

1079
00:56:31.129 --> 00:56:33.929
of fusion again of transhumanism with a bunch of

1080
00:56:33.929 --> 00:56:38.290
other political ideologies on the right, including overtly racist

1081
00:56:38.290 --> 00:56:42.169
ideas that advocate deeply troubling forms of eugenics and

1082
00:56:42.169 --> 00:56:46.520
conceptions of natural human hierarchies. Um, SO, you know,

1083
00:56:47.010 --> 00:56:49.409
I think forms of transhumanism that engage with this

1084
00:56:49.409 --> 00:56:53.179
kind of thinking are. REALLY problematic, utterly abhorrent in

1085
00:56:53.179 --> 00:56:54.939
truth, and, and I would say a clear and

1086
00:56:54.939 --> 00:56:58.179
present danger to society. We, we absolutely need to

1087
00:56:58.179 --> 00:57:01.260
contest and reject those ideas. Um, I think the

1088
00:57:01.260 --> 00:57:04.729
work of Quinlibodian is very useful for understanding how

1089
00:57:04.899 --> 00:57:08.020
the history of neoliberalism actually underpins this trend. His

1090
00:57:08.020 --> 00:57:12.129
new book, Hae Bastards, explores this, um, this relationship

1091
00:57:12.129 --> 00:57:15.500
between this kind of, um, eugenic ideas, uh, human,

1092
00:57:15.620 --> 00:57:18.709
natural human hierarchy and, and, uh, and kind of

1093
00:57:18.709 --> 00:57:20.620
the, you know, how it emerged out of, out

1094
00:57:20.620 --> 00:57:23.739
of, um, neoliberalism, uh, so it's, which is absolutely

1095
00:57:23.739 --> 00:57:26.919
worth um worth investigating. So yeah, I think, you

1096
00:57:26.919 --> 00:57:29.639
know, transhumanism has a strong link to eugenics, ultimately

1097
00:57:29.639 --> 00:57:32.719
eugenics is how do we make better people. Transhumanism

1098
00:57:32.719 --> 00:57:36.280
is the same project, um, so yeah, strong links

1099
00:57:36.280 --> 00:57:36.520
there.

1100
00:57:37.659 --> 00:57:39.699
What is it that in your book you call

1101
00:57:39.699 --> 00:57:44.939
data totalitarianism and what part is played by things

1102
00:57:44.939 --> 00:57:49.330
like surveillance, uh, the idea of the quantified self,

1103
00:57:49.649 --> 00:57:53.770
algorithms, personal data, and, and these other things that,

1104
00:57:54.100 --> 00:57:55.820
uh, well, I mean, what kind of role do

1105
00:57:55.820 --> 00:57:58.699
they play in data totalitarianism?

1106
00:57:59.750 --> 00:58:03.550
Yeah, OK, so, um, a, a, a, a big

1107
00:58:03.550 --> 00:58:07.219
desire of transhumanists is essentially to make the world

1108
00:58:07.550 --> 00:58:11.070
tractable to human will. Um, SO the, the mathematician

1109
00:58:11.070 --> 00:58:14.340
John van Neumann, for example, he said, uh, all

1110
00:58:14.340 --> 00:58:18.629
stable processes we shall predict, all unstable processes we

1111
00:58:18.629 --> 00:58:21.909
shall control. And that sentence has proved a very

1112
00:58:21.909 --> 00:58:26.239
powerful inspiration to the transhumanist ideology. Um, MAYBE we

1113
00:58:26.239 --> 00:58:28.000
can talk a bit more later on about the

1114
00:58:28.000 --> 00:58:31.590
kind of cybernetic influence on transhumanism, but essentially, if

1115
00:58:31.590 --> 00:58:35.080
the world with all its complexity can be simplified

1116
00:58:35.080 --> 00:58:38.639
or abstracted into something we can control, then transhumanist

1117
00:58:38.639 --> 00:58:43.010
fantasies are, are boosted, um. So you could think

1118
00:58:43.010 --> 00:58:45.280
of this as a, as a um as a

1119
00:58:45.280 --> 00:58:48.409
kind of dataism. You could use the term deism.

1120
00:58:48.489 --> 00:58:50.209
I think Yuval No Harari calls it a kind

1121
00:58:50.209 --> 00:58:52.929
of new religion of deism. Essentially it's the belief

1122
00:58:52.929 --> 00:58:55.500
that big data and AI uh will allow us

1123
00:58:55.500 --> 00:58:58.770
to predict and control everything. And of course big

1124
00:58:58.770 --> 00:59:01.810
data is now absolutely central to the new capitalist

1125
00:59:01.810 --> 00:59:04.330
structures as well. To the extent that, that, you

1126
00:59:04.330 --> 00:59:07.649
know, theorists have suggested we're we're entering a new

1127
00:59:07.649 --> 00:59:11.020
form of capitalism. So for Shoshana Zubov, it's, it's

1128
00:59:11.020 --> 00:59:14.530
surveillance capitalism. um OR, you know, for Yanis Varoufakis,

1129
00:59:14.570 --> 00:59:17.229
we've we've now actually gone beyond capitalism and entered

1130
00:59:17.229 --> 00:59:22.300
techno feudalism. Um, SO again, transhumanism and, and capitalism,

1131
00:59:22.550 --> 00:59:25.949
they align here, uh, and, and indeed many transhumanists

1132
00:59:25.949 --> 00:59:29.699
advocate extensive surveillance systems, which of course would provide

1133
00:59:29.699 --> 00:59:33.090
the data to enable all of this. So the

1134
00:59:33.090 --> 00:59:37.250
urge towards, you know, algorithmic control essentially, uh, comes

1135
00:59:37.250 --> 00:59:39.810
from the idea that, well, humans in this, in

1136
00:59:39.810 --> 00:59:43.510
this system are perceived as knowledge objects, essentially in,

1137
00:59:43.570 --> 00:59:46.010
in the tradition of radical behaviorism. So that, you

1138
00:59:46.010 --> 00:59:48.689
know, we're trying to understand this as a as

1139
00:59:48.689 --> 00:59:51.209
an object, a system that we can predict and

1140
00:59:51.209 --> 00:59:57.010
control. Um, AND, uh, just, uh, so what, what

1141
00:59:57.010 --> 00:59:59.719
you need is information that allow that allows us

1142
00:59:59.719 --> 01:00:03.760
to analyze, you know, predict even direct human behavior,

1143
01:00:03.969 --> 01:00:06.530
and big data is, is supposedly enabling us to

1144
01:00:06.530 --> 01:00:08.560
do this. And of course you would think that

1145
01:00:08.969 --> 01:00:12.639
that would leave transhumanists fearing for human agency and,

1146
01:00:12.649 --> 01:00:16.090
you know, realizing their beloved morphological freedom can't survive

1147
01:00:16.090 --> 01:00:19.439
this process. But instead they actually embrace it because

1148
01:00:19.729 --> 01:00:22.370
without, you know, this fantasy of big data and

1149
01:00:22.370 --> 01:00:25.530
AI um we we simply won't be able to

1150
01:00:25.530 --> 01:00:28.489
control everything, which is essentially their, their aim. So

1151
01:00:28.489 --> 01:00:31.649
we have a, a kind of potent reconstruction of

1152
01:00:31.649 --> 01:00:36.129
social reality premised on a small subset of humanity

1153
01:00:36.129 --> 01:00:39.399
having privileged information. And powerful knowledge over the rest

1154
01:00:39.399 --> 01:00:41.760
of humanity, you know, and that's kind of there

1155
01:00:41.760 --> 01:00:45.989
in surveillance capitalism, techno feudalism and in transhumanist statism.

1156
01:00:46.239 --> 01:00:49.760
So, so the desire within transhumanism to control all

1157
01:00:49.760 --> 01:00:54.949
unstable processes, uh, and to transcend all confining qualities

1158
01:00:54.949 --> 01:00:57.439
requires a world that is limited its in its

1159
01:00:57.439 --> 01:01:01.959
complexity, um. So the entirety is tractable to human

1160
01:01:01.959 --> 01:01:03.989
reason and will, and it is, for me it's

1161
01:01:03.989 --> 01:01:07.350
that totality which I call data totalitarianism. It's a

1162
01:01:07.350 --> 01:01:11.709
kind of extension of surveillance capitalism, an extension of

1163
01:01:11.709 --> 01:01:14.860
what Ulysses Mejias and Nick Cory called data colonialism.

1164
01:01:15.129 --> 01:01:18.100
Um, YOU know, again, Varoufakis, techno feudalism, it's an

1165
01:01:18.100 --> 01:01:20.020
extension of that. It's a, it's a, a kind

1166
01:01:20.020 --> 01:01:23.219
of coming together of that capitalist trajectory of data

1167
01:01:23.219 --> 01:01:27.209
colonialism, surveillance capitalism with this transhumanist idea, this dream

1168
01:01:27.209 --> 01:01:31.360
of controlling everything, meaning everything needs to become um

1169
01:01:31.360 --> 01:01:33.860
data that we can then just manipulate to our

1170
01:01:33.860 --> 01:01:36.550
own desires. Um, SO I use the concept in

1171
01:01:36.550 --> 01:01:39.310
my book as a way to undermine that transhumanist

1172
01:01:39.310 --> 01:01:41.830
value I mentioned earlier of the continuous questioning of

1173
01:01:41.830 --> 01:01:45.429
knowledge, because it's based on, on the reverence essentially

1174
01:01:45.429 --> 01:01:49.719
of instrumentalist forms of knowledge production aimed at ever

1175
01:01:49.719 --> 01:01:54.110
increasing potency of, of means geared towards um even

1176
01:01:54.110 --> 01:01:57.340
more problematic ends in the form of essentially control,

1177
01:01:57.590 --> 01:02:00.310
profit and power. Um, SO that's, that's kind of

1178
01:02:00.310 --> 01:02:01.669
what I was trying to get at with this

1179
01:02:01.669 --> 01:02:03.350
term, data totalitarianism.

1180
01:02:04.429 --> 01:02:09.909
So you mentioned briefly the influence of cybernetics, cybernetics

1181
01:02:09.909 --> 01:02:13.149
over transhumanism. So let's talk a little bit more

1182
01:02:13.149 --> 01:02:17.870
about that, particularly how, how cybernetic framing of the

1183
01:02:17.870 --> 01:02:21.830
mind influences the way that transhumanists think about the

1184
01:02:21.830 --> 01:02:25.340
human mind and the potential consequences of that.

1185
01:02:26.639 --> 01:02:28.879
Yeah, so, so I, I think it is, it

1186
01:02:28.879 --> 01:02:33.149
is cybernetics that enables transhumanists to conceive of life

1187
01:02:33.149 --> 01:02:37.520
as just information processing. So that includes minds and

1188
01:02:37.520 --> 01:02:41.429
everything else. Everything can be abstracted from its actual

1189
01:02:41.429 --> 01:02:46.280
material instantiation and converted to a code which uh

1190
01:02:46.280 --> 01:02:48.719
which kind of stands in for it. And that

1191
01:02:48.719 --> 01:02:51.719
potentially enables any form of being to exist in

1192
01:02:51.719 --> 01:02:54.949
a different instantiation or sub-state and for us to

1193
01:02:54.949 --> 01:02:57.909
edit and control it. Um, SO for example, we

1194
01:02:57.909 --> 01:03:01.590
can imagine decoding our conscious mind and turning it

1195
01:03:01.590 --> 01:03:04.659
into code and uploading that into a virtual system.

1196
01:03:04.919 --> 01:03:08.449
So. Essentially this, this creates a kind of um

1197
01:03:08.449 --> 01:03:12.590
a material information hierarchy. Information is more pliable than

1198
01:03:12.590 --> 01:03:15.459
material reality, so we just have to learn to

1199
01:03:15.459 --> 01:03:18.250
speak the code of life. Uh, DNA for example,

1200
01:03:18.379 --> 01:03:20.060
can be seen as the code of life. We

1201
01:03:20.060 --> 01:03:22.169
can edit it, copy it, make it a new.

1202
01:03:22.419 --> 01:03:26.780
Information is conceptualized as potentially separate from the material

1203
01:03:26.780 --> 01:03:29.399
world. Um, SO, and, and, and as a result,

1204
01:03:29.469 --> 01:03:33.800
intelligence becomes this magical force that allows us to

1205
01:03:33.800 --> 01:03:37.320
process information more effectively. Um, ALL of life becomes

1206
01:03:37.320 --> 01:03:41.959
just a question of increasingly potent intelligence controlling information

1207
01:03:41.959 --> 01:03:45.760
processes. Um, SO, you know, transhumanist discourse is absolutely

1208
01:03:45.760 --> 01:03:49.800
full of language which expresses humans in machineic terms

1209
01:03:49.800 --> 01:03:52.840
or, or like computers. So humans, for example, are

1210
01:03:52.840 --> 01:03:57.330
suboptimal systems or bug ridden code, right? So these,

1211
01:03:57.500 --> 01:04:01.419
these metaphors, they're appealing to transhumanist because if humans

1212
01:04:01.419 --> 01:04:04.770
are just code, we can be upgraded and fixed,

1213
01:04:04.979 --> 01:04:07.060
um, the, the, you know, and the world as

1214
01:04:07.060 --> 01:04:09.260
well with all its limitations can be expanded as

1215
01:04:09.260 --> 01:04:12.120
well. We can have limitless resources and time. We

1216
01:04:12.120 --> 01:04:14.459
just need to write the code, rewrite the code.

1217
01:04:14.659 --> 01:04:20.179
So by making things quantifiable and readable, complex interrelational

1218
01:04:20.179 --> 01:04:24.100
aspects of reality which defy reductionism are simply removed

1219
01:04:24.100 --> 01:04:26.790
from consideration. And, and that, you know, but, but

1220
01:04:26.790 --> 01:04:30.270
also along with that, that goes, um, the kind

1221
01:04:30.270 --> 01:04:33.260
of it means that questions of meaning disappear too.

1222
01:04:33.750 --> 01:04:36.229
Everything is just intelligence and information processing in an

1223
01:04:36.229 --> 01:04:39.510
abstract sense. So even human being becomes something that

1224
01:04:39.510 --> 01:04:42.070
can be fused with or transferred over to the

1225
01:04:42.070 --> 01:04:45.310
digital realm. Um, YOU know, so we no longer

1226
01:04:45.310 --> 01:04:47.629
can say what what being human is in the.

1227
01:04:47.719 --> 01:04:51.149
Existential or philosophical or ethical sense. Those questions no

1228
01:04:51.149 --> 01:04:53.669
longer have meaning for transhumanists, you know, the human

1229
01:04:53.669 --> 01:04:59.300
is simply copyable, changeable, replicable, controllable, and potentially immortal.

1230
01:04:59.550 --> 01:05:02.260
Um, BUT of course, the material world, in reality,

1231
01:05:02.350 --> 01:05:06.629
does not just, uh, disappear. Life is not just

1232
01:05:06.629 --> 01:05:09.830
code, and you can't escape ethicality and questions of

1233
01:05:09.830 --> 01:05:12.820
meaning. By pretending everything is just like a computer

1234
01:05:12.820 --> 01:05:15.469
and the implications of doing so are very dangerous,

1235
01:05:15.550 --> 01:05:18.310
but, but that is the kind of cybernetic influence

1236
01:05:18.310 --> 01:05:22.189
on, on transhumanism, the fantasy that um life is

1237
01:05:22.189 --> 01:05:26.310
just information and we can process it however we

1238
01:05:26.310 --> 01:05:29.949
will by increasing our intelligence. You know, intelligence becomes

1239
01:05:30.080 --> 01:05:33.620
the cardinal virtue, I guess, of, of um. Of

1240
01:05:33.620 --> 01:05:34.469
that kind of thinking.

1241
01:05:35.530 --> 01:05:38.560
Mhm. So let me ask you just one question

1242
01:05:38.560 --> 01:05:43.000
about artificial intelligence. You've already alluded to it, particularly

1243
01:05:43.000 --> 01:05:47.189
AGI or artificial general intelligence several times during our

1244
01:05:47.189 --> 01:05:51.620
conversation. But uh how does it tie to transhumanism

1245
01:05:51.840 --> 01:05:55.760
and what are the expectations and claims made about

1246
01:05:55.760 --> 01:06:00.239
it by accelerationists and transhumanists?

1247
01:06:01.370 --> 01:06:03.219
Um, YEAH, I mean, I think I've, I've touched

1248
01:06:03.219 --> 01:06:04.459
on this a bit, like you said, I mean,

1249
01:06:04.620 --> 01:06:08.050
AI, I think is fundamental to transhumanism. They, they

1250
01:06:08.050 --> 01:06:10.669
think of it as a form of magic. Um,

1251
01:06:10.820 --> 01:06:13.139
YOU'LL hear them saying things like we're making Sam

1252
01:06:13.139 --> 01:06:15.689
think, um, and they talk of alchemy and stuff

1253
01:06:15.689 --> 01:06:18.139
like that. So they, they don't all agree on.

1254
01:06:18.235 --> 01:06:22.425
Whether, you know, super intelligence or artificial general intelligence

1255
01:06:22.735 --> 01:06:26.284
is a threat to human existence, they don't even

1256
01:06:26.334 --> 01:06:28.564
even agree whether that matters or not. So some,

1257
01:06:28.655 --> 01:06:30.375
some of them would like to see humans replaced

1258
01:06:30.375 --> 01:06:32.895
by what they call mind children, which is digital

1259
01:06:32.895 --> 01:06:37.919
artificial intelligences, essentially. So um. Yeah, so, uh, you

1260
01:06:37.919 --> 01:06:39.919
know, intelligence is, is, as I say, it's the

1261
01:06:39.919 --> 01:06:42.550
kind of the cardinal virtue of, of up politics,

1262
01:06:42.810 --> 01:06:46.239
because if life is just information processing, then intelligence

1263
01:06:46.239 --> 01:06:49.800
is what enables us to order information more effectively.

1264
01:06:50.000 --> 01:06:52.590
So that's why AI is so important to transhumanism.

1265
01:06:52.840 --> 01:06:55.120
So, um, but. You know, it's worth pointing out

1266
01:06:55.120 --> 01:06:59.350
that artificial intelligence is a very narrowly conceived conception

1267
01:06:59.350 --> 01:07:02.919
of intelligence, really, right? Um, YOU know, it's, it's

1268
01:07:02.919 --> 01:07:06.959
abstracted out of embodied being and situated context and

1269
01:07:06.959 --> 01:07:10.800
into machines and made subject potentially to exponential growth.

1270
01:07:11.250 --> 01:07:13.060
So this is the magic, the, the kind of

1271
01:07:13.060 --> 01:07:16.979
the explosion, the trick, the possibility, um, which kind

1272
01:07:16.979 --> 01:07:20.020
of goes beyond the imagination, so it leads to

1273
01:07:20.020 --> 01:07:22.870
the singularity, the event horizon and the black hole

1274
01:07:22.870 --> 01:07:26.179
behind it which we simply cannot know. um, SO.

1275
01:07:26.479 --> 01:07:29.270
You know, to some transhumanists, it is effectively God,

1276
01:07:29.370 --> 01:07:31.370
uh, you know, and, and they, they lean on,

1277
01:07:31.399 --> 01:07:34.209
on AGI as the thing that will solve all

1278
01:07:34.209 --> 01:07:38.290
problems, including all ethical problems. Um, SO yeah, AI

1279
01:07:38.290 --> 01:07:42.439
absolutely, it's, it's, it's key to transhumanist ideas, um,

1280
01:07:42.469 --> 01:07:46.449
and, and it underpins their fantasies, and likewise transhumanism

1281
01:07:46.449 --> 01:07:49.090
has become key to the AI industry and, and

1282
01:07:49.090 --> 01:07:51.520
the kind of the moral underpinning of, of what

1283
01:07:51.520 --> 01:07:55.429
they're doing, including risking. Um, YOU know, potentially causing

1284
01:07:55.429 --> 01:07:56.709
existential risks for humanity.

1285
01:07:58.070 --> 01:08:02.090
There is also the term posthumanism. Is it the

1286
01:08:02.090 --> 01:08:06.409
same as transhumanism? And if not, what does it

1287
01:08:06.409 --> 01:08:09.570
mean and what would be the differences here?

1288
01:08:10.379 --> 01:08:15.030
Um, YEAH, OK, good question. So, so, um, posthumanism

1289
01:08:15.030 --> 01:08:18.350
is, it's what comes after humanism. So it is,

1290
01:08:18.390 --> 01:08:23.200
it's the rejection of certain enlightenment humanist assumptions, essentially.

1291
01:08:23.390 --> 01:08:26.029
So unlike transhumanism, which is really about the human

1292
01:08:26.029 --> 01:08:29.700
becoming something else, posthumanism is is about humanism, not,

1293
01:08:29.709 --> 01:08:31.270
not the human, if you see what I mean.

1294
01:08:31.629 --> 01:08:33.830
So, um, they, they do have certain things in

1295
01:08:33.830 --> 01:08:38.029
common, so posthumanists agree with transhumanists that the human

1296
01:08:38.029 --> 01:08:42.830
condition is fundamentally changeable. Um, AND, and both posthumanist

1297
01:08:42.830 --> 01:08:45.660
and transhumanists are very interested in this process of

1298
01:08:45.660 --> 01:08:50.750
technogenesis, this dynamic co-evolution of technological and human development.

1299
01:08:51.120 --> 01:08:55.399
Um, BUT posthumanists undermine the Enlightenment notion of the

1300
01:08:55.399 --> 01:08:58.680
human. So, so they, they, you know, don't accept

1301
01:08:58.680 --> 01:09:02.350
the idea that we're all individuals, separate from nature,

1302
01:09:02.520 --> 01:09:06.000
with a glistening and powerful rationality that places us

1303
01:09:06.000 --> 01:09:09.859
hierarchy. ABOVE the rest of nature. Um, Rather, they

1304
01:09:09.859 --> 01:09:12.609
argue, um, that that is a, is a construct,

1305
01:09:12.620 --> 01:09:16.439
essentially, it's a, you know, a historically contingent construct,

1306
01:09:16.500 --> 01:09:18.180
uh, uh, so it's not what the human is,

1307
01:09:18.339 --> 01:09:20.859
it's what we imagined it to be, um, through

1308
01:09:20.859 --> 01:09:24.740
Enlightenment humanism. Instead, they would say what humans actually

1309
01:09:24.740 --> 01:09:28.939
are, uh, is inextricably embedded in the natural world

1310
01:09:28.939 --> 01:09:32.379
around them. Uh WE'RE defined by our relationality, we

1311
01:09:32.379 --> 01:09:34.430
can't escape it, so we are just part of

1312
01:09:34.580 --> 01:09:37.169
the web of nature, if you like. Um, SO

1313
01:09:37.169 --> 01:09:40.810
posthumanism for that reason, aims to think ethically beyond

1314
01:09:40.810 --> 01:09:45.290
the human. So they, they emphasize responsibility towards the

1315
01:09:45.290 --> 01:09:47.919
wider nature of which we're just a part. So,

1316
01:09:48.009 --> 01:09:51.330
um, Rosie Briotti, who's a a famous posthumanist thinker,

1317
01:09:51.419 --> 01:09:54.049
she sees, she says that we are bonded by

1318
01:09:54.049 --> 01:09:58.850
the compassionate acknowledgement of our interdependence with multiple human

1319
01:09:58.850 --> 01:10:01.640
and non-human others. So it's, it's very much a

1320
01:10:01.640 --> 01:10:06.589
relational, compassionate kind of um ideology. So whereas transhumanism,

1321
01:10:06.720 --> 01:10:08.479
you know, maybe you could characterize that as a

1322
01:10:08.479 --> 01:10:12.399
will to power, control, domination, even colonization of the,

1323
01:10:12.410 --> 01:10:15.080
of the human and space, the escape of all

1324
01:10:15.080 --> 01:10:19.720
earthly limits. Posthumanism emphasizes our embeddedness in nature, it

1325
01:10:19.720 --> 01:10:22.919
emphasizes compassion and that we look beyond ourselves. It's

1326
01:10:22.919 --> 01:10:25.850
a kind of ecological thinking, not just in the

1327
01:10:25.850 --> 01:10:28.540
environmental sense, but also in, in, in terms of

1328
01:10:28.540 --> 01:10:32.919
the intraconnection of all things. It therefore embraces complexity

1329
01:10:32.919 --> 01:10:36.439
theory, complexity science. And calls for humility, uh, because

1330
01:10:36.439 --> 01:10:38.890
we cannot possibly understand all that, that there is.

1331
01:10:39.000 --> 01:10:42.640
Complexity science tells us to understand anything completely, we'd

1332
01:10:42.640 --> 01:10:45.149
have to understand absolutely everything else, and that was

1333
01:10:45.149 --> 01:10:48.040
obviously impossible. So, so it embraces a kind of

1334
01:10:48.040 --> 01:10:52.080
humility, the limitation of human reason. Whereas transhumanism tries

1335
01:10:52.080 --> 01:10:55.160
to limit complexity and make life tractable to human

1336
01:10:55.160 --> 01:10:58.020
will, so it's fundamentally hubristic, you know, it's they're,

1337
01:10:58.160 --> 01:11:00.120
they're kind of opposites in that regard. Which is

1338
01:11:00.120 --> 01:11:02.560
why, again, when we talked about political polls, there's

1339
01:11:02.560 --> 01:11:06.910
this claim. That you could see posthumanism and transhumanism

1340
01:11:06.910 --> 01:11:10.939
as kind of um uh transhumanism as up, posthumanism

1341
01:11:10.939 --> 01:11:14.180
is down, political polls uh against each other in,

1342
01:11:14.220 --> 01:11:16.509
in this new um political imaginary, essentially.

1343
01:11:17.779 --> 01:11:22.339
Can there also be religious undertones to transhumanism? I

1344
01:11:22.339 --> 01:11:25.649
mean, obviously earlier when I asked you about AGI

1345
01:11:25.890 --> 01:11:29.379
you mentioned that some people in among the transhumanists

1346
01:11:29.620 --> 01:11:32.290
even think about it or talk about it as

1347
01:11:32.290 --> 01:11:37.850
gods, so that's already pointing to religious undertones there,

1348
01:11:37.979 --> 01:11:43.459
but more generally can transhumanism be a religious movement

1349
01:11:43.459 --> 01:11:44.220
in any way?

1350
01:11:44.729 --> 01:11:47.649
Yeah, I mean, absolutely. So I think there are

1351
01:11:47.649 --> 01:11:49.609
many dimensions to this. I mean, one thing I've,

1352
01:11:49.729 --> 01:11:51.290
I've already mentioned, I think is that there are

1353
01:11:51.290 --> 01:11:54.859
actually religious transhumanist organizations, so that's one thing, you

1354
01:11:54.859 --> 01:11:58.649
know, there is the Christian Transhumanist Association, etc. um

1355
01:11:58.649 --> 01:12:01.729
BUT I think more importantly, transhumanism, it can be

1356
01:12:01.729 --> 01:12:04.580
seen as as a kind of secular religion. Um,

1357
01:12:04.649 --> 01:12:07.120
IT promises in many ways the same things that

1358
01:12:07.120 --> 01:12:10.290
traditional religions have, but, but, you know, it's grounded

1359
01:12:10.290 --> 01:12:15.100
in secular science. Um, SO the most transcendent versions

1360
01:12:15.100 --> 01:12:18.459
of transhumanism, where, you know, consciousness or maybe just

1361
01:12:18.459 --> 01:12:21.370
intelligence kind of leaves the body and exists in

1362
01:12:21.370 --> 01:12:24.660
some kind of virtual manifestation, that's just an updated

1363
01:12:24.660 --> 01:12:26.859
version of the soul, right? I mean, that's, that's

1364
01:12:26.859 --> 01:12:29.839
what it is, um. Uh, YOU know, I, I,

1365
01:12:29.910 --> 01:12:31.709
I think, uh, there's two thinkers that have written

1366
01:12:31.709 --> 01:12:34.109
quite well on this in particular, Beth Singler and

1367
01:12:34.109 --> 01:12:36.709
Megan O'Gieblin. I think, I'm not sure I'm pronouncing

1368
01:12:36.709 --> 01:12:38.189
that right, but those two have written a lot

1369
01:12:38.189 --> 01:12:41.870
about AI and and transhumanism and its links to

1370
01:12:41.870 --> 01:12:44.770
religion. Um, AND, and, you know, I think, um,

1371
01:12:44.779 --> 01:12:48.529
Megan points out the great irony is that science

1372
01:12:48.529 --> 01:12:52.339
is it's supposed to replace religious fantasy during the

1373
01:12:52.339 --> 01:12:56.180
Enlightenment. Um, AND this is what transhumanism celebrates, but

1374
01:12:56.180 --> 01:12:59.459
transhumanism then comes along and restores these fantasies and

1375
01:12:59.459 --> 01:13:02.259
calls it science, right? So, um, you know, it

1376
01:13:02.259 --> 01:13:05.129
can't make these promises without slipping back into those

1377
01:13:05.129 --> 01:13:07.899
religious myths, uh, from which science was supposed to

1378
01:13:07.899 --> 01:13:11.819
liberate us. Um, Beth Singler also draws attention to

1379
01:13:11.819 --> 01:13:15.359
kind of, uh, patterns of religiosity, especially in AI

1380
01:13:15.359 --> 01:13:18.750
discourse. She, she points out, for example, the singularity

1381
01:13:19.040 --> 01:13:22.149
is, is a godlike, uh, kind of infinite knowledge,

1382
01:13:22.319 --> 01:13:24.200
you know, so it's like, uh, the oracle, it's,

1383
01:13:24.279 --> 01:13:27.870
it's godlike. Um, AND also it's coming about is

1384
01:13:27.870 --> 01:13:30.589
sometimes seen as the rapture or the end of

1385
01:13:30.589 --> 01:13:32.770
days. There's an apocalyptic element to it as well,

1386
01:13:32.850 --> 01:13:36.759
you know, it, it's an existential, existentially risky thing,

1387
01:13:36.850 --> 01:13:39.649
so we're all going to be judged by it,

1388
01:13:40.009 --> 01:13:42.899
essentially. Um MIND uploading, of course, is can be

1389
01:13:42.899 --> 01:13:45.345
seen as escaping the flesh. Of the mortal world.

1390
01:13:45.575 --> 01:13:49.455
Um, uh, Bessinger also points out Rocco's basilisk. I

1391
01:13:49.455 --> 01:13:50.615
don't know if you know that, that kind of

1392
01:13:50.615 --> 01:13:53.015
thought experiment, but it's, it's an updated version of

1393
01:13:53.015 --> 01:13:57.575
Pascal's wager, essentially. So AI threatens eternal damnation for

1394
01:13:57.575 --> 01:14:01.375
non-believers, as well as heavenly promises of, of immortality

1395
01:14:01.375 --> 01:14:04.930
for, you know, it's apostles, etc. um. You've also

1396
01:14:04.930 --> 01:14:07.220
got profits in the form of people like Kurzweil

1397
01:14:07.220 --> 01:14:09.529
and Altmann and Musk, although Musk has got to

1398
01:14:09.529 --> 01:14:12.299
be the most bizarre profit there's ever been. But,

1399
01:14:12.410 --> 01:14:14.950
but, you know, uh, what Kurtzweil promises in particular

1400
01:14:14.950 --> 01:14:18.520
is a kind of a technological and universal heaven.

1401
01:14:18.729 --> 01:14:20.290
You know, by the end of this century, he

1402
01:14:20.290 --> 01:14:23.689
thinks that human consciousness will essentially be bodyless and

1403
01:14:23.689 --> 01:14:25.770
we'll be able to travel around the universe taking

1404
01:14:25.770 --> 01:14:28.959
on. Uh, ANY physical manifestations in the form of,

1405
01:14:28.970 --> 01:14:32.859
of nanobot swarms. So effectively he, he's using religious

1406
01:14:32.859 --> 01:14:36.540
fantasy as a kind of rhetorical device, um, promising

1407
01:14:36.540 --> 01:14:40.189
the spiritual and and material benefits of religious salvation,

1408
01:14:40.339 --> 01:14:43.529
but in a transhumanist discourse, you know, which again

1409
01:14:43.529 --> 01:14:47.100
is it has that irony of um uh retreating

1410
01:14:47.100 --> 01:14:49.259
back into the religious myth that science is supposed

1411
01:14:49.259 --> 01:14:51.700
to free us from. So yeah, I think that's

1412
01:14:52.100 --> 01:14:53.459
some of the things we can say about religion.

1413
01:14:54.660 --> 01:14:57.979
Do you think that the transhumanism can lead to

1414
01:14:57.979 --> 01:15:02.459
dehumanization? If so, what kind of dehumanization would we

1415
01:15:02.459 --> 01:15:07.060
be talking about here and what does dehumanization mean

1416
01:15:07.060 --> 01:15:08.870
in this particular context?

1417
01:15:09.990 --> 01:15:14.439
Um, YEAH, OK, so, as I've mentioned, transhumanists tend

1418
01:15:14.439 --> 01:15:18.350
to have a kind of narrow conception of intelligence.

1419
01:15:18.479 --> 01:15:21.049
Um, SO they see it as the ability to

1420
01:15:21.049 --> 01:15:24.049
solve complex goals. And when you frame it that

1421
01:15:24.049 --> 01:15:28.089
way, it avoids questions of context, questions of meaning

1422
01:15:28.089 --> 01:15:31.160
and purpose of life, it avoids deeper ethical questions

1423
01:15:31.160 --> 01:15:33.250
about our relations with each other and the rest

1424
01:15:33.250 --> 01:15:35.609
of nature, you know, which can be seen to

1425
01:15:35.609 --> 01:15:39.129
have um dimensions of emotional intelligence or whatever else

1426
01:15:39.129 --> 01:15:41.689
linked to them, which we just exclude from, from

1427
01:15:41.689 --> 01:15:46.459
these questions. um. So that narrow vision, what it

1428
01:15:46.459 --> 01:15:50.810
enables is a very quantifying and kind of hierarchical

1429
01:15:51.100 --> 01:15:54.779
notion of intelligence, um, uh, you know, and, and

1430
01:15:54.779 --> 01:15:59.009
therefore humans are, are also hierarchically graded, uh, based

1431
01:15:59.009 --> 01:16:02.479
on their intelligence, so for example. Um, AND, and,

1432
01:16:02.490 --> 01:16:05.169
you know, as I've mentioned, many transhumanists, they often

1433
01:16:05.169 --> 01:16:08.220
point out that AI will soon automate most jobs

1434
01:16:08.220 --> 01:16:11.950
away, um, leaving no purpose for most humans, uh,

1435
01:16:12.009 --> 01:16:14.750
uh, certainly those that don't own the machines, um,

1436
01:16:14.810 --> 01:16:17.529
which will of course replace them. Um, AND with

1437
01:16:17.529 --> 01:16:19.490
our lack of intelligence, we won't be able to

1438
01:16:19.490 --> 01:16:21.810
compete. So they ask, well, what do we do

1439
01:16:21.810 --> 01:16:24.169
with the, with the people in, in this context?

1440
01:16:24.319 --> 01:16:29.169
And um, Elise Bohan, who's another transhumanist, she argues

1441
01:16:29.169 --> 01:16:31.569
that, you know, things like universal basic income are

1442
01:16:31.569 --> 01:16:34.870
not acceptable because, as she points out, almost half

1443
01:16:34.870 --> 01:16:37.649
the human population has an IQ below 100, so

1444
01:16:37.649 --> 01:16:39.569
she says, you know, they just can't be trusted

1445
01:16:39.569 --> 01:16:41.330
to decide what to do with their own lives.

1446
01:16:41.850 --> 01:16:44.339
So, so her solution for this problem is not,

1447
01:16:44.580 --> 01:16:47.580
it's not wealth redistribution, it's not universal public services,

1448
01:16:47.620 --> 01:16:50.180
it's not that fully automated luxury communism, none of

1449
01:16:50.180 --> 01:16:53.419
that. Instead, it's, it's an updated version of the

1450
01:16:53.419 --> 01:16:56.660
happiness producing drug from Brave New World, Soma. So

1451
01:16:56.660 --> 01:16:59.209
we end up back with the Huxleys actually. Um,

1452
01:16:59.339 --> 01:17:01.814
SO she stays. THAT kind of, uh, she says

1453
01:17:01.814 --> 01:17:05.455
that low status, low skilled, low IQ and unemployed

1454
01:17:05.455 --> 01:17:08.455
people have the weakest buy-in for reality, so we

1455
01:17:08.455 --> 01:17:11.995
need better drugs and better virtual worlds. So, um,

1456
01:17:12.015 --> 01:17:14.194
you know, essentially she's arguing that in the 21st

1457
01:17:14.194 --> 01:17:16.615
century it would be necessary for humans to spend

1458
01:17:16.615 --> 01:17:19.149
more time in virtual reality. And, and actually this

1459
01:17:19.149 --> 01:17:22.149
is an exact copy of uh the neo reactionary

1460
01:17:22.149 --> 01:17:25.549
thinker Curtis Yarvin. Uh HE states that virtualizing the

1461
01:17:25.549 --> 01:17:29.459
masses is mildly preferable to the profit maximizing solution

1462
01:17:29.459 --> 01:17:33.430
of converting them all into biodiesel. So, so in

1463
01:17:33.430 --> 01:17:35.709
transhumanism, there's, there's these questions of what do we

1464
01:17:35.709 --> 01:17:37.790
do with humans that no longer have much purpose

1465
01:17:37.790 --> 01:17:40.870
for us essentially. Um, AND, and, you know, as

1466
01:17:40.870 --> 01:17:43.790
a result, you can argue that transhumanism can be

1467
01:17:43.790 --> 01:17:47.149
seen to have a concerning proximity to necropoli politics,

1468
01:17:47.189 --> 01:17:50.750
the indifference to death and dying of those structured

1469
01:17:50.750 --> 01:17:54.040
outside of the technocapitalist bubble of progress. And in

1470
01:17:54.040 --> 01:17:56.600
fact, the the the transhumanist thinker Steve Fuller, who

1471
01:17:56.600 --> 01:17:59.839
I mentioned earlier, he calls for the construction of

1472
01:17:59.839 --> 01:18:03.240
a new republic of humanity, he calls it. And

1473
01:18:03.240 --> 01:18:07.430
um that would be exclusively for entities that should

1474
01:18:07.430 --> 01:18:10.560
be regarded as having political rights. And for Fuller,

1475
01:18:10.640 --> 01:18:13.470
humans can be in this, but so can animals

1476
01:18:13.470 --> 01:18:15.560
and so can machines. All of them can gain

1477
01:18:15.560 --> 01:18:19.209
entry and all of them can be expelled. And

1478
01:18:19.209 --> 01:18:20.970
what he states is that it's it's, it's your

1479
01:18:20.970 --> 01:18:25.839
capacity for for self assertion against a countervailing force

1480
01:18:25.839 --> 01:18:28.290
um that marks you as worthy for rights. You

1481
01:18:28.290 --> 01:18:30.879
don't simply capitulate or adapt, you leave your mark.

1482
01:18:31.250 --> 01:18:33.490
So for him, any entity that fails to leave

1483
01:18:33.490 --> 01:18:36.330
its mark um should become susceptible to what he

1484
01:18:36.330 --> 01:18:40.290
calls necronomics, um, and economics of death making, which

1485
01:18:40.290 --> 01:18:43.330
aims to generate the most societal value from death

1486
01:18:43.330 --> 01:18:45.479
making. Um, SO in other words, if you are

1487
01:18:45.479 --> 01:18:48.600
not at the top of the technohuman hierarchy in

1488
01:18:48.600 --> 01:18:51.359
control of our kind of future human evolution or

1489
01:18:51.359 --> 01:18:54.220
posthuman evolution, you have no right to an existence

1490
01:18:54.220 --> 01:18:56.600
at all. You compete or die. And so it's

1491
01:18:56.600 --> 01:19:00.279
a radicalization of the expulsions and concentrations that we've

1492
01:19:00.279 --> 01:19:03.399
seen are inherent to capitalist logics, you know, um.

1493
01:19:04.080 --> 01:19:07.419
And you know, some transhumanists acknowledge the, the many

1494
01:19:07.419 --> 01:19:10.339
crises of our times and um but they always

1495
01:19:10.339 --> 01:19:14.229
tend to locate the failings in human biology instead

1496
01:19:14.229 --> 01:19:19.100
of structural, social injustice, frankly. So, um again, Elise

1497
01:19:19.100 --> 01:19:22.140
Bohan calls us eight-brained meat sacks, and you know,

1498
01:19:22.220 --> 01:19:24.169
we're, we're ill fitted to the modern world, in

1499
01:19:24.169 --> 01:19:27.160
other words. Um, SO, you know, the, these ideas,

1500
01:19:27.560 --> 01:19:31.439
this doesn't feel like a kind of participatory, democratic,

1501
01:19:31.479 --> 01:19:35.899
inclusive, pluralistic project, because most of us are considered

1502
01:19:35.899 --> 01:19:37.839
just too stupid to be trusted with the human

1503
01:19:37.839 --> 01:19:40.359
future. Instead, it's a kind of like a hyper

1504
01:19:40.359 --> 01:19:44.720
rationalist ordering, uh, with techno solutionism, kind of IQ

1505
01:19:44.720 --> 01:19:47.560
fetishism, uh, and, and, you know, as we've mentioned

1506
01:19:47.560 --> 01:19:51.120
a a problematic eugenics essentially kind of those logics

1507
01:19:51.120 --> 01:19:53.660
are baked into this. Um, SO, you know, I

1508
01:19:53.660 --> 01:19:56.819
think transhumanism, it, it, it too often it, it

1509
01:19:56.819 --> 01:20:00.819
functions as a kind of, uh, a disorienting discourse.

1510
01:20:00.870 --> 01:20:04.240
It, it stops us thinking ethically. It celebrates the,

1511
01:20:04.259 --> 01:20:07.180
the amassing of, of knowledge and power, um, but

1512
01:20:07.180 --> 01:20:10.129
doesn't enable us to think hard about what, what

1513
01:20:10.129 --> 01:20:14.430
the techno human evolutionary implications are. Um, IT, it

1514
01:20:14.430 --> 01:20:17.149
kind of, yeah, it tends towards the abstracted, uh,

1515
01:20:17.160 --> 01:20:21.060
the utopian and the hyperbolic, you know, um, uh,

1516
01:20:21.149 --> 01:20:24.109
but it relies on things like super intelligence to

1517
01:20:24.109 --> 01:20:27.750
kind of realize ethical outcomes or, or a benevolent

1518
01:20:27.750 --> 01:20:29.910
form of, of eugenics, as Elise Bohane would put

1519
01:20:29.910 --> 01:20:33.080
it. Um, SO it constantly displays this false belief

1520
01:20:33.080 --> 01:20:37.419
that, again, I've spoken of earlier, that scientific progress

1521
01:20:37.950 --> 01:20:40.740
necessarily leads to ethical progress. And er you know,

1522
01:20:40.819 --> 01:20:43.859
it's that failing that opens transhumanist aims to charges

1523
01:20:43.859 --> 01:20:47.180
of, I think, dehumanization. The failure to ensure an

1524
01:20:47.180 --> 01:20:50.930
inclusive future for for humans and non-humans who share

1525
01:20:50.930 --> 01:20:51.459
this planet.

1526
01:20:53.540 --> 01:20:57.819
Finally, then, uh, how should we as a society

1527
01:20:57.819 --> 01:21:00.500
deal with all of this? I mean, what can

1528
01:21:00.500 --> 01:21:03.660
we do with all this information about transhumanism and

1529
01:21:03.660 --> 01:21:07.089
the other related movements and how should we approach

1530
01:21:07.339 --> 01:21:11.049
ethically a potential transhuman future?

1531
01:21:12.439 --> 01:21:15.089
Um, YEAH, I mean, that, that question is huge.

1532
01:21:15.180 --> 01:21:17.540
I think it's, it's probably too, too big to

1533
01:21:17.540 --> 01:21:19.580
deal with at the end of like, um, uh,

1534
01:21:19.660 --> 01:21:21.490
you know, uh, an hour and a bit podcast.

1535
01:21:21.500 --> 01:21:24.160
But, um, to even begin, I think, to do

1536
01:21:24.160 --> 01:21:26.180
justice to that, we probably need another, another couple

1537
01:21:26.180 --> 01:21:28.419
of hours. But, but I think, um, in the

1538
01:21:28.419 --> 01:21:30.339
short term, you know, what we absolutely need is,

1539
01:21:30.379 --> 01:21:34.020
is, uh, global resistance to tech authoritarianism and all

1540
01:21:34.020 --> 01:21:36.700
forms of fascism, and a rejection of, of this

1541
01:21:36.700 --> 01:21:40.950
kind of um. Uh, ESSENTIALIST concept of, of human

1542
01:21:40.950 --> 01:21:44.629
hierarchy and um the rejection of the, uh, the

1543
01:21:44.629 --> 01:21:48.250
worth of all of, of all people. Um. In,

1544
01:21:48.259 --> 01:21:50.149
in my book, I, I develop a kind of

1545
01:21:50.149 --> 01:21:53.379
meta-ethical framework for the future, which I call virtual

1546
01:21:53.379 --> 01:21:56.580
relational anthropoporea. But that's a probably a story for

1547
01:21:56.580 --> 01:21:58.459
a different day. It's a bit, bit much to

1548
01:21:58.459 --> 01:22:00.890
unpack right now. But the book is open access,

1549
01:22:00.899 --> 01:22:02.899
and it's free to download or read online for

1550
01:22:02.899 --> 01:22:04.979
anyone who might be interested, so they can go

1551
01:22:04.979 --> 01:22:07.140
and check it out there. But essentially, you know,

1552
01:22:07.379 --> 01:22:09.890
it, what it does is it calls for systemic

1553
01:22:09.890 --> 01:22:14.660
alternatives to kind of technocapitalism. Aimed at doing uh

1554
01:22:14.660 --> 01:22:19.160
less harm primarily, um, and more cautiously and lightly

1555
01:22:19.160 --> 01:22:23.220
directing, uh, kind of our capacities, with a focus

1556
01:22:23.220 --> 01:22:26.100
on leaving space for pluralistic ways of, of both

1557
01:22:26.100 --> 01:22:29.129
human and non-human being. So that is not an,

1558
01:22:29.250 --> 01:22:32.140
uh, an outright rejection of technological development in all

1559
01:22:32.140 --> 01:22:34.299
its forms. I'm not calling for attempting to halt

1560
01:22:34.299 --> 01:22:37.009
technohuman evolution. Um, I, you know, as I've said,

1561
01:22:37.069 --> 01:22:39.589
I think we've always evolved alongside our technologies and,

1562
01:22:39.629 --> 01:22:42.580
and we'll obviously continue to do that. But we

1563
01:22:42.580 --> 01:22:45.390
do need a reassertion of values. Um, SO I

1564
01:22:45.390 --> 01:22:48.899
think philosophy, the humanities, and the arts, as well

1565
01:22:48.899 --> 01:22:52.149
as kind of non-Western perspectives of human meaning, need

1566
01:22:52.149 --> 01:22:54.120
to play a much more pivotal role, I think,

1567
01:22:54.129 --> 01:22:56.750
in our culture. Um, WHICH would allow us to,

1568
01:22:56.870 --> 01:22:59.189
to challenge the, the kind of the dominance, the

1569
01:22:59.189 --> 01:23:02.549
pervasive power, and the corrupting force of the drive

1570
01:23:02.549 --> 01:23:05.870
of a few Silicon Valley billionaires to accumulate endless

1571
01:23:05.870 --> 01:23:09.350
capital and, and to essentially escape with the spoils

1572
01:23:09.350 --> 01:23:13.620
of this technological development, uh, whilst rejecting responsibility for

1573
01:23:13.620 --> 01:23:16.229
the, the kind of social and environmental wreckage that

1574
01:23:16.229 --> 01:23:19.060
they're leaving behind. So, so that's what I think

1575
01:23:19.060 --> 01:23:21.060
we need to think about. Big challenge for, for,

1576
01:23:21.140 --> 01:23:22.910
for us, and, and I think it should be

1577
01:23:22.910 --> 01:23:26.520
the starting point of any serious transhumanist kind of

1578
01:23:26.520 --> 01:23:28.939
um thought really, but it obviously isn't.

1579
01:23:30.689 --> 01:23:33.069
Yes, let's end on that note, and for people

1580
01:23:33.069 --> 01:23:35.279
who would like to learn more about your meta

1581
01:23:35.279 --> 01:23:37.709
ethical approach that you live at the end of

1582
01:23:37.709 --> 01:23:41.029
the book, they can read it on, or they

1583
01:23:41.029 --> 01:23:43.629
can search for it online and it's again the

1584
01:23:43.629 --> 01:23:47.310
politics and ethics of transhumanism, techno human evolution, and

1585
01:23:47.310 --> 01:23:50.470
advanced capitalism. I'm leaving a link to it in

1586
01:23:50.470 --> 01:23:53.990
the description of the interview and Doctor Thomas, apart

1587
01:23:53.990 --> 01:23:56.470
from the book, would you like to tell people

1588
01:23:56.470 --> 01:23:59.180
where they can find your work on the internet?

1589
01:23:59.569 --> 01:24:03.299
Yeah, sure. So, um, I'm on Blue Sky, um,

1590
01:24:03.399 --> 01:24:08.299
uh, uh, also I've got a website, Posthuman Futures.com.

1591
01:24:08.629 --> 01:24:10.589
And, uh, I've actually got my own podcast that

1592
01:24:10.589 --> 01:24:12.589
I, I, I'm, I'm nowhere near as, uh, as

1593
01:24:12.589 --> 01:24:14.709
regular as you, I'm afraid, Ricardo, nowhere near as

1594
01:24:14.709 --> 01:24:17.029
prolific, but there's a, a little podcast called the

1595
01:24:17.029 --> 01:24:18.310
A to Z of the Future, which has a

1596
01:24:18.310 --> 01:24:20.990
little series on the Anthropocene, a little series on

1597
01:24:20.990 --> 01:24:23.450
transhumanism where I interview a lot of the, the,

1598
01:24:23.459 --> 01:24:25.990
uh, the, the transhumanists I've mentioned today, uh, so

1599
01:24:25.990 --> 01:24:28.410
you can check out that as well. And I'm,

1600
01:24:28.529 --> 01:24:30.089
yeah, that that's good.

1601
01:24:31.109 --> 01:24:33.689
Great. So thank you so much for taking the

1602
01:24:33.689 --> 01:24:35.470
time to come on the show. It's been a

1603
01:24:35.470 --> 01:24:38.790
very fun and informative conversation. Thank you. Thanks

1604
01:24:38.790 --> 01:24:40.339
a lot, Ricardo. Take care. Cheers.

1605
01:24:41.629 --> 01:24:44.149
Hi guys, thank you for watching this interview until

1606
01:24:44.149 --> 01:24:46.279
the end. If you liked it, please share it,

1607
01:24:46.470 --> 01:24:49.259
leave a like and hit the subscription button. The

1608
01:24:49.259 --> 01:24:51.459
show is brought to you by Nights Learning and

1609
01:24:51.459 --> 01:24:55.540
Development done differently, check their website at Nights.com and

1610
01:24:55.540 --> 01:24:59.259
also please consider supporting the show on Patreon or

1611
01:24:59.259 --> 01:25:01.740
PayPal. I would also like to give a huge

1612
01:25:01.740 --> 01:25:05.169
thank you to my main patrons and PayPal supporters

1613
01:25:05.169 --> 01:25:09.069
Pergo Larsson, Jerry Mullerns, Frederick Sundo, Bernard Seyche Olaf,

1614
01:25:09.180 --> 01:25:12.430
Alex Adam Castle, Matthew Whitting Barno, Wolf, Tim Hollis,

1615
01:25:12.520 --> 01:25:15.850
Erika Lenny, John Connors, Philip Fors Connolly. Then the

1616
01:25:15.850 --> 01:25:19.649
Mater Robert Windegaruyasi Zu Mark Nes calling in Holbrookfield

1617
01:25:19.649 --> 01:25:24.439
governor Michael Stormir Samuel Andrea, Francis Forti Agnsergoro and

1618
01:25:24.439 --> 01:25:27.890
Hal Herzognun Macha Jonathan Labrant John Jasent and the

1619
01:25:27.890 --> 01:25:32.009
Samuel Corriere, Heinz, Mark Smith, Jore, Tom Hummel, Sardus

1620
01:25:32.009 --> 01:25:35.609
Fran David Sloan Wilson, Asila dearraujoro and Roach Diego

1621
01:25:35.609 --> 01:25:42.439
Londonorea. Yannick Punteran Rosmani Charlotte blinikol Barbara Adamhn Pavlostaevskynalebaa

1622
01:25:42.439 --> 01:25:46.990
medicine, Gary Galman Samov Zaledrianei Poltonin John Barboza, Julian

1623
01:25:46.990 --> 01:25:51.640
Price, Edward Hall Edin Bronner, Douglas Fry, Franca Bartolotti

1624
01:25:51.640 --> 01:25:56.439
Gabrielon Scorteus Slelitsky, Scott Zachary Fish Tim Duffyani Smith

1625
01:25:56.439 --> 01:26:01.100
John Wieman. Daniel Friedman, William Buckner, Paul Georgianneau, Luke

1626
01:26:01.100 --> 01:26:05.879
Lovai Giorgio Theophanous, Chris Williamson, Peter Vozin, David Williams,

1627
01:26:06.000 --> 01:26:10.069
the Acosta, Anton Eriksson, Charles Murray, Alex Shaw, Marie

1628
01:26:10.069 --> 01:26:14.370
Martinez, Coralli Chevalier, bungalow atheists, Larry D. Lee Junior,

1629
01:26:14.560 --> 01:26:19.200
Old Heringbo. Sterry Michael Bailey, then Sperber, Robert Gray,

1630
01:26:19.299 --> 01:26:23.839
Zigoren, Jeff McMann, Jake Zu, Barnabas radix, Mark Campbell,

1631
01:26:24.000 --> 01:26:28.359
Thomas Dovner, Luke Neeson, Chris Storry, Kimberly Johnson, Benjamin

1632
01:26:28.359 --> 01:26:33.120
Galbert, Jessica Nowicki, Linda Brandon, Nicholas Carlsson, Ismael Bensleyman.

1633
01:26:33.750 --> 01:26:38.879
George Eoriatis, Valentin Steinman, Perrolis, Kate van Goller, Alexander

1634
01:26:38.879 --> 01:26:45.600
Aubert, Liam Dunaway, BR Masoud Ali Mohammadi, Perpendicular John

1635
01:26:45.600 --> 01:26:51.029
Nertner, Ursulauddinov, Gregory Hastings, David Pinsoff Sean Nelson, Mike

1636
01:26:51.029 --> 01:26:54.694
Levin, and Jos Net. A special thanks to my

1637
01:26:54.694 --> 01:26:57.535
producers. These are Webb, Jim, Frank Lucas Steffinik, Tom

1638
01:26:57.535 --> 01:27:02.415
Venneden, Bernardin Curtis Dixon, Benedict Muller, Thomas Trumbo, Catherine

1639
01:27:02.415 --> 01:27:05.694
and Patrick Tobin, Gian Carlo Montenegroal N Cortiz and

1640
01:27:05.694 --> 01:27:09.055
Nick Golden, and to my executive producers Matthew Levender,

1641
01:27:09.134 --> 01:27:12.294
Sergio Quadrian, Bogdan Kanivets, and Rosie. Thank you for

1642
01:27:12.294 --> 01:27:12.645
all.

