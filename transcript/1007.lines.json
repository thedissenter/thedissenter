[
	{
		"start_time": "00:00",
		"speaker": "Ricardo Lopes",
		"words": "Hello, everybody. Welcome to a new episode of the Center. I'm your host as always Ricard Lobs. And today I'm joined by Doctor Brian Talbot. He is assistant professor at the University of Colorado Boulder. He is the author of the End of Epistemology as we know it. So, Doctor Talbot, welcome to the show. It's a pleasure to everyone. Thank you. It's great to be here. So, tell us first what's behind uh this book, I mean, what motivated you to write the book and what's basically the main premise here? I mean, what do you mean exactly by the end of Epistemology as we know it?"
	},
	{
		"start_time": "00:42",
		"speaker": "Brian Talbot",
		"words": "Uh I should say, you know, it's important, it's important to have catchy titles, but a title doesn't have to be strictly speaking. True to be a good title. So, um so the title, so Epistemology is like very roughly study of like, what we should and shouldn't believe and why, why we shouldn't, shouldn't believe it. Um Sort of what makes beliefs better or worse or like more or less rational. And um the, the title is sort of like kind of a pun play on words because uh in my opinion to determine like what we should and shouldn't be uh believe we need to in some sense, kind of think about what the, what our goals are. Um So what is the end, the, the, the thing at which we're aiming in some sense, uh when we believe? And so I think the book is an attempt to call into question a lot of um views and in contemporary and kind of historical standard epistemology sort of has been done for a long time. I want to call a lot of that into question, say we need to do things very differently in many ways. So at the end of epistemology, as we know in that sense, but also it's about trying to drive our thinking about what we shouldn't, shouldn't believe um by thinking about what we're trying to accomplish when we have beliefs. So it's, we're thinking about epistemology by thinking about what are our goals first and then deriving all the norms, all the rules um in a sense from that. Um And what, what I was thinking about, what motivated me to write this book. I mean, there's so many things and it takes so long to write a book. And even before you start writing, there's so much going on. So a lot to say, but uh when I first started thinking about this stuff, years and years and years ago, um so my research at the time was on like the epistemology of philosophy, like, how do we know roughly philosophical stuff? Like, what is it that makes our beliefs about philosophical questions reasonable? And that was a lot of what my work was on. But my teaching was really heavily about philosophy of law, political philosophy, um and ethics. So I was thinking a lot about um ethics and the law for my students. And I was thinking a lot about philosophical methodology and epistemology from my own research. And I was, uh you know, in the ethics and the law, there's a lot of thinking about uh the structure of reasons and the structure of norms and rules and what makes rules or norms better or worse. And people thought a lot about that stuff and I started applying some of that thinking from law and ethics to work in epistemology that was trying to explain what's so good about having uh reasonable beliefs. And I just sort of felt like what people were saying about um what makes belief reasonable and why is it important to be reasonable? What people were saying about that wasn't really matching up with what they thought reasonableness was or reasonable belief was or justified belief or knowledge. And there just seem to be this mismatch, especially when you start thinking about these things through the lens of law and, and, and ethics where they really, I think more a developed thought about um what makes norms or rules, good norms or rules. And so I started thinking there's just this mismatch and, um, what people, yeah, what people were saying we need to pursue the truth and that's what the, the, the, the norms epistemology is about. But then what they said the norms were, wasn't really well suited for the pursuit of the truth. Uh And so, um, there's a sort of a, a parable in the book that I got from my friend Daniel is a really nice, it's like a little story. So you imagine, you know, you run into somebody and you're talking to them and they say, oh, you know, you're talking about their interests and they say, oh, I really love books. Uh And I, and you say back, oh, you love books. What's your favorite book? And they say, oh, I don't, I don't have a favorite book. I love every book. Exactly the same as every other book. So I love, you know, Windows 95 for dummies, this outdated book on, on computer software. Exactly. As much as the brothers K Matzo, this great work of literature. And so you think this person doesn't really love books or they don't love books in the right way, or they don't love the right things about books. And I really felt like that's what you were seeing in, in epistemology. It was supposed to be about the pursuit of the truth, but the way the norms are structured and what you were allowed to do and what was reasonable to do wasn't always the stuff that was really aimed at pursuing the truth and especially not aimed at pursuing the important truths. Um And so I thought there's something wrong going, there's something going on wrong here. And I, that's why I started thinking about the material in the book"
	},
	{
		"start_time": "05:43",
		"speaker": "Ricardo Lopes",
		"words": "and when it comes to these norms or could you give us some examples of those epistemic norms? I mean, when it comes to, uh, I don't know, mainstream philosophy, is there a set of epistemic norms that most philosophers tend to follow or not? Yeah."
	},
	{
		"start_time": "06:05",
		"speaker": "Brian Talbot",
		"words": "Um So here's a very, here's probably the least controversial one. Don't contradict yourself. Mhm. So you don't believe two things that are contradictory, that's a very standard or you should, you know, you put, if you want to put it as a should, you shouldn't believe contradictory things. It's unreasonable to believe contradictory things that's in, I think pretty much close to universally accepted. Um If your evidence really clearly tells you that something is false, you shouldn't believe that that's a very widely held uh norm. Um More generally, people think that you should believe what your evidence tells you is true. Um It's fairly common, although not universal for people to think. Um, DON'T believe things you don't know, stuff like that. Um But the, don't contradict yourself, believe what your evidence tells. You don't believe what your evidence tells you is false kind of stuff. Those are very, very standard. Uh um Like the fact pretty close to pretty close to universally accepted norms in epistemology."
	},
	{
		"start_time": "07:12",
		"speaker": "Ricardo Lopes",
		"words": "But there's a very important question I think to tackle here. So why is it that we should even care about epistemic norms at all? I mean, why do they matter at all to begin with?"
	},
	{
		"start_time": "07:28",
		"speaker": "Brian Talbot",
		"words": "So, um not everybody agrees on this question. Uh I think everybody in epistemology. Well, yeah. So part of the structure of the book is to consider a range of different possible answers to that question. And to think about, you know, I, I all there's a bunch of answers to that question. I think all are, are relatively plausible to some extent. So here's an easy answer. Um, IF you have, if you be the better your beliefs are the more able you are to act well, right. If your, if your beliefs are totally disconnected from reality, you're not gonna be very successful in, in doing the things you wanna do. That's a, that's a pretty common view. So, um, epistemic norms are supposed to be like rules or, or, uh, standards for evaluating. Are you thinking? Well, uh And then if you conform to those, you're more likely to be able to act. Well, that's a pretty standard view, but I don't think it's all just about action and, and a lot of people, most people I think probably don't think it's all about action. There's things we're just curious about that. Don't have a lot of like practical significance. Um So here's a, so it's, it's hard to disentangle curiosity from practical significance, but here's one I really would like to know if there's intelligent life on other planets. Um, BUT I'm never gonna meet any of those. If there are, they are probably never going to meet them but not gonna have any impact on what I do, I suspect. But I would really like to know. So I'm like, that's the thing I'm genuinely curious about that. I don't have any think has any practical significance. So, um often we think to be curious is to want to know the answer to a question very roughly. So uh we're interested in the truth about things in a way that's not just practical. Um And um having good beliefs is the having normative beliefs, having reasonable beliefs is supposed to be the best way of getting to the truth. So that's a way in which it's supposed to matter. Um We need to socially coordinate ourselves with other people and to some extent that requires having coordinations what we believe, who we trust, who we don't trust, um about what topics and stuff like that. And so um norms, you can think of norms as rules that help us all kind of get on the same page in terms of how to form beliefs and who to trust. So they play that kind of role. Um So there's a bunch of different explanations for, um, why it matters, uh to have good beliefs or to have reasonable beliefs or to have justified beliefs. Um, YOU know, in terms of practical success, in terms of, you know, just getting the truth because we care about it in terms of social coordinations, stuff like that. And I think those are all very reasonable answers. Um And so I don't wanna say any one of them is the single correct answer. I think they're probably also all true to some extent. And so we need to think about given uh these different explanations for the importance of being reasonable or having good beliefs. What does it mean? What, what should it mean to be reasonable or have good beliefs?"
	},
	{
		"start_time": "10:42",
		"speaker": "Ricardo Lopes",
		"words": "But I think that there's perhaps a broader question here that might have some bearing on what you explore in the book. So, uh does the question of whether anything really matters at all also have any bearing here? Because I would imagine that, for example, if you were talking to a radical skeptic or a nihilist or someone along those lines, they would just say, look who cares if anything is true or not because, uh that doesn't even mean anything. I mean, something along those lines."
	},
	{
		"start_time": "11:18",
		"speaker": "Brian Talbot",
		"words": "Yeah. So this is, there's, there's a lot to say here, but I'm gonna, I'll, I'll, I'll, uh, I'm gonna skip a lot of it. Uh Maybe you, so maybe nothing really matters. That's a, that's an open possibility. Part of my approach to philosophy is to try to, um when you, when you write to only argue about the things you need to argue about. So, in the book, I'm like, hey, you know, some people think nothing really matters for a variety of different reasons and uh I'm not going to try to convince them otherwise. So I think here's the thing to say, even if nothing really matters in some sense of like, objectively, nothing really matters or, you know, uh, in some deep fundamental way, the universe doesn't care if we live or die, whatever. Um Even if that's true, which I'm not convinced by, um, things matter to us, I mean, very, I mean, the, the very limit things matter to me. Uh I suspect something matters to you. Uh, AND it does seem like things matter to us, at least to some significant extent. And so even if nothing really matters, things matter to us and what more could you want? I mean, well, you could want things to really matter. Uh, BUT if nothing can really matter, then there's nothing more to want than what matters to you. And then the question is, uh, I suspect, well, not a question but I suspect if something matters to you acting decently matters to you, achieving your goals matters to you. Most people are curious about some things, even if those things don't really matter, this curiosity matters to them and So they should, again, if there are norms or rules for belief or standards for evaluating belief that are good to conform to, in order to act, well, in order to satisfy your curiosity, we want, it matters to us that we know what those norms are, that we figure out what those norms are. So nothing needs to really matter as long as things matter to us. And I think it's un without a doubt, things matter to us."
	},
	{
		"start_time": "13:19",
		"speaker": "Ricardo Lopes",
		"words": "So, but as long as something mattered to us, we also have different sets of norms. So for example, in the book, you focus on epistemic norms, but we also have moral norms. So uh how do you think we should approach things here if there's, for example, a conflict between these two different sets of norms or even if it's not moral norms and the other kinds of norms that are not epistemic."
	},
	{
		"start_time": "13:50",
		"speaker": "Brian Talbot",
		"words": "Yeah. So this is the uh the notion of mattering is a, is a, is a, is a term I use throughout the book. And I partly chose that because it wasn't a term that another philosopher had already grasped on to and, and used it for themselves. So I wanted to use it for my own self. And part of what I, what I'm thinking about when I talk about norms, mattering is, is exactly this question of when two norms conflict from different kind of domains. When you know, it's you're curious about something but it would make you unhappy to know the answer. So I'm curious about whether or not there's intelligent life on another planet. But if I found out there was not, it would, I would be really bummed out. Um, SO there's a, I mean, and that's true, by the way I really wanted, I would still really be curious but it would really be sad to know the answer if the answer is no. Um So there's a conflict there between what I'm curious about in some sense was epidemically good. What epidemic, you know, I want to know the truth. But also uh what is good for me, we call prudential sometimes was. So there's a conflict in a prudential norm and we have this question, the prudential norms say, don't believe there are no aliens on other planets, no intelligent life, the maybe the epistemic norms, they do believe it because that's what my evidence tells me, let's say. So I have this conflict and there's, then I have this question. Well, what should I believe? Now? There's a really boring set of answers which is, well, prudentially, you should believe what prudence says and epidemically you should believe what the epistemic norms say. And there's nothing more to say and this is what people think. There's nothing really matters. That's kind of what they're trying to argue for is that there's nothing to say other than there's the prudent answer. And the epistemic answer, there's no more answers. And I just think, well, there's at least the answer with in this case, what's more important, what, what matters more to me is that the epistemic stuff or the prudential stuff? Uh And I think we can systematically think about that. Um And so in normative conflicts, you should follow the norm that matters more in that case. That's the kind of, that's the sort of schematic answer. Then the question is, well, what norm matters more in that case? And in order to think about that, we need to think really deeply about why norms matter. Um And so, um part of the goal of the book is to say, let's try to figure out why epistemic norms could matter because that will help us think about how much they do matter. Um And because if they don't matter at all, then every time it makes me feel sad to believe the truth, I should always ignore the truth because that would make me sad. And I would think that would be very surprising. Um So that doesn't really answer your question because I haven't told you whether you should ever believe the truth over being sad. You know, that even if it makes you sad. But I do think yes, but I don't actually answer that question in the book. Uh What I wanna do is say, let's think about how the epistemic norms could be genuinely, really important and what that would have to look like, but I don't try to argue that they're, that they are more important than other stuff in some cases. I think they almost definitely are. I think there are pretty clearly cases in which you should believe the truth, even though it's upsetting. Um, EVEN though even in some cases you should believe the truth, even if it's gonna make you act worse. I think that's true sometimes. Um, BUT I don't try to argue for that in the book. Um I'm mostly trying to think what would it have to look like if the tic norms ever, epistemic norms ever could matter a lot. Um But I don't try to argue, I don't try to really like work out those conflicts between them and other norms."
	},
	{
		"start_time": "17:38",
		"speaker": "Ricardo Lopes",
		"words": "So another thing that you do in your book is that you explore the difference between knowledge and true belief and also then you go through different kinds of beliefs. So, uh to start off with what is the difference there between knowledge and true belief?"
	},
	{
		"start_time": "17:58",
		"speaker": "Brian Talbot",
		"words": "Well, I don't know. Um I suspect nobody knows we, I mean, that's a hu very hotly contested debated area of philosophy. We don't know. I don't think anybody knows, they think people have views. I don't think anybody knows the difference between knowledge and true belief completely. But what we do know is there's these clear cases that are knowledge and there's clear cases that are true beliefs but not knowledge. So we, we know, these kind of clear difference cases. So, I mean, the easy example is, um, let's say, you know, I think what I ask you what's my birthday and you're like, I don't know, you just guess totally randomly unless say you guess it, right. Um, BUT I don't tell you, you just guess you form a belief in your head totally randomly about what my birthday is and you, you know, like, and you believe it even if you got it, right? So you'd have a true belief un controversially among, in, among philosophers, you don't know my birthday. Um So that, but then once I tell you what my birthday is, then you do know it. So that's like kind of a clear case, like guessing isn't gonna give you knowledge even though it can give you true belief. Um YOU know, forming beliefs in an unreasonable manner isn't supposed to give you knowledge even though it can sometimes you luck out and get true beliefs. Um And then of course, what unreasonable means is hotly contested as well. Um So I don't know the difference between knowledge and true belief. And so in the book, I have to talk about knowledge a lot because knowledge is like one of the most standard uh paradigmatic things that standard epistemology thinks about. And that is so I have to criticize how they think about knowledge because I want to criticize standard epistemology, but I don't know what knowledge is So I have to, like, focus on fairly uncontroversial claims that everybody's gonna agree on about the difference between knowledge and true belief."
	},
	{
		"start_time": "19:50",
		"speaker": "Ricardo Lopes",
		"words": "And are there any pointless beliefs? And if so what does it mean to call a belief? Uh, POINTLESS."
	},
	{
		"start_time": "20:00",
		"speaker": "Brian Talbot",
		"words": "Yeah. Almost every possible belief is pointless. That's a real, that's a real bummer. Uh, SO pointless belief. Uh, uh, IS a belief such that it basically doesn't matter if you get it right or not. So, I'll give you an example a fairly standard example. So outside of, uh, there's a park across the street from me and it's got a law, it's got grass on that lawn. Um, I could know it would be a real pain in the neck, but I could know with a lot of work how many blades of grass are in that long, but it doesn't matter. That's like, not a good thing to know. It's like, uh, even if it was easy to know it, it wouldn't be particularly valuable to know that. So, um, it, there a belief about the number of blades in the grass on the lawn can still be reasonable in a very standard sense. It can fit my evidence. Uh It can specify all the standard norms on, on what is a good belief. It can be knowledge, but it just doesn't matter one way or the other if I just guessed how many blades of grass on the lawn. So like even whether or not if, I guess it totally unreasonably, who cares. Uh And so that's an example of a pointless belief. I have some other work prior to the book where, um, I do, I'll, I do some like proofs to show there's a limit to the possible value of pointless beliefs effectively. Uh Either they have no value or they're effectively infinitely small, um infinitely little value. Um And I think that's really important. So, and so first of all, that's like just one example, but it turns out that like when you think hard about pointless beliefs, which, uh, it's weird to have a research project where you have to think where you have to think a lot about what's, what's not worth thinking about. But that's my job. Uh Almost everything you could possibly believe is pointless because did not be so for every interesting question, there's a bunch of really uninteresting related questions. Um So I think, I, I think I use this example of the book, I love my wife and I'm really interested in a lot of things about her, but like, I could count the, the hairs on her arm, I guess. And that would give me some knowledge about my wife, but I think that's pointless, right? And so for almost every topic that we're interested in is actually most of that topic is really kind of boring. Um And so it just turns out the, uh, there is really interesting stuff in the world that we're genuinely curious about and that we should be curious about probably. Um But most things are not worth knowing and like provably not worth knowing. Uh And there's some, I have some interesting proofs uh in some of my earlier work. Uh And so that's important, I think partly because it shows us that just being knowledge is not enough to make something particularly valuable, just being true is not enough to make a belief, particularly valuable, just being a fit fit to your evidence is not particularly valuable. In fact, almost everything that you could believe that was true and knowledge and fitted into your evidence would be not particularly valuable. Um Because again, it mostly be like little facts about how many atoms in the wall behind me and like, you know, how many miles between me and your, your mother's best friend, you know, what was the phone number of your grandparents in 1946? Stuff like that? Right? There's all that facts out there that just aren't, aren't particularly worth knowing. Um And so that opens this question, like if just being knowledge or just being reasonable in a standard sense of reasonable or just being fitted to your evidence, that doesn't make things good automatically because almost everything that does that isn't good. And so then you're like, does it ever make anything good? Is that really what's important? Being knowledge, being reasonable, being true or is there something else going on and that's kind of got part of what got me started thinking about this book,"
	},
	{
		"start_time": "23:55",
		"speaker": "Ricardo Lopes",
		"words": "but that's about pointless beliefs. But what are mundane beliefs? Because that's another kind here, I guess."
	},
	{
		"start_time": "24:03",
		"speaker": "Brian Talbot",
		"words": "Yeah. In the book, I talk about three categories of belief and these are just sort of very rough categories to kind of help frame thinking. Obviously there's a lot of questions that, yeah. Anyway, it's more complicated than this. But I, but I, but you have to simplify things a little bit and, and when you're writing so pointless beliefs, ba basically don't matter at all. Um What I there's something I call interesting beliefs, right? Those are ones that like, it's good to know those. And then this kind of middle category of mundane which are beliefs that are worth the things that are kind of uh important to. Uh, BUT only because they're useful and if they weren't useful, they would be pointless. Um And whereas the sort of interesting stuff is uh important, kind of independent of its usefulness, it's more important than it is useful. So, you know, like, um, I know my wife's phone number, I know my mom's phone number. But like, you know, uh if I was somehow no longer able to use that information, you know, if like aliens came to earth and said, hey, Brian, we're just gonna stop you from ever texting or calling your wife ever again. I'd be really upset about that. But it also would make that information useless to me. Right. So, I wanna know my wife's phone number, but if I couldn't use it, I wouldn't wanna know it anymore. Or I wouldn't care if I knew it one way or another. So that's, am an example of mundane belief. It's worth a belief that's worth having just because it's useful. And then there's, this raises a set of issues which are sometimes true beliefs are useful, but sometimes false beliefs are about as useful as true beliefs. Um, SO, you know, I wanna make salad later on, let's say, and I want to put radishes in that salad because I like radishes and I think I got 37 radishes in my fridge. Well, if I had 36 instead, that's probably still useful, that's probably I'm still gonna act it basically the same. Uh, I wanna know that I have, I want to know something about those radishes but it doesn't need to be like, strictly speaking true. That's actually not a great example. But, uh, it's the simplest one I could think of off the top of my head. Uh There's some really interesting complicated examples in ethics. Actually, in legal philosophy, this comes up all the time. So in legal philosophy, a very common view of the law is that one function of the law is to give us advice. But in order to give us advice, the law sometimes has to be a little bit more simple than reality is if the law was as perfectly, it was so complicated that it was perfectly matching the reality in every possible case, it would be too complicated to understand. You couldn't use it. So, fairly common in view of the law is that the law has to be kind of like a slightly dumbed down version of, um, morality. And if that's right, then the law sometimes gives you bad advice. But in the long run, it's supposed to, if it does its job, it's supposed to give you, uh, you're supposed to do better on a very standard view. Follow. If the law is well made, you'll do better in the long run following the law than you will sort of thinking for yourself in every possible case. That's a controversial view. You don't have to believe that, but it's a pretty common view of what good law looks like. And so in that case, if you believe the law, uh, you would be, you would act better in the long run, but your belief would be slightly false would be a little bit off because the law is oversimplified. So that's a case in which, uh, you might do better with a oversimplified belief that you can use, but which is slight, which is strictly speaking false, you would act better using that, that false belief than you would if you had a totally true belief because it be the true belief would be too complicated to use. Uh And so then we have this question if sometimes, if, what, what we care about from mundane places, their usefulness and false beliefs can sometimes be as or more useful than true beliefs. Why the, then we wouldn't always really wanna have true beliefs in mundane contexts, sometimes false beliefs would be just as good and then epistemic norms as we generally understand them are all about the truth. But then they're not really well matched to mundane the youth, the value of mundane beliefs because mundane beliefs about usefulness, truth and usefulness can come apart. So the epistemic norms that they're standardly understood are not tracking what we really are interested in what we really want out of mundane beliefs."
	},
	{
		"start_time": "28:31",
		"speaker": "Ricardo Lopes",
		"words": "So I, I want to ask you about non-standard epistemic norms. We've already talked a little bit about the standard epistemic norms. You gave a few examples earlier. But before we get into that specifically, could you tell us about this idea of epistemic consequentialism? What is that?"
	},
	{
		"start_time": "28:50",
		"speaker": "Brian Talbot",
		"words": "Yeah. So in ethics, consequentialism is the view that basically what you, what what you should do is determined by what produces the best long run consequences. And very roughly epidemic consequentialism is that idea. But in epistemology, so it's like what you should believe uh is determined by the consequences of those beliefs. So the epidemic consequences. So like what you should believe is determined by uh what the rules are, the norms for belief are determined by uh what norms are best for you to follow in terms of getting, have informed, having good beliefs. So, if you follow these norms in the long run, you'll have better beliefs than if you don't follow these norms."
	},
	{
		"start_time": "29:37",
		"speaker": "Ricardo Lopes",
		"words": "And how does that connect them to non-standard epistemic norm?"
	},
	{
		"start_time": "29:43",
		"speaker": "Brian Talbot",
		"words": "Well, so uh the discussion and epistemology, at least historically uh has looked consequential. So people say, why does it matter that my beliefs are reasonable? Uh Why does it matter that? I believe what my evidence tells me? And the answer is supposed to be, if you do that, you're more gonna have more true beliefs than you would if you didn't do that. So it looks consequentialist, you're justifying, you're explaining the norms in terms of, you're gonna get true beliefs, you follow norms. But of course, uh there are gonna be cases in which forming one false belief is potentially going to give you more true beliefs in the long run. So use the, the law example I just gave, uh, let's as, let's assume that the law is well made, not a good assumption in many countries, but let's assume that we live in a country where the law is well made. And so, uh the average citizen who just believes what the law tells them, who just believe the law is right, is gonna act better more often than if they use their own judgment. Um If that's right, then believing that the law is correct is false because the law is not entirely correct. If you just believe the laws inside you believe the law is entirely correct, that's a false belief. But that, having that false belief will give you more true beliefs in the long run about what you should do in particular situations. It'll give you more true beliefs than having the true belief. That law is incorrect. Um, IF that's right again, there's a lot of ifs there. But we can just imagine that's true. If that were true for a person, then forming one false belief about that, the law is always correct will give them more true beliefs in the long run than if they'd formed the true belief that the law is not entirely correct. So that would be what I called the trade off, uh was often called a trade off. You form one false belief because having that false belief will give you more true beliefs in the long run. And if you're an epidemic, consequentialist, you should say, yeah, that sounds great. But uh everybody who is an epidemic, almost everybody who's an epidemic, consequentialist has tried to deny that this is a consequence of their view. Um So not every single person the last couple of years, like for example, Richard Pettigrew said, yeah, maybe we could be OK with that. Um But historically, people who are epidemic consequentialist have tried to deny that tradeoffs are we should make tradeoffs. Uh But it looks like a natural fit that you should say, forming a false belief, gives you more true beliefs in the long run. That's the right thing to do according to consequentialism. But people want to deny this. Um That's one aspect of it really, really quickly. Also epidemic consequentialist in contemporary work tend to be like maximizer which means that you should form the best beliefs. You can. And uh I think that is the wrong approach in epistemology. You should be a satisfy or uh what's called scalar consequentialist. That's a view that comes from Alison Norcross mostly uh and satisfying and scalar consequentialist don't think you should always believe what's best. Um And if that's right, you, it causes all these really difficult problems for contemporary consequential theories."
	},
	{
		"start_time": "33:14",
		"speaker": "Ricardo Lopes",
		"words": "And in the book, sort of related to that, you also talk about epistemic tradeoffs, what are those? And how do they apply to these discussions surrounding non-standard epistemic norms?"
	},
	{
		"start_time": "33:28",
		"speaker": "Brian Talbot",
		"words": "Yeah. So tradeoffs are cases in which you form one belief that is bad in some way uh in order to form other because it's likely to benefit you in terms of producing other good beliefs. So forming a bad belief about what you should like about uh some rule for action might uh give you more good beliefs about how to act in the long run. Or another example uh from the book, uh John Doris has this uh uh work where he argues that having false beliefs about, uh, your behavior and your personal relationships can lead you to act better in the long run. Also very depressing. Um, AND, uh, if he's right, then it may be that those false beliefs about, um, about the relationship can also lead to other true beliefs about how to act well in your relationship."
	},
	{
		"start_time": "34:23",
		"speaker": "Ricardo Lopes",
		"words": "By the way. Could you give us an example of that?"
	},
	{
		"start_time": "34:26",
		"speaker": "Brian Talbot",
		"words": "No, that's, that's, that's John's work. So that's, that's, I don't know that, I don't know, that works well enough. Um I'll give you a more an example. I do know a little bit better. Um There is some research that suggests that overconfident academics publish better. Um So, and there's some reason to think that thinking you're a better researcher than you, in fact, are that you're more capable than you, in fact, are leads to more discoveries. So that'd be a way in which forming a belief that's false thinking. You're a better researcher than you really are. This is not only false, it probably goes against your evidence. Um, UNREASONABLE belief. Uh That's one bad belief you can form, but if you form that bad belief, you're somewhat more likely to learn things in the future. And if that's true, you've traded off, you've sacrificed your belief about your abilities. You had this one's bad for the benefit of these other long term benefits in terms of learning other new thing, other interesting things. Sorry. One second,"
	},
	{
		"start_time": "35:28",
		"speaker": "Ricardo Lopes",
		"words": "it's probably, it's probably basically the idea that if I think I'm not good enough to become, I don't know, an academic, for example, it's even pointless for me to study or to uh apply to it."
	},
	{
		"start_time": "35:44",
		"speaker": "Brian Talbot",
		"words": "Right. Yeah. So this is, of course, that's an empirical question. Like what actually works. So I'm a philosopher, not a, not a scientist. So I can't tell you if it's really true, that being overconfident will help you. But if it is true, then uh that would be a epistemic trade off. If being overconfident helped you learn new things, that would be a trade off where you're sacrificing one belief and making that bad in order to get other good things. And yeah, I think it's plausible although again, I don't think it's been studied well enough that we can be 100% certain, but it's an interesting example to think about."
	},
	{
		"start_time": "36:19",
		"speaker": "Ricardo Lopes",
		"words": "So tell us now about the methodology that you, you use in the book when it comes to trying to come up with rep what you, you call replacement norms."
	},
	{
		"start_time": "36:34",
		"speaker": "Brian Talbot",
		"words": "Yeah. So um methodology is basically start with what uh people have said um their explanations they've given for why the epistemic norms are supposed to matter. So for example, the consequentialist explanation, which is the epidemic norms are supposed to matter because if we conform to them, we form more good beliefs or um there's a social view that says the epistemic norms are supposed to matter because if we all sort of follow the same rules. We can better figure out who to listen to and who not listen to or the action view, which is that if we uh have good beliefs, that's gonna be good for action in various ways. So each chapter of the book or many of the chapters start with, this is what philosophers said about why the epic norms are supposed to matter. Let's just assume they're right. And then ask what would norms that do what these people are talking about look like? So what would norms that uh produce better action look like? What would norms that enable good social coordinations look like? Um And we don't, so typically, that's assumed that these, these stories are gonna um vindicate uh the norms that we typically accept in philosophy, but I don't assume that. So I say, let's just take this the, the answer very seriously, the idea very seriously. Let's not assume anything about what the norms actually do look like and just say if you started from this idea and you just went, what would you get?"
	},
	{
		"start_time": "38:14",
		"speaker": "Ricardo Lopes",
		"words": "And what do you think would be some of the biggest objections to the kind of way you approach things here basically to your methodology?"
	},
	{
		"start_time": "38:26",
		"speaker": "Brian Talbot",
		"words": "Yeah. Um So I've gotten different objections from different people. Um One objection is the epistemic norms aren't supposed to matter. So who cares? Um That, that always makes that, that always makes me a little bit sad if they don't matter why are we thinking about them so much? Um So another objection is even if I'm right in a sense, the, the, the non-standard norms that I'm interested in, we can't follow them. So, for example, we can't, like, intentionally form false beliefs. If, even if that's gonna give us true beliefs in the long run, that's a pretty standard view. Like, even if you knew that being overconfident was gonna give you more, would help you out in the long run. You can't just make yourself overconfident on that basis. Uh Some people think that's impossible. And so there are, people are like, well, so then, so what um if we can't follow these norms, they, they're not that they're not the right norms. That's like probably the most uh common uh objection. Yeah. And then it sort of, I guess one other objection is just uh people have cared about knowledge and justified belief in the sort of standard sense for all of history, uh All of philosophical history. So there's no way I can, I can be right. I can't. So I'm saying they've always been mistaken. Uh So I must be wrong because I'm disagreeing with Plato uh for and everybody else. So that's a, I think a very reasonable objection. Um"
	},
	{
		"start_time": "40:07",
		"speaker": "Ricardo Lopes",
		"words": "uh And, and I mean, how would you reply to those objections? I mean, do you think that at least uh those people would have a point or not?"
	},
	{
		"start_time": "40:21",
		"speaker": "Brian Talbot",
		"words": "Yeah. So I mean, I think it's, I do think it's a very reasonable worry if you disagree with everybody, it's good evidence that you're wrong. Um, BUT I think, um, the approach that I'm taking to these questions is an approach that I don't think people have taken uh enough previously. And so, um, yeah, so there's all this work outside of epistemology on why norms matter. Right. So again, I do a lot of uh work in ethics and legal philosophy. And, you know, in legal philosophy, people thought about all they always think about, there are the laws and then there are the justification for the laws. And if the, if the justification for the laws doesn't actually mean the laws are good, then we should change the law, right? Um And so, and same thing, ethics, we thought a lot about like why uh people thought a lot about why it's good to be ethical in various ways. And so what I've really tried to do in the book is take these ideas that are these, these discussions from outside of epistemology about the nature of social norms or the nature of respect or the nature of consequentialism, all the stuff and bring them into epistemology in a way that I don't think has been done as much previously as it should have. And so it does give you surprising results. Um But I don't think that is a devastating problem because um if everybody's dis if I'm disagreeing with everybody, but they haven't been approaching things in this way that I'm thinking about things. Um And by the way, I should say, I'm not disagreeing with literally every everybody, not literally everybody, I'm not the only person to have questioned uh sort of standard technology. Quite a few people have done that. So, like, I don't want to say, I'm like the pi I, I'm not even a pioneer, I'm like following in the footsteps of a lot of really important philosophers. Uh So I should, I don't want to puff myself up too much, but I'm disagreeing with a lot of people. Um And so I think it's not surprising because I uh I'm trying to bring a method to this discussion that has not been used often enough. And so uh it's not surprising that people have gotten different results because they haven't as much used. Uh The method I'm using again, other people have, I'm not the only person I've done it this way. But um um most people don't, don't do purchasing this way. And then there's this other question like, well, if we can't do this, uh then why does it matter? Um And it's true, I don't think we can, you can't just like just um most of the time you can't just decide to believe something. Um But you can do things to try to cultivate uh a character that means you'll believe, have better beliefs. Um Even if you can't choose in any particular situation what to believe. You can are like, there's reasons I think you can cultivate being the kind of person that will believe the kinds of things you should believe. And then uh so it still can be interesting to think how we cultivated in ourselves, the right kind of character to believe the right things. And then of course, we want to know what are the right things to believe."
	},
	{
		"start_time": "43:47",
		"speaker": "Ricardo Lopes",
		"words": "And so what kinds of replacement norms do you suggest?"
	},
	{
		"start_time": "43:53",
		"speaker": "Brian Talbot",
		"words": "Um It's gonna depend on why the epistemic norms are supposed to matter. So again, the norms that would be the right norms if all we care about is acting well, are gonna be different from the norms that uh if we partly care about satisfying our curiosity. Um BECAUSE acting well is more disconnected from the truth, more often than curiosity, whereas curiosity is often about the pursuit of truth. Um So it's really gonna depend on what the right answer to the question is. Why did the epidemic no matter in the first place? And I, since I think there's a lot of different good answers to that question, I can't sort of univocity say what should replace it. But I have some general thoughts. Every view about why the norms matter is gonna tell us that sometimes we should make tradeoffs. Sometimes you should form one bad belief in order to form the benefit in other uh epidemically relevant ways. Um WHEN you should form tradeoffs is gonna vary depending on what the good real epidemic good is supposed to be. But all the, all the views I consider end up saying you should make tradeoffs sometimes which are hugely controversial. So that's part of the interest of the book. So the Replacement Norms, the ones that are gonna be the right norms are gonna say make trade off sometimes. Um And then the other thing is the standard asemic norms, say never contradict yourself, never believe anything that's like clearly against your evidence, stuff like that, never believe anything is clearly false. And the replacement norms aren't gonna agree with that. So they'll say you should contradict yourself if that's helpful in the long run, you should believe false things if that's helpful in the long run, but also sometimes believing false things is good enough. Um uh We don't have to have perfect beliefs, we can have beliefs that are good enough. Uh And I think that's gonna be true basically on every view, although what counts as good enough and when, when a false belief can be good enough is gonna depend on what view. So it's not like a, an abdication of the truth. The truth is really important in a lot of contexts. Um But um getting completely to the truth is not always as important in every context, you can get close to the truth of all the, you know. So here's the truth and here's like all the false things you could believe sometimes being like right here really close to the truth, but still wrong is good enough and, you know, it's gonna depend from situation to situation. Um But um I think all the replacement norms are gonna say sometimes getting close enough to the truth is good enough and then in pointless cases, being far from the truth is probably fun in a lot of cases. Um So, yeah, so all the replacement norms are gonna say, make trade off sometimes. And I think they're all gonna say you don't need to get all the way to the truth in every possible situation. And that's a fairly radical view in philosophy."
	},
	{
		"start_time": "46:55",
		"speaker": "Ricardo Lopes",
		"words": "I mean, it's fairly radical but isn't it more realistic to assume that most of the beliefs we have are just at best good enough? I mean, even when it comes to most of the knowledge that is out there to be acquired, I mean, first of all, I guess we don't even have enough time to process all that information and then to form uh correct beliefs or true beliefs. But then, I mean, even as we move along, as, I mean, as time passes, we, as humanity keep acquiring more and more knowledge that we don't have yet have there to, to learn about, you"
	},
	{
		"start_time": "47:43",
		"speaker": "Brian Talbot",
		"words": "know, I, I think that's definitely right. Um And this is actually a thing I'm, I'm in my upcoming work, I'm really interested in. So one thing people could say in response to what you're saying, so I'm very sympathetic with this view. People could say, well, it's true that like, as a whole, we don't, we don't really have, like, we can always improve as a whole, but they might say individual beliefs are either true or false and individual beliefs can be knowledge or not. And so, you know, even if we keep making progress, like at the holistic level, they would say, don't, you shouldn't believe something if it's not true yet, like if you don't know the truth, don't believe it um about individual things. And they say, well, you can know individual things and you get the truth about individual things, even if we keep progressing as a whole. Uh But I actually think this kind of emphasis on individual bits of knowledge and truth is often a mistake and we should be kind of emphasizing like kind of collective kind of. Uh SO are kind of big picture holistic um set of beliefs. Uh What I in the book called The Picture of the world around us. Um I think that might be really what's more important than that. That is what you're saying is 100% applies to that as we acquire new information, our picture gets better and better and better. But like, it's definitely as a whole picture never gonna be completely accurate. And so we have to think if we kind of evaluate our kind of picture of the world as a whole. We can't hold it up to this ideal standard because we're never gonna get there. Um And we have to say, was it, what does it mean for the picture of the world? It's a holistic thing to be good enough. And I actually think that's the right way of thinking. I suspect that's the right way of thinking about epidemic values, kind of more holistically than atomically, rather not about individual beliefs, but about kind of collective sets of beliefs."
	},
	{
		"start_time": "49:37",
		"speaker": "Ricardo Lopes",
		"words": "So one final question then are epistemic norms categorical? And what does it mean for them to be categorical? What does that word mean here?"
	},
	{
		"start_time": "49:50",
		"speaker": "Brian Talbot",
		"words": "Um Well, here's what I think it means. And then you can tell me if that's what if that's what you think it means. Uh WHEN philosophers talk about non being categorical, they typically wanna say something like it applies to everybody at all times, regardless of their desires and interests. Is that kind of what you had in mind?"
	},
	{
		"start_time": "50:14",
		"speaker": "Ricardo Lopes",
		"words": "Yeah, that's usually what I think about when someone mentions that word."
	},
	{
		"start_time": "50:21",
		"speaker": "Brian Talbot",
		"words": "Yeah. So our episode of norms, categorical, it depends. Uh So it again depends on the function of epistemic norms. So I think moral norms are categorical. And if you think that the, that the moral norms kind of involve uh have implications for what we should believe, then the epistemic, then at least some epistemic norms will be categorical because they'll be derivative of the moral norms. But if you think the epistemic norms also have to do with satisfying our curiosity. Um, THEN you might think, well, whether or not they're categorical, then depends on if there are sort of categorical requirements and what we should be curious about. So if you think there are certain things that everybody ought to be curious about and that, then they're gonna be categorical requirements on what you should think about and how you should think about it in order to satisfy that curiosity, but I'm not convinced of that. I think that's an open question. Uh And if curiosity is more subjective and like just you get to be curious about whatever you're curious about, then, then there wouldn't be any categorical norms that are connected to curiosity. So it depends a lot on sort of what, what the end of epistemology really is. If it's about morality, if it's about action, if it's about curiosity, if it's about something else, the category, uh the categorical nature is just gonna kind of come along with that."
	},
	{
		"start_time": "51:54",
		"speaker": "Ricardo Lopes",
		"words": "A and so that would be what in your mind, it would determine whether they should or shouldn't be categorical, is that it?"
	},
	{
		"start_time": "52:06",
		"speaker": "Brian Talbot",
		"words": "Yeah, you figure out what is supposed to, why they're supposed to matter first and then you can answer the question of whether or not they're categorical."
	},
	{
		"start_time": "52:15",
		"speaker": "Ricardo Lopes",
		"words": "Great. So the book is again the end of epistemology as we know it, I'm leaving a link to it in the description of the interview and Dr Talbot just before we go apart from the book, would you like to tell people where they can find you and your work on the internet?"
	},
	{
		"start_time": "52:33",
		"speaker": "Brian Talbot",
		"words": "Yeah. Uh Doctor Brian talbot.com/philosophy. Um Yeah, doctor and, and if you just, if you Google Brian Talbot philosophy, you're gonna find me pretty quickly. So"
	},
	{
		"start_time": "52:47",
		"speaker": "Ricardo Lopes",
		"words": "great. So thank you so much again for taking the time to come on the show. It's been fun to talk with you."
	},
	{
		"start_time": "52:53",
		"speaker": "Brian Talbot",
		"words": "Thank you. It's my pleasure. Thanks for having me. I appreciate it."
	},
	{
		"start_time": "52:57",
		"speaker": "Ricardo Lopes",
		"words": "Hi guys. Thank you for watching this interview. Until the end. If you liked it, please share it. Leave a like and hit the subscription button. The show is brought to you by N Lights learning and development. Then differently check the website at N lights.com and also please consider supporting the show on Patreon or paypal. I would also like to give a huge thank you to my main patrons and paypal supporters, Perego Larson, Jerry Muller and Frederick Suno Bernard Seche O of Alex Adam, Castle Matthew Whitting be no wolf, Tim Ho Erica LJ Conners, Philip Forrest Connelly. Then the Met Robert Wine in NAI Z Mar Nevs calling in Holbrook Field, Governor Mikel Stormer Samuel Andre Francis for Agns Ferger Ken Hall. Her ma J and Lain Jung Y and the Samuel K. Hes Mark Smith, J. Tom Hummel s friends, David Sloan Wilson, Yasa dear. Roman Roach Diego, Jan Punter, Romani Charlotte, Bli Nicole Barba, Adam Hunt, Pavlo Stassi Na Me, Gary G Alman, Sam of Z Ari and YPJ Barboza Julian Price Edward Hall, Eden Broder Douglas Fry Franca Gilon Cortez or Solis Scott Zachary ftdw Daniel Friedman, William Buckner, Paul Giorgio, Luke Loki, Georgio Theophano, Chris Williams and Peter Wo David Williams, the Ausa Anton Erickson, Charles Murray, Alex Shaw, Marie Martinez, Coralie Chevalier, Bangalore Fists, Larry Dey Junior, Old Ebon, Starry Michael Bailey. Then Spur by Robert Grassy Zorn. Jeff mcmahon, Jake Zul Barnabas Radick Mark Temple, Thomas Dvor Luke Neeson, Chris Tory Kimberley Johnson, Benjamin Gilbert Jessica. No week in the B brand Nicholas Carlson Ismael Bensley Man, George Katis, Valentine Steinman, Perros Kate Von Goler, Alexander Albert Liam Dan Biar Masoud Ali Mohammadi Perpendicular J Ner Urla. Good enough Gregory Hastings David Pins of Sean Nelson, Mike Levin and Jos Net. A special thanks to my producers, these our web, Jim Frank Luca Stina, Tom Vig and Bernard N Cortes Dixon Bendik Muller Thomas Trumble, Catherine and Patrick Tobin, John Carlman Negro, Nick Ortiz and Nick Golden and to my executive producers, Matthew Lavender, Sergi, Adrian Bogdan Knits and Rosie. Thank you for all."
	}
]