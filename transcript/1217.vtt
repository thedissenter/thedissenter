WEBVTT

1
00:00:00.379 --> 00:00:03.190
Hello, everyone. Welcome to a new episode of the

2
00:00:03.190 --> 00:00:06.300
Dissenter. I'm your host, as always, Ricardo Lobs, and

3
00:00:06.300 --> 00:00:10.359
today I'm joined by Doctor Hannah Schleihoff. She's uh

4
00:00:10.359 --> 00:00:14.020
an assistant professor in the department for Developmental Psychology

5
00:00:14.020 --> 00:00:19.930
at Utrecht University. Her research investigates socio-cognitive underpinnings of

6
00:00:19.930 --> 00:00:25.090
cultural learning, focusing on how cultural novices, children during

7
00:00:25.090 --> 00:00:29.809
early and middle childhood, grow into proficient cultural beings.

8
00:00:29.850 --> 00:00:32.729
And today we're going to talk about children's ideas

9
00:00:32.729 --> 00:00:37.650
about other people's beliefs, belief revision, revision, and other

10
00:00:37.650 --> 00:00:40.290
related topics. So Hannah, welcome to the show. It's

11
00:00:40.290 --> 00:00:41.509
a pleasure to everyone.

12
00:00:42.130 --> 00:00:44.909
Thank you for having me. So,

13
00:00:45.240 --> 00:00:50.959
when exactly do children start considering other people's beliefs?

14
00:00:51.470 --> 00:00:53.650
So that's a, that's a pretty good first question.

15
00:00:53.759 --> 00:00:56.389
Um, SO maybe let me first talk about what

16
00:00:56.389 --> 00:00:59.400
belief is in general. And I know you've had

17
00:00:59.400 --> 00:01:01.319
a lot of people talking about this on the

18
00:01:01.319 --> 00:01:03.360
show and I think compared to the definitions that

19
00:01:03.360 --> 00:01:07.660
they gave, mine is rather, rather minimal. Um, BUT

20
00:01:07.660 --> 00:01:11.800
belief is, um, a representation, a mental representation that

21
00:01:11.800 --> 00:01:14.919
we have, and it has the goal that it

22
00:01:14.919 --> 00:01:18.339
is a representation of the world as, um, as

23
00:01:18.720 --> 00:01:21.599
close to reality as possible. So the goal of

24
00:01:21.599 --> 00:01:25.239
a belief is to, to be true. But sometimes

25
00:01:25.239 --> 00:01:29.069
our representations, our knowledge about the world is incomplete

26
00:01:29.069 --> 00:01:32.080
or maybe even false. So a belief can be

27
00:01:32.080 --> 00:01:35.349
true, but it can also be false. And I

28
00:01:35.349 --> 00:01:37.470
think it is important when we think about these

29
00:01:37.470 --> 00:01:41.269
mental representations that there are many other kinds of

30
00:01:41.269 --> 00:01:44.949
mental representations that we can have. So, beliefs is

31
00:01:44.949 --> 00:01:47.660
one of them, but we can also um have

32
00:01:47.660 --> 00:01:51.790
mental representations um about hopes, about goals, and about

33
00:01:51.790 --> 00:01:55.065
perspective of, of others. And there is It's like

34
00:01:55.065 --> 00:01:59.224
a developmental trajectory of how these develop. And beliefs

35
00:01:59.224 --> 00:02:02.364
actually is rather the, the end, uh, goal of

36
00:02:02.364 --> 00:02:05.504
this trajectory. So when can we think about other

37
00:02:05.504 --> 00:02:08.945
um people's beliefs, it's something that develops rather late

38
00:02:08.945 --> 00:02:13.619
compared to the others. Um, AND for example, there,

39
00:02:13.740 --> 00:02:15.979
so, um, even there, there is a lot of

40
00:02:15.979 --> 00:02:20.500
variance and a lot of inter interindividual variability in

41
00:02:20.500 --> 00:02:25.940
this, I think, um, there's certain timelines or certain

42
00:02:25.940 --> 00:02:29.419
age ranges, um, that are considered or that are

43
00:02:29.419 --> 00:02:34.110
associated with important developmental changes. And one of them

44
00:02:34.110 --> 00:02:37.850
is around 9 months of age. So there is

45
00:02:37.850 --> 00:02:40.889
a time when kids start to understand other people's

46
00:02:40.889 --> 00:02:45.309
perspective and goals. So, for example, they understand that

47
00:02:45.570 --> 00:02:49.690
um somebody else sees something differently from their own,

48
00:02:49.699 --> 00:02:52.889
so that they have a different perspective. And there

49
00:02:52.889 --> 00:02:56.649
are studies, for example, where you see children see

50
00:02:56.649 --> 00:03:00.289
two objects, but they, um, another person sitting across

51
00:03:00.289 --> 00:03:03.330
from them only sees one. And then, um, they

52
00:03:03.330 --> 00:03:06.210
expect that this agent reaches for the object that

53
00:03:06.210 --> 00:03:08.570
the agent can see and not the object that

54
00:03:08.570 --> 00:03:12.289
only the children can see, for example. And around

55
00:03:12.289 --> 00:03:15.050
the same time, children also start to develop an

56
00:03:15.050 --> 00:03:17.729
understanding of other people's goals, and that these goals

57
00:03:17.729 --> 00:03:20.330
can also be different from their own. And they

58
00:03:20.330 --> 00:03:24.809
also start to predict or expect that people behave

59
00:03:24.809 --> 00:03:28.250
rationally considering the goals and the perspectives that they

60
00:03:28.250 --> 00:03:33.149
have. So that you, um, take your own perspective

61
00:03:33.149 --> 00:03:35.589
and your own goal into account when you make

62
00:03:35.589 --> 00:03:39.089
a certain, um, action, when you plan your actions.

63
00:03:39.589 --> 00:03:42.330
And then a little bit later, around the age

64
00:03:42.330 --> 00:03:46.029
of 18 months, children also start to understand that

65
00:03:46.029 --> 00:03:49.020
people's desires could be different from their own. And

66
00:03:49.020 --> 00:03:53.520
there's one famous study by Alison Gopnik, where the,

67
00:03:53.860 --> 00:03:58.839
the experimenter um pretended to like broccoli much more

68
00:03:59.020 --> 00:04:03.580
than crackers, and the child themselves obviously liked the

69
00:04:03.580 --> 00:04:07.100
crackers much more than, um than the broccoli. And

70
00:04:07.100 --> 00:04:10.460
then the experimenter asked, so, can you please give

71
00:04:10.460 --> 00:04:13.740
me, give me something of the one, That that

72
00:04:13.740 --> 00:04:17.140
I liked the most, and kids younger than 18

73
00:04:17.140 --> 00:04:18.980
months, I think the sample was actually they were

74
00:04:18.980 --> 00:04:22.380
14 months old, they handed over the crackers, but

75
00:04:22.380 --> 00:04:26.140
around 18 months, the kids understood that the experimenters'

76
00:04:26.140 --> 00:04:29.119
preferences are different from their own and handed over

77
00:04:29.220 --> 00:04:34.230
the broccoli. And then a little bit later, again,

78
00:04:34.239 --> 00:04:37.510
around the age of 4, children really become to

79
00:04:37.510 --> 00:04:41.279
be um understand that also people's beliefs can be

80
00:04:41.279 --> 00:04:44.000
different from their own, and also can be different

81
00:04:44.000 --> 00:04:46.920
from the, the true state of the world so

82
00:04:46.920 --> 00:04:50.040
that we can also hold false beliefs. And around

83
00:04:50.040 --> 00:04:54.760
that age, children typically pass these very famous like

84
00:04:54.760 --> 00:04:57.239
false belief tests, and I think the most famous

85
00:04:57.239 --> 00:05:02.410
one there is, is, um, When children observe how

86
00:05:02.410 --> 00:05:05.329
an object is hidden in one of two boxes,

87
00:05:05.690 --> 00:05:08.630
and, um, an agent sees how this is happening,

88
00:05:08.850 --> 00:05:11.089
and then the agent leaves the stage, so the

89
00:05:11.089 --> 00:05:14.250
agent thinks the object is, for example, in box

90
00:05:14.250 --> 00:05:17.329
A, and then somebody else comes in and moves

91
00:05:17.329 --> 00:05:19.269
this object and puts it in the other box.

92
00:05:20.149 --> 00:05:23.040
And then, um, the kids observed this whole scene,

93
00:05:23.160 --> 00:05:25.279
but the agent, the first agent was gone, so

94
00:05:25.279 --> 00:05:28.000
he doesn't know where it is. But comes back

95
00:05:28.000 --> 00:05:30.279
and then the children are asked, um, where would

96
00:05:30.279 --> 00:05:34.059
this person now look for, for the object? And

97
00:05:34.239 --> 00:05:36.480
kids around 4 years of age start to answer

98
00:05:36.480 --> 00:05:39.480
this question, right? So they say the agent would

99
00:05:39.480 --> 00:05:41.920
look in the first box where they um thought,

100
00:05:42.079 --> 00:05:44.279
where they believed the object was hidden, even though

101
00:05:44.279 --> 00:05:47.839
it's not a state of reality anymore. And kids

102
00:05:47.839 --> 00:05:51.519
that are younger usually um still say that's in

103
00:05:51.519 --> 00:05:56.549
the other box, and, Yeah, around that age, you

104
00:05:56.549 --> 00:05:59.630
really, we would really say that children really start

105
00:05:59.630 --> 00:06:03.029
to consider another person's belief because then they have

106
00:06:03.029 --> 00:06:07.269
this like full blown understanding of um what a

107
00:06:07.269 --> 00:06:09.350
belief is and that the belief can also be

108
00:06:09.350 --> 00:06:09.869
false.

109
00:06:11.720 --> 00:06:15.529
And why is it that people, not only children

110
00:06:15.529 --> 00:06:19.529
but also adults, care about the beliefs that other

111
00:06:19.529 --> 00:06:22.970
people hold? Why does it matter?

112
00:06:24.359 --> 00:06:28.160
I think this is really fundamental to us being

113
00:06:28.160 --> 00:06:32.459
such a social species, so understanding and being able

114
00:06:32.459 --> 00:06:36.019
to navigate the social world is necessary for our

115
00:06:36.019 --> 00:06:39.670
survival. And just to give you a few examples

116
00:06:39.670 --> 00:06:42.470
where I think this matters, um, for example, when

117
00:06:42.470 --> 00:06:47.750
we Yeah, predict other people's behavior, so imagine that

118
00:06:47.750 --> 00:06:50.709
um I'm like going to a concert with my

119
00:06:50.709 --> 00:06:54.429
friend tomorrow, but then I learn the concert is

120
00:06:54.429 --> 00:06:57.269
being canceled, but my friend doesn't know it, so

121
00:06:57.269 --> 00:06:59.890
I know that they would probably still show up,

122
00:07:00.070 --> 00:07:01.619
so I predict that they show up at the

123
00:07:01.619 --> 00:07:05.869
concert hall, if I don't inform them that the

124
00:07:05.869 --> 00:07:09.299
concert was canceled, and um then I can, Use

125
00:07:09.299 --> 00:07:11.540
this information to help them and write them a

126
00:07:11.540 --> 00:07:15.119
text and tell them, your, the concert was canceled,

127
00:07:15.220 --> 00:07:17.739
um, you should not go there. So I can

128
00:07:17.739 --> 00:07:21.260
use this information to predict other people's behavior and

129
00:07:21.260 --> 00:07:24.299
then help them. But for example, you could also

130
00:07:24.299 --> 00:07:27.679
use it to deceive others if for whatever reason,

131
00:07:27.700 --> 00:07:31.040
I do. I, the concert is actually happening, but

132
00:07:31.040 --> 00:07:33.230
I don't want my friend to to go. I

133
00:07:33.230 --> 00:07:35.880
could also tell them the concert was canceled even

134
00:07:35.880 --> 00:07:37.959
though it's still happening, so I could also deceive

135
00:07:37.959 --> 00:07:42.519
someone with this knowledge. And it also enables us

136
00:07:42.519 --> 00:07:46.600
to really share a common vision so we can

137
00:07:46.600 --> 00:07:49.320
have, if we know what another person believes, I

138
00:07:49.320 --> 00:07:53.760
can, um, change this person's beliefs so that we

139
00:07:53.760 --> 00:07:55.320
have a common vision. So it's really a sort

140
00:07:55.320 --> 00:08:01.019
of, The foundation of collaboration and us working together.

141
00:08:01.769 --> 00:08:05.410
And I think one other um important topic that

142
00:08:05.410 --> 00:08:08.410
is important to us humans, we are really concerned

143
00:08:08.410 --> 00:08:12.850
about what other people's beliefs about, believe about us.

144
00:08:12.929 --> 00:08:16.570
So we're really concerned about our reputation and being

145
00:08:16.570 --> 00:08:19.890
aware of what another person believes helps us also

146
00:08:19.890 --> 00:08:22.769
to manage our reputation and maybe behave in certain

147
00:08:22.769 --> 00:08:26.570
ways, um, uh, in front of certain people or

148
00:08:26.570 --> 00:08:28.769
maybe also in others. So I think those are

149
00:08:28.769 --> 00:08:33.229
just a few examples. Um, THAT really illustrate that

150
00:08:33.229 --> 00:08:36.520
we use the skill to think about other people's

151
00:08:36.520 --> 00:08:39.440
beliefs pretty much all the time every day.

152
00:08:41.200 --> 00:08:44.450
And what are the kinds of beliefs that people

153
00:08:44.450 --> 00:08:45.969
tend to care about?

154
00:08:48.190 --> 00:08:52.429
I think that um people care about others' beliefs

155
00:08:52.429 --> 00:08:55.869
when those beliefs are related um or in some

156
00:08:55.869 --> 00:08:59.979
way like meaningful and relevant to their um own

157
00:08:59.979 --> 00:09:04.369
lives, to themselves, um, and also in certain contexts.

158
00:09:05.049 --> 00:09:07.929
And just to give you a simple example, I

159
00:09:07.929 --> 00:09:11.309
think when I'm like on. Uh, IN the traffic,

160
00:09:11.340 --> 00:09:14.400
I'm driving a car and I believe that the

161
00:09:14.400 --> 00:09:16.710
other driver thinks that the traffic light is green,

162
00:09:16.799 --> 00:09:18.640
even though I know that it's red. That is

163
00:09:18.640 --> 00:09:22.039
like an important like piece of information that is

164
00:09:22.039 --> 00:09:25.760
um That could save my life. And this is

165
00:09:25.760 --> 00:09:30.080
a fact-based belief. So here I'm like making some

166
00:09:30.320 --> 00:09:35.440
inferences about the, the other um potential like facts

167
00:09:35.440 --> 00:09:38.099
that the other person thinks that are facts um

168
00:09:38.320 --> 00:09:41.119
in the world, but there's also other kinds of

169
00:09:41.119 --> 00:09:44.479
beliefs um that are, are seem to be almost

170
00:09:44.479 --> 00:09:46.840
a little bit more complex, for example, when I'm

171
00:09:46.840 --> 00:09:51.320
trying to, Decide who um to spend time with,

172
00:09:51.330 --> 00:09:53.770
uh, with, um, who are my friends, what kind

173
00:09:53.770 --> 00:09:56.849
of values do they have, and what, yeah, kind

174
00:09:56.849 --> 00:09:59.039
of people do I want to surround myself with,

175
00:09:59.130 --> 00:10:01.530
then I might also think about what kind of

176
00:10:01.530 --> 00:10:04.280
core beliefs, what kind of core values they have,

177
00:10:04.609 --> 00:10:07.729
so that I can decide um who, who to

178
00:10:07.729 --> 00:10:09.690
spend my time with, who to learn from, who

179
00:10:09.690 --> 00:10:12.789
to befriend. And I think those beliefs are more

180
00:10:12.890 --> 00:10:16.369
like value-based beliefs. So there we are not making

181
00:10:16.369 --> 00:10:19.880
inferences so much about Facts and evidence, but more

182
00:10:19.880 --> 00:10:23.260
about what do people, what values do people hold.

183
00:10:24.750 --> 00:10:28.099
Right, OK, so you've already told us that about

184
00:10:28.099 --> 00:10:31.719
fact-based and value-based beliefs, we're going to come back

185
00:10:31.719 --> 00:10:35.179
to them later, but it is one thing for

186
00:10:35.179 --> 00:10:38.739
people to hold particular beliefs, but it is another

187
00:10:38.739 --> 00:10:42.219
thing for them to have control over their own

188
00:10:42.219 --> 00:10:46.099
beliefs. Uh, WHAT kinds of intuitions do children and

189
00:10:46.099 --> 00:10:47.820
adults have about that?

190
00:10:49.309 --> 00:10:52.270
Yeah, that's a great question there. Um, I need

191
00:10:52.270 --> 00:10:56.190
to mention here, Joshua Konfer, who is, um, a

192
00:10:56.190 --> 00:10:59.289
PhD student at UC Berkeley and actually just, um,

193
00:10:59.510 --> 00:11:03.109
just graduated, and he is really interested in this

194
00:11:03.109 --> 00:11:07.349
topic and ran a few studies where he is

195
00:11:07.349 --> 00:11:11.739
interested or investigated what kind of intuitions adults and

196
00:11:11.739 --> 00:11:15.950
also younger children have about What kind of beliefs

197
00:11:15.950 --> 00:11:19.270
other people can hold and how free they are

198
00:11:19.270 --> 00:11:24.130
in choosing of what kinds of beliefs, um, they,

199
00:11:24.549 --> 00:11:29.469
they choose to hold and um he starts his

200
00:11:29.469 --> 00:11:33.229
paper by giving this example that if you look

201
00:11:33.229 --> 00:11:36.950
at fact-based beliefs, so sometimes we have the feeling

202
00:11:36.950 --> 00:11:40.950
that it's almost impossible to believe something else if

203
00:11:40.950 --> 00:11:44.780
there is evidence speaking for a certain belief. So,

204
00:11:44.940 --> 00:11:48.380
imagine, um, I am now telling you that the

205
00:11:48.380 --> 00:11:52.940
United States is a colony of Great Britain and

206
00:11:52.940 --> 00:11:55.299
you have a lot of evidence that speaks against

207
00:11:55.299 --> 00:11:57.619
it. So even if I would offer you a

208
00:11:57.619 --> 00:12:00.780
lot of money, you probably couldn't change your mind.

209
00:12:00.900 --> 00:12:03.409
So you really are like convinced you have so

210
00:12:03.409 --> 00:12:07.260
much evidence that the US is no more, no

211
00:12:07.260 --> 00:12:09.659
longer a colony of Great Britain, that you would

212
00:12:09.659 --> 00:12:12.349
not change your mind. So here it seems like.

213
00:12:12.869 --> 00:12:19.200
Evidence is um uh like a limiting feature of

214
00:12:19.460 --> 00:12:22.359
how free we are to choose what to believe.

215
00:12:22.890 --> 00:12:26.299
And he investigated this in um a study with

216
00:12:26.299 --> 00:12:29.280
younger children, uh, 5 to 6 year old children,

217
00:12:29.500 --> 00:12:35.099
um, also, and adults, and ran 3 different conditions

218
00:12:35.099 --> 00:12:38.820
where he manipulated how much evidence a person or

219
00:12:38.820 --> 00:12:42.909
what kind of evidence a person has, um. To

220
00:12:42.909 --> 00:12:46.309
base their belief on. And he did this by

221
00:12:46.309 --> 00:12:51.179
showing the kids, um, A picture book story, and

222
00:12:51.179 --> 00:12:53.580
in this picture books, the kid saw a character

223
00:12:53.580 --> 00:12:56.659
and the character formed the belief that the weather

224
00:12:56.659 --> 00:13:00.900
is sunny, it's sunny outside, but there were different

225
00:13:00.900 --> 00:13:04.099
conditions and how much evidence this character had for

226
00:13:04.099 --> 00:13:07.260
this belief. There was a strong evidence condition where

227
00:13:07.260 --> 00:13:11.500
the character um went to the living room, looked

228
00:13:11.500 --> 00:13:13.179
outside the window and saw that the sun was

229
00:13:13.179 --> 00:13:16.700
shining. So there, the character had strong evidence for

230
00:13:16.700 --> 00:13:19.969
their belief. And then there was another condition where

231
00:13:19.969 --> 00:13:22.609
the character had no evidence for their belief, so

232
00:13:22.609 --> 00:13:26.530
the character stayed in the bedroom that didn't have

233
00:13:26.530 --> 00:13:30.130
any windows and still formed the belief, it's sunny

234
00:13:30.130 --> 00:13:34.000
outside. And in the third condition, there was counter-evidence.

235
00:13:34.200 --> 00:13:36.159
So, the character went to the living room, looked

236
00:13:36.159 --> 00:13:39.200
out of the window, it's raining, but formed a

237
00:13:39.200 --> 00:13:42.400
belief, it's sunny outside. And then the kids were

238
00:13:42.400 --> 00:13:45.780
asked, and also adults, so would it be possible

239
00:13:45.960 --> 00:13:49.599
that this character would hold the opposite belief instead,

240
00:13:49.679 --> 00:13:53.929
so that it's raining outside. And interestingly, um, even

241
00:13:53.929 --> 00:13:55.969
the youngest children as well as the the adults

242
00:13:55.969 --> 00:14:00.729
really seem, um, perceive that this evidence is restricting

243
00:14:00.729 --> 00:14:04.140
the freedom that this character has to form their

244
00:14:04.140 --> 00:14:07.330
beliefs. So, in the strong evidence condition, they said

245
00:14:07.330 --> 00:14:11.250
that it's almost impossible to, to change their mind.

246
00:14:11.369 --> 00:14:14.450
So you kind of, you almost must believe that

247
00:14:14.450 --> 00:14:16.919
it is sunny outside if you've seen it. But

248
00:14:16.919 --> 00:14:18.840
when there was no evidence or if there was

249
00:14:18.840 --> 00:14:22.320
even evidence leading into a different direction, they said

250
00:14:22.320 --> 00:14:24.770
it's very possible that you hold a different belief,

251
00:14:25.080 --> 00:14:27.599
um, or almost you need to change your mind

252
00:14:27.599 --> 00:14:31.020
if there's evidence, uh, speaking for the contrary. Mhm.

253
00:14:32.489 --> 00:14:35.530
But, uh, do the kinds of intuitions people have

254
00:14:35.530 --> 00:14:39.530
about other people being able to control their own

255
00:14:39.530 --> 00:14:41.570
beliefs or the kind of control they have over

256
00:14:41.570 --> 00:14:44.650
their own beliefs depend on whether we are talking

257
00:14:44.650 --> 00:14:48.429
about fact-based or value-based beliefs?

258
00:14:49.570 --> 00:14:51.929
Yeah, um, that is actually the second condition that

259
00:14:51.929 --> 00:14:54.880
Josh, um, the 2nd study that Josh ran there

260
00:14:54.880 --> 00:14:59.169
he looked at value-based beliefs. And here, similar to

261
00:14:59.169 --> 00:15:01.969
for the fact-based beliefs, it is the evidence that

262
00:15:01.969 --> 00:15:06.030
is limiting what beliefs are possible, and his hypothesis

263
00:15:06.030 --> 00:15:09.770
here was that for value-based beliefs, it's morality, whether

264
00:15:09.770 --> 00:15:12.570
we think a certain belief is possible to hold

265
00:15:12.570 --> 00:15:16.330
or not. And here he also again had three

266
00:15:16.330 --> 00:15:19.450
conditions. Um, ONE condition where a character formed a

267
00:15:19.450 --> 00:15:23.849
moral belief, an immoral belief, and one where it

268
00:15:23.849 --> 00:15:27.369
was neither moral or immoral, where the character just

269
00:15:27.369 --> 00:15:30.450
like had a, um, stated like a certain opinion

270
00:15:30.450 --> 00:15:34.369
or preference. So to give you a more detailed

271
00:15:34.369 --> 00:15:36.570
example of how this looked like, it was a

272
00:15:36.570 --> 00:15:39.880
character called Ashley, who is um in a park

273
00:15:39.880 --> 00:15:43.719
and she sees, A boy um who, like, falls

274
00:15:43.719 --> 00:15:46.239
from his bike, and then in the moral condition,

275
00:15:46.559 --> 00:15:49.669
she formed the belief, it's bad that this uh

276
00:15:49.669 --> 00:15:52.710
boy fell from the bike and hurt himself. And

277
00:15:52.710 --> 00:15:55.880
in the immoral condition, Ashley formed the belief, it's

278
00:15:55.880 --> 00:15:58.239
good that this boy fell from the bike and

279
00:15:58.239 --> 00:16:03.080
hurt himself. And in the opinion condition, um, the,

280
00:16:03.119 --> 00:16:04.919
the boy, she was just seeing that the boy

281
00:16:04.919 --> 00:16:07.119
sits next to his bike, she didn't observe the

282
00:16:07.119 --> 00:16:11.239
falling process. And, um, formed this opinion, oh, it's,

283
00:16:11.400 --> 00:16:14.909
it's good that this bike, um, is yellow. And

284
00:16:14.909 --> 00:16:18.179
then we presented uh the kids and adults with,

285
00:16:18.200 --> 00:16:20.960
um, the, an alternative belief and us, is it

286
00:16:20.960 --> 00:16:24.640
possible to hold this alternative belief? And when they

287
00:16:24.640 --> 00:16:27.400
had formed, when Ashley had formed a moral belief

288
00:16:27.400 --> 00:16:30.630
in the beginning, we presented. The um with an

289
00:16:30.630 --> 00:16:33.549
immoral belief and ask, could it instead be also

290
00:16:33.549 --> 00:16:36.869
um the case that Ashley thinks that it is

291
00:16:36.869 --> 00:16:39.869
good that the boy fell from the bike? Or

292
00:16:39.869 --> 00:16:43.309
if Ashley had formed the immoral belief, we asked

293
00:16:43.309 --> 00:16:46.989
them, could it instead be that it's um bad,

294
00:16:47.109 --> 00:16:49.530
that Ashley thinks it's bad that the boy fell

295
00:16:49.530 --> 00:16:52.349
um from the bike. And in the case of

296
00:16:52.349 --> 00:16:55.489
the opinion condition, we simply asked them. Could it

297
00:16:55.489 --> 00:16:58.289
also be that Ashley thinks it's good if the

298
00:16:58.289 --> 00:17:02.020
bike was blue instead of yellow? And here we

299
00:17:02.020 --> 00:17:06.530
also found interesting condition differences. So in the moral

300
00:17:06.530 --> 00:17:11.058
condition, most or the majority of participants, um, Had

301
00:17:11.058 --> 00:17:14.298
the feeling that it is actually not so likely

302
00:17:14.298 --> 00:17:17.698
that you change your mind, versus in the immoral

303
00:17:17.698 --> 00:17:21.019
condition when Ashley was holding an immoral belief, it's

304
00:17:21.019 --> 00:17:22.779
good that the boy fell from the bike, it

305
00:17:22.779 --> 00:17:24.739
was very different, so they had a feeling it,

306
00:17:24.979 --> 00:17:27.208
she should be drawn to the opposite, so she

307
00:17:27.208 --> 00:17:30.659
should be drawn to um thinking it would be

308
00:17:30.659 --> 00:17:34.688
possible um that it was bad, so drawn to,

309
00:17:34.698 --> 00:17:37.310
towards the moral side. And also in the opinion,

310
00:17:37.449 --> 00:17:40.670
um, condition, kids and adults had the feeling it's,

311
00:17:40.689 --> 00:17:45.010
um, or the preference to, to say that it's

312
00:17:45.010 --> 00:17:47.130
OK to, you have a lot of control of

313
00:17:47.130 --> 00:17:49.410
your of your beliefs. So you can believe that

314
00:17:49.410 --> 00:17:52.390
it's good that the bike is blue or yellow.

315
00:17:53.089 --> 00:17:56.729
Um, AND then we found in one of the

316
00:17:56.729 --> 00:18:00.069
conditions also an interesting age difference or age effects,

317
00:18:00.290 --> 00:18:03.469
and that was in, in the moral condition. There

318
00:18:03.469 --> 00:18:07.290
we found that the youngest kids had the feeling,

319
00:18:08.030 --> 00:18:11.140
it is really like this, this morality is really

320
00:18:11.140 --> 00:18:13.569
restricting of what you can believe or not. So,

321
00:18:13.829 --> 00:18:17.390
if you believe it is bad, the um boy

322
00:18:17.390 --> 00:18:20.310
fell from the bike, it's really almost impossible to

323
00:18:20.310 --> 00:18:24.030
believe the opposite. But this actually this effect um

324
00:18:24.030 --> 00:18:29.439
reduced the older participants got with adults, Um, thinking

325
00:18:29.439 --> 00:18:32.420
that it is actually still pretty possible that you

326
00:18:32.420 --> 00:18:34.859
could think the opposite, that you also could hold

327
00:18:34.859 --> 00:18:38.989
an immoral belief. So it seems like Um, especially

328
00:18:38.989 --> 00:18:42.530
for the younger age groups, morality really seems to

329
00:18:42.829 --> 00:18:47.979
restrict the beliefs that seem to be possible. Compared

330
00:18:47.979 --> 00:18:50.000
to the older ones. Mhm.

331
00:18:50.540 --> 00:18:54.939
Right. And are there big differences between the judgments

332
00:18:54.939 --> 00:18:57.160
made by children and adults?

333
00:18:58.550 --> 00:19:01.380
Yeah, the, the differences that we found are, are

334
00:19:01.380 --> 00:19:04.469
restricted to the second study where we looked at

335
00:19:04.469 --> 00:19:09.030
value-based beliefs and, um, the differences were really the

336
00:19:09.030 --> 00:19:12.689
ones that we found in this morality condition. So

337
00:19:12.829 --> 00:19:16.859
only there in the morality condition, if the, uh,

338
00:19:16.869 --> 00:19:19.829
the kids and the um, we had 55 and

339
00:19:19.829 --> 00:19:22.790
6 year olds, 7 and 8-year-olds and adults, and

340
00:19:22.790 --> 00:19:27.349
there we, we found that the Um, younger children

341
00:19:27.349 --> 00:19:32.910
thought that the beliefs are really restricted by this

342
00:19:32.910 --> 00:19:37.180
morality, so they thought it's almost impossible to hold

343
00:19:37.180 --> 00:19:40.500
an immoral instead of a moral belief. But the

344
00:19:40.500 --> 00:19:42.390
older the kids got, so even the 7 and

345
00:19:42.390 --> 00:19:45.109
8 year olds and the adults thought it is

346
00:19:45.109 --> 00:19:47.270
more possible to also change your mind to a

347
00:19:47.270 --> 00:19:51.829
moral belief, and we, Oh, we, we don't really,

348
00:19:51.849 --> 00:19:55.410
um, exactly studied what are the underlying mechanisms for

349
00:19:55.410 --> 00:19:59.130
this, but our interpretation was that the more you

350
00:19:59.130 --> 00:20:03.170
are um uh confronted or more experiences you also

351
00:20:03.170 --> 00:20:06.770
get with like immoral behaviors of other people, the

352
00:20:06.770 --> 00:20:09.040
more likely you see it, you, you think it

353
00:20:09.040 --> 00:20:12.239
is that people can also change their mind, um,

354
00:20:12.250 --> 00:20:14.750
and hold immoral beliefs.

355
00:20:16.119 --> 00:20:19.760
So let's get into the topic of belief revision.

356
00:20:20.040 --> 00:20:21.140
What, what is that?

357
00:20:22.489 --> 00:20:25.689
Yeah, we um have already slightly hinted at this.

358
00:20:25.729 --> 00:20:30.530
Um, SO belief revision is the process of changing

359
00:20:30.530 --> 00:20:34.930
your mind when new information arrives, and especially when

360
00:20:34.930 --> 00:20:38.569
this information contradicts what you already believe. And I

361
00:20:38.569 --> 00:20:42.849
think it's important um to distinguish two concepts there.

362
00:20:42.949 --> 00:20:45.130
So one is belief updating, and the other is

363
00:20:45.130 --> 00:20:48.750
belief revision. And belief updating is um that you

364
00:20:48.750 --> 00:20:52.310
hold a certain belief. Um, FOR example, uh, going

365
00:20:52.310 --> 00:20:54.829
back to the, um, false belief example, in the

366
00:20:54.829 --> 00:20:58.229
beginning, a reward is in one box, and then

367
00:20:58.229 --> 00:21:00.869
you see, for example, how an, uh, agent is

368
00:21:00.869 --> 00:21:03.469
taking this, um, object out and you remove it,

369
00:21:03.609 --> 00:21:05.989
and we removes it in the second box. And

370
00:21:05.989 --> 00:21:07.949
then you can update your beliefs, so you see

371
00:21:07.949 --> 00:21:11.150
this change happening, you can update your belief that

372
00:21:11.150 --> 00:21:13.290
uh now the object is not anymore in A

373
00:21:13.290 --> 00:21:15.699
but in B, and you've observed this process. So

374
00:21:15.699 --> 00:21:18.510
there is not really a conflict happening, but still

375
00:21:18.510 --> 00:21:20.949
your belief has changed. And that is what we

376
00:21:20.949 --> 00:21:24.650
call belief updating. And if there is a conflict,

377
00:21:24.709 --> 00:21:28.349
um, for example, imagine you haven't observed this process

378
00:21:28.349 --> 00:21:30.229
of how the object is removed from A to

379
00:21:30.229 --> 00:21:33.650
B. Um, THEN it's really a conflict. So, if

380
00:21:33.650 --> 00:21:35.930
you suddenly see, oh, now the object is in

381
00:21:35.930 --> 00:21:38.810
B, then you realize, oh, it cannot be true

382
00:21:38.810 --> 00:21:41.089
anymore that it is in A. So there is

383
00:21:41.089 --> 00:21:43.689
a conflict between these two beliefs, and you need

384
00:21:43.689 --> 00:21:47.810
to decide, is my new evidence strong enough that

385
00:21:47.810 --> 00:21:51.410
I need to abandon my former belief and take

386
00:21:51.410 --> 00:21:52.390
on my new belief.

387
00:21:54.800 --> 00:21:59.160
And and how does belief revision develop in children?

388
00:22:01.089 --> 00:22:03.930
So far what I know of in the research,

389
00:22:04.089 --> 00:22:07.010
most of the studies look at kids in the

390
00:22:07.010 --> 00:22:09.979
age range from 4 and 5 years. For 4

391
00:22:09.979 --> 00:22:13.030
and 5 years and that also makes sense and

392
00:22:13.030 --> 00:22:15.420
so far if you think about that, um, this

393
00:22:15.420 --> 00:22:19.099
is the age when they are able to understand

394
00:22:19.099 --> 00:22:21.739
the concept of a belief. So they understand that

395
00:22:21.739 --> 00:22:24.819
beliefs can be false and um maybe are more

396
00:22:24.819 --> 00:22:28.819
flexible in um in changing their beliefs. And in

397
00:22:28.819 --> 00:22:31.640
my own studies where I also looked at um

398
00:22:31.660 --> 00:22:35.489
4 and 5 year olds, we found that. At

399
00:22:35.489 --> 00:22:38.770
this age range, like so early, they actually, kids

400
00:22:38.770 --> 00:22:42.930
already changed their beliefs in very rational ways, and

401
00:22:42.930 --> 00:22:48.050
that they consider, Um, not only, like, new information

402
00:22:48.050 --> 00:22:53.410
coming in, but they also consider what foundation they

403
00:22:53.410 --> 00:22:55.329
base their initial beliefs on.

404
00:22:56.550 --> 00:23:01.250
Mhm. And on what basis do children revise their

405
00:23:01.250 --> 00:23:02.229
beliefs then?

406
00:23:03.489 --> 00:23:07.599
Yeah, so They, they do consider what we found

407
00:23:07.599 --> 00:23:09.979
in our own study that they do always consider,

408
00:23:10.579 --> 00:23:13.239
yeah, their prior beliefs and the, uh, the strength

409
00:23:13.239 --> 00:23:16.160
of their prior beliefs, and then they compare this

410
00:23:16.160 --> 00:23:19.119
to the new evidence coming in and the quality

411
00:23:19.119 --> 00:23:22.319
of new, of the new evidence and how we

412
00:23:22.319 --> 00:23:25.680
did this in our study, um, we also had

413
00:23:25.680 --> 00:23:27.560
again two boxes, um, that is how a lot

414
00:23:27.560 --> 00:23:31.890
of our research works and The kids, um, we're

415
00:23:31.890 --> 00:23:33.770
told in one of these boxes is a reward

416
00:23:33.770 --> 00:23:38.770
for you. And then, We, um, manipulated the prior

417
00:23:38.770 --> 00:23:41.650
belief of whether the children thinks it's in box

418
00:23:41.650 --> 00:23:43.959
A or box B by asking the children, can

419
00:23:43.959 --> 00:23:45.729
you bring the boxes over to the table where

420
00:23:45.729 --> 00:23:48.250
the study is taking place? And when the kids

421
00:23:48.250 --> 00:23:51.400
picked up these boxes, one of the boxes was,

422
00:23:51.530 --> 00:23:54.729
was either heavier or made a noise, so that

423
00:23:54.729 --> 00:23:56.890
they thought, oh, it's probably the reward is in

424
00:23:56.890 --> 00:23:59.930
there. So they had some evidence that the reward

425
00:23:59.930 --> 00:24:03.449
is in one of these boxes. Um, So in

426
00:24:03.449 --> 00:24:06.890
that condition, they had strong evidence actually, in, for

427
00:24:06.890 --> 00:24:09.050
example, the, the reward is in box A because

428
00:24:09.050 --> 00:24:12.709
it's heavier. And then we presented them with an

429
00:24:12.709 --> 00:24:15.790
alternative, uh, new evidence that the reward is in

430
00:24:15.790 --> 00:24:18.709
the respective other box. And what we did in

431
00:24:18.709 --> 00:24:20.770
our study that is, was that we gave them

432
00:24:20.770 --> 00:24:23.829
verbal reasons. So we were interested in how, um,

433
00:24:23.839 --> 00:24:27.569
can children like evaluate verbal reasons and integrate them

434
00:24:27.569 --> 00:24:30.589
with their prior knowledge. And in that case, one

435
00:24:30.589 --> 00:24:34.270
of the reasons, the reason was either good or

436
00:24:34.270 --> 00:24:38.099
was bad. So for example, um, imagine you have

437
00:24:38.109 --> 00:24:41.510
strong evidence that um the reward is in box

438
00:24:41.510 --> 00:24:45.189
A, but then somebody tells you, but the reward

439
00:24:45.189 --> 00:24:47.390
is actually in box B because I've seen it

440
00:24:47.390 --> 00:24:48.910
in there, so I know it because I've seen

441
00:24:48.910 --> 00:24:50.829
it in there. So that would be a good

442
00:24:50.829 --> 00:24:53.180
reason, and now we have like two good reasons,

443
00:24:53.189 --> 00:24:59.060
like, like, um, contradicting each other. Alternatively, if you

444
00:24:59.060 --> 00:25:02.130
have this strong evidence and somebody else tells you,

445
00:25:02.410 --> 00:25:05.489
oh, I think it's in box B because that

446
00:25:05.489 --> 00:25:08.020
box is my favorite color, then it's rather a

447
00:25:08.020 --> 00:25:10.459
weak reason, so here you would rather not change

448
00:25:10.459 --> 00:25:14.969
your mind. And in another condition, we also manipulated

449
00:25:14.969 --> 00:25:18.050
whether they have prior evidence at all. So if

450
00:25:18.050 --> 00:25:20.290
they brought over the boxes and both of them

451
00:25:20.290 --> 00:25:22.489
were equally heavy or none of them made a

452
00:25:22.489 --> 00:25:26.609
noise, then they didn't have any evidence, prior evidence

453
00:25:26.609 --> 00:25:29.270
to base their belief on. So there we were,

454
00:25:29.530 --> 00:25:32.290
maybe it would be more likely that they're swayed

455
00:25:32.290 --> 00:25:36.209
by the argument presented afterwards. And what we found

456
00:25:36.209 --> 00:25:39.310
was that actually kids relate change their beliefs in

457
00:25:39.310 --> 00:25:43.390
a very rational way, so they really incorporated the

458
00:25:43.390 --> 00:25:45.989
strength of their prior belief, whether it was based

459
00:25:45.989 --> 00:25:49.420
on evidence or not, and the quality of the

460
00:25:49.420 --> 00:25:52.390
argument that was presented afterwards. So if they didn't

461
00:25:52.390 --> 00:25:54.510
have any prior belief but were presented with a

462
00:25:54.510 --> 00:25:58.250
strong argument afterwards, they very often change their mind.

463
00:25:59.140 --> 00:26:01.599
On the other hand, if they um had very

464
00:26:01.599 --> 00:26:04.540
strong ri belief, but presented with a weak argument,

465
00:26:04.619 --> 00:26:07.280
it's only my favorite color, they almost never change

466
00:26:07.280 --> 00:26:11.180
their mind. And in these two other conditions where

467
00:26:11.180 --> 00:26:13.739
they had strong evidence and were presented with a

468
00:26:13.739 --> 00:26:16.260
strong argument, we found that actually in 50% of

469
00:26:16.260 --> 00:26:20.459
the cases, they changed their mind. And when they

470
00:26:20.459 --> 00:26:23.459
did not have any evidence, and then they were

471
00:26:23.459 --> 00:26:25.939
presented with a weak reason, we found that they

472
00:26:25.939 --> 00:26:28.400
changed their mind a little bit more than 50%.

473
00:26:28.989 --> 00:26:31.540
So it seemed like it is, they, they don't

474
00:26:31.540 --> 00:26:33.939
have any clue. It is a bad reason that

475
00:26:33.939 --> 00:26:36.500
it's a favorite color, but it's maybe still better

476
00:26:36.500 --> 00:26:38.619
than nothing because you don't have any idea what

477
00:26:38.619 --> 00:26:41.579
is happening. So they're, they still, um, some of

478
00:26:41.579 --> 00:26:43.780
them followed this, this argument even though it was

479
00:26:43.780 --> 00:26:44.459
a bad one.

480
00:26:46.199 --> 00:26:49.640
So those are the kinds of reasons that children

481
00:26:49.640 --> 00:26:53.000
consider when revising their beliefs, right?

482
00:26:54.270 --> 00:26:58.810
Yeah, so that is um Those reasons are everywhere

483
00:26:58.810 --> 00:27:01.530
mostly interested in something that you also call like

484
00:27:01.530 --> 00:27:06.729
first order evidence, so we um really gave a

485
00:27:06.729 --> 00:27:10.790
reason that speaks directly for or against the belief.

486
00:27:11.650 --> 00:27:15.050
And we also in an additional study in the

487
00:27:15.050 --> 00:27:17.650
same paper, we ran, um, we looked at what

488
00:27:17.650 --> 00:27:22.589
the kids also consider. So-called second-order evidence and second-order

489
00:27:22.589 --> 00:27:26.550
evidence, um, the way we defined it was either

490
00:27:26.550 --> 00:27:32.349
like confirming or like undermining the evidence for a

491
00:27:32.349 --> 00:27:35.069
belief. So it was, um, in our case, we

492
00:27:35.069 --> 00:27:37.270
called it also meta reason, so it really was

493
00:27:37.270 --> 00:27:40.790
a reason about the reason and um to give

494
00:27:40.790 --> 00:27:43.890
you an example again, we ran a study where

495
00:27:43.890 --> 00:27:48.589
um So the kids were looking for a pet

496
00:27:48.589 --> 00:27:51.369
that was lost, and they were presented with a

497
00:27:51.369 --> 00:27:53.969
picture where they saw like two bushes, a bush

498
00:27:53.969 --> 00:27:56.329
with red berries and a bush with purple berries,

499
00:27:56.729 --> 00:27:59.369
and they saw that there were like duck prints.

500
00:27:59.449 --> 00:28:01.339
So the animal that was lost was a duck,

501
00:28:01.650 --> 00:28:03.969
and they saw that there were duck prints, um,

502
00:28:04.369 --> 00:28:06.969
footprints, um, leading to one of the bushes, and

503
00:28:06.969 --> 00:28:08.489
the kids were asked, where do you think the

504
00:28:08.489 --> 00:28:12.939
duck is hiding? And Um, then the kids, most

505
00:28:12.939 --> 00:28:16.170
of them were correctly, like, inferred the duck is

506
00:28:16.170 --> 00:28:19.180
hiding behind the bush, um, where the footprints lead

507
00:28:19.180 --> 00:28:21.920
to. And then in the next step, we gave

508
00:28:21.920 --> 00:28:26.060
them either confirming or undermining evidence. So we either

509
00:28:26.060 --> 00:28:29.099
said, yes, you're right, so these footprints look like

510
00:28:29.099 --> 00:28:31.020
duck footprints, and we showed a picture of how

511
00:28:31.020 --> 00:28:33.760
duck footprints look like. And in, in, in the

512
00:28:33.760 --> 00:28:37.520
other condition, we actually said, oh wait, these footprints

513
00:28:37.520 --> 00:28:40.239
don't look like duck footprints because duck footprints look

514
00:28:40.239 --> 00:28:42.880
like this, and we showed them how duck footprints

515
00:28:42.880 --> 00:28:46.030
look like. And then we ask them, um, again,

516
00:28:46.150 --> 00:28:47.869
so where do you think the duck is hiding?

517
00:28:48.189 --> 00:28:52.699
And in the undermining condition, so where we're presenting,

518
00:28:52.910 --> 00:28:56.410
presented them with this undermining second order evidence, kids

519
00:28:56.550 --> 00:29:00.510
much more often change their belief compared to the

520
00:29:00.510 --> 00:29:04.150
condition where their um initial evidence was confirmed.

521
00:29:05.589 --> 00:29:11.349
Right. OK, so changing topics, what do people consider

522
00:29:11.349 --> 00:29:13.150
to be good reasoning?

523
00:29:15.239 --> 00:29:19.239
Yeah, so, um, I think what people, the way

524
00:29:19.239 --> 00:29:23.459
people can evaluate other other's reasoning is like twofold.

525
00:29:23.839 --> 00:29:28.119
So you can see whether a person gets to

526
00:29:28.119 --> 00:29:31.680
the right conclusions, gets to the right outcomes, or

527
00:29:31.680 --> 00:29:35.680
you can also um like investigate and evaluate the

528
00:29:35.680 --> 00:29:39.199
process that people use to go to, to get

529
00:29:39.199 --> 00:29:45.099
to a certain outcome. And, um, sometimes these two

530
00:29:45.099 --> 00:29:49.660
things, um, interfere or don't, uh, um, lead in

531
00:29:49.660 --> 00:29:53.839
the same direction. So, for example, if you're presented

532
00:29:53.839 --> 00:29:59.050
with, um, Somebody who reaches a correct conclusion, but

533
00:29:59.050 --> 00:30:01.729
you know that the processes that they used were

534
00:30:01.729 --> 00:30:05.890
completely irrational, so maybe to decide whether a reward

535
00:30:05.890 --> 00:30:08.810
is in box A or box B, they just

536
00:30:08.810 --> 00:30:11.010
were throwing a coin, then you would say this

537
00:30:11.010 --> 00:30:13.609
was an irrational process that they used, and they

538
00:30:13.609 --> 00:30:17.369
were simply lucky to get to the right conclusion,

539
00:30:17.449 --> 00:30:19.979
but still they got it right. And this is

540
00:30:19.979 --> 00:30:24.709
something that we looked at in um children and

541
00:30:24.709 --> 00:30:28.430
also adults from different cultures, so we went to

542
00:30:28.430 --> 00:30:32.589
study from kids. In the United States and in

543
00:30:32.589 --> 00:30:35.949
China, and we presented them with pretty much exactly

544
00:30:35.949 --> 00:30:38.390
the same scenario that I just explained to you.

545
00:30:38.829 --> 00:30:42.069
Again, it was a lost pet and um the

546
00:30:42.069 --> 00:30:44.520
kids were tasked, so where is the pet? Um,

547
00:30:44.699 --> 00:30:48.290
AND then one of the characters in the story

548
00:30:48.709 --> 00:30:52.569
was using an irrational procedure of figuring out where,

549
00:30:52.949 --> 00:30:55.109
where the pet is hiding, and they were just

550
00:30:55.109 --> 00:30:57.589
using, so we had several, uh, versions of this,

551
00:30:57.670 --> 00:31:01.609
but for example, just using like, um, Um, what

552
00:31:01.609 --> 00:31:03.969
do you call it? One of these boards where

553
00:31:03.969 --> 00:31:08.689
you with an error and you, um, Make the

554
00:31:08.689 --> 00:31:11.849
arrow flip and then you um uh it points

555
00:31:11.849 --> 00:31:15.859
at a certain um color in this board. And

556
00:31:16.410 --> 00:31:19.609
then um uh the kids were asked, um, or

557
00:31:19.609 --> 00:31:23.000
the characters said, OK, I believe that the pet

558
00:31:23.000 --> 00:31:25.449
is hiding behind um the bush with the purple

559
00:31:25.449 --> 00:31:29.030
berries because that is what um my random process,

560
00:31:29.810 --> 00:31:33.869
um, just like. Came up with, um, but by

561
00:31:33.869 --> 00:31:37.719
accident, the character was right. Um, AND the other

562
00:31:37.719 --> 00:31:42.859
character, for example, used, um, the correct procedure. And

563
00:31:42.859 --> 00:31:45.859
he, the correct procedure was in this case, or

564
00:31:45.859 --> 00:31:48.979
a rational procedure, which was in this case, looking

565
00:31:48.979 --> 00:31:51.819
for evidence. So looking for, for example, for footprints

566
00:31:51.819 --> 00:31:55.619
on the floor and inferring, oh, the animal is

567
00:31:55.619 --> 00:31:59.880
in this hiding location. But unknown to these characters,

568
00:31:59.939 --> 00:32:03.550
um, the animal has changed location in the meantime,

569
00:32:03.939 --> 00:32:07.739
so it was not anymore in the bush where

570
00:32:07.739 --> 00:32:10.770
the footprints lead to. So in the end, the

571
00:32:10.770 --> 00:32:15.119
character who had used a random procedure. Came to

572
00:32:15.119 --> 00:32:18.020
the right conclusion and the character who has used

573
00:32:18.760 --> 00:32:23.040
the um rational procedure came to the wrong conclusion.

574
00:32:23.439 --> 00:32:26.199
And then we asked kids, um, which of these

575
00:32:26.199 --> 00:32:28.869
characters do you think did the better job and

576
00:32:28.869 --> 00:32:32.319
also which of these characters would you prefer to

577
00:32:32.319 --> 00:32:35.479
um ask for help if you needed help in

578
00:32:35.479 --> 00:32:39.310
finding something. And then we found an interesting um

579
00:32:39.589 --> 00:32:43.670
difference, an interesting developmental difference that 4 and 5

580
00:32:43.670 --> 00:32:47.750
year olds had always a strong preference for the

581
00:32:47.750 --> 00:32:51.510
character who got to the right outcome, independent of

582
00:32:51.510 --> 00:32:55.339
whether they used uh wrong or, or like let's

583
00:32:55.339 --> 00:32:59.709
say a rational or rational procedure. And adults had

584
00:32:59.709 --> 00:33:03.349
a strong preference for the character who used the

585
00:33:03.349 --> 00:33:07.670
rational procedure, independent of whether they reached a correct

586
00:33:07.670 --> 00:33:11.550
or incorrect outcome. And we found some interesting differences

587
00:33:11.550 --> 00:33:15.260
actually in the middle age ranges between like 6

588
00:33:15.260 --> 00:33:18.349
and um 9 years of age, because we found

589
00:33:18.349 --> 00:33:22.390
that the kids in China actually had earlier on

590
00:33:22.390 --> 00:33:26.390
a preference for the character who used a rational

591
00:33:26.390 --> 00:33:30.229
procedure over the character who came to the correct

592
00:33:30.229 --> 00:33:33.670
outcome. And the kids in the United States had

593
00:33:33.670 --> 00:33:38.310
the same switch, so they also, um, uh, This

594
00:33:38.310 --> 00:33:40.719
developmental switch that they at some point preferred the

595
00:33:40.719 --> 00:33:43.719
character with the rational procedure, um, but it happened

596
00:33:43.719 --> 00:33:46.280
a little bit later. In the United States, it

597
00:33:46.280 --> 00:33:49.989
was around 78 years of age. And we were,

598
00:33:50.000 --> 00:33:53.180
um, wondering, so why did we find this developmental

599
00:33:53.599 --> 00:33:57.310
difference in these two cultures. And um thought it

600
00:33:57.310 --> 00:34:01.910
could be that in China, um, people are often

601
00:34:01.910 --> 00:34:05.670
like raised with a more like holistic picture of

602
00:34:05.670 --> 00:34:08.810
the world and trying to really see relation among,

603
00:34:09.320 --> 00:34:12.550
for example, like processes and outcomes and maybe this

604
00:34:12.550 --> 00:34:15.909
helps these kids to like earlier on, um, make

605
00:34:15.909 --> 00:34:20.989
this developmental switch and evaluating rather the process compared

606
00:34:20.989 --> 00:34:25.010
to the outcome when they observe um, Yeah, actions

607
00:34:25.010 --> 00:34:26.830
or like reasoning of other people.

608
00:34:28.000 --> 00:34:31.958
Yeah, that, that's really interesting to find and explain

609
00:34:31.958 --> 00:34:35.969
these cross cultural differences, but also the aspects in

610
00:34:35.969 --> 00:34:40.560
which there is universality, I guess. So, uh, I

611
00:34:40.560 --> 00:34:43.438
have one last topic I would like to ask

612
00:34:43.438 --> 00:34:49.563
you about. So you have some. Recent exciting findings

613
00:34:49.563 --> 00:34:55.043
that suggest that chimpanzees respond to higher order evidence.

614
00:34:55.364 --> 00:34:56.965
Could you tell us about that? First of all,

615
00:34:57.125 --> 00:35:01.544
tell us what higher order evidence is and then

616
00:35:01.885 --> 00:35:04.504
what you did there in that study.

617
00:35:04.995 --> 00:35:09.504
Yeah, um, yeah, so in this study, it actually

618
00:35:09.504 --> 00:35:12.604
we, we started out by also um investigating belief

619
00:35:12.604 --> 00:35:17.159
revision. In chimpanzees, and we found it very similar

620
00:35:17.159 --> 00:35:19.860
to the study that I explained earlier with kids,

621
00:35:20.239 --> 00:35:23.120
it was that chimpanzees revise their beliefs in rational

622
00:35:23.120 --> 00:35:27.699
ways, so if they form an initial belief based

623
00:35:27.699 --> 00:35:32.239
on weak evidence, but afterwards are represented with stronger

624
00:35:32.239 --> 00:35:36.540
evidence, then they change their mind. However, when it's

625
00:35:36.540 --> 00:35:39.020
the other way around, when they are first presented

626
00:35:39.020 --> 00:35:41.820
with strong evidence and they base their initial belief

627
00:35:41.820 --> 00:35:44.739
on strong evidence, and now later on presented with

628
00:35:44.739 --> 00:35:47.840
the weak evidence, then they stick to their initial

629
00:35:47.840 --> 00:35:51.860
belief. And in the second step, we were interested

630
00:35:51.860 --> 00:35:57.040
in, uh, can chimpanzees also um understand the second

631
00:35:57.040 --> 00:36:02.080
order evidence, also similar to um to what we

632
00:36:02.080 --> 00:36:05.959
have done with children. Um, AND here we looked

633
00:36:05.959 --> 00:36:09.979
at whether they understand also undermining. Undermining evidence. And

634
00:36:09.979 --> 00:36:12.590
in that case, in the kids' version of the

635
00:36:12.590 --> 00:36:16.429
study, we had this like confirming or disconfirming um

636
00:36:16.429 --> 00:36:19.949
reasons and we said, oh, these duck, these footprints

637
00:36:19.949 --> 00:36:22.360
don't look like duck, duck footprints, and of course

638
00:36:22.360 --> 00:36:25.540
that was not possible to do with chimpanzees. So

639
00:36:25.540 --> 00:36:29.969
we had to come up with A nonverbal version

640
00:36:29.969 --> 00:36:33.370
of this task. And here again, we had like

641
00:36:33.370 --> 00:36:36.750
two boxes and the question was, um, in which

642
00:36:36.750 --> 00:36:40.229
of these two boxes is the apple hidden, and

643
00:36:40.229 --> 00:36:42.379
then we presented the chimpanzees with different pieces of

644
00:36:42.379 --> 00:36:45.739
evidence. And in this study where we looked at

645
00:36:46.120 --> 00:36:49.719
um the second-order evidence, we first showed them a

646
00:36:49.719 --> 00:36:51.800
weak evidence for one box, and in this case,

647
00:36:51.879 --> 00:36:54.840
we just lifted this box, we shook it, and

648
00:36:54.840 --> 00:36:57.320
we put it down, and the chimpanzees probably inferred,

649
00:36:57.639 --> 00:36:59.800
um, as we know from previous work, um, they

650
00:36:59.800 --> 00:37:02.479
can use this clue, the apple is in this

651
00:37:02.479 --> 00:37:04.199
box where I heard the noise. So they could

652
00:37:04.199 --> 00:37:06.800
make a choice, they chose the one where they've

653
00:37:06.800 --> 00:37:08.860
heard the noise. And then in the next step,

654
00:37:08.939 --> 00:37:12.060
we presented them with strong evidence, so we were

655
00:37:12.060 --> 00:37:14.770
turning around the box and we showed them, like,

656
00:37:14.780 --> 00:37:18.300
through a blurry window, that there was um an

657
00:37:18.300 --> 00:37:20.219
apple in there. They saw something that looks like

658
00:37:20.219 --> 00:37:23.060
an apple through a blurry window, and there was

659
00:37:23.060 --> 00:37:26.209
strong evidence, strong visual evidence that, oh, probably the

660
00:37:26.209 --> 00:37:28.739
noise that I just heard was something else, it

661
00:37:28.739 --> 00:37:31.300
was probably not the apple, but now I've seen

662
00:37:31.300 --> 00:37:32.780
it, so it must be in the other box,

663
00:37:32.899 --> 00:37:36.320
so I, I should change my mind. Um, AND

664
00:37:36.320 --> 00:37:38.360
that is also what most of the, um, chimps

665
00:37:38.360 --> 00:37:40.780
did, as we've known from the, uh, previous study.

666
00:37:41.550 --> 00:37:44.120
And then in the next step, we actually showed

667
00:37:44.120 --> 00:37:47.360
them like undermining an epistemic defeater. So we showed

668
00:37:47.360 --> 00:37:50.080
them that this evidence, this strong evidence that they've

669
00:37:50.080 --> 00:37:53.280
just based their belief on is not really valid,

670
00:37:53.360 --> 00:37:56.379
and how did we do that? So, we took,

671
00:37:56.439 --> 00:37:59.080
um, like a second screen that was in this

672
00:37:59.080 --> 00:38:02.239
box out that had a picture of an apple

673
00:38:02.239 --> 00:38:05.570
on it. So what they've just seen earlier, what

674
00:38:05.570 --> 00:38:08.570
was not the actual apple, it was just a

675
00:38:08.570 --> 00:38:11.290
picture of an apple. And now if they can

676
00:38:11.290 --> 00:38:14.290
make this inference that, oh, there's strong evidence that

677
00:38:14.290 --> 00:38:17.689
I've just seen was now defeated by the evidence

678
00:38:17.689 --> 00:38:21.050
of like, it's just a picture, they should actually

679
00:38:21.050 --> 00:38:23.810
change their mind, and they should change their mind

680
00:38:23.810 --> 00:38:27.229
back to um what they've heard initially. So now,

681
00:38:27.860 --> 00:38:30.699
The shaking, the shaking noise that they heard initially

682
00:38:30.699 --> 00:38:33.919
was actually the strongest evidence that they had overall

683
00:38:33.919 --> 00:38:37.780
because this other piece of visual evidence was defeated.

684
00:38:38.399 --> 00:38:41.479
And we, we found that if we defeated this

685
00:38:41.479 --> 00:38:44.159
evidence, if we showed them this picture of the

686
00:38:44.159 --> 00:38:47.800
apple, the chimpanzees were much more likely to change

687
00:38:47.800 --> 00:38:50.840
their mind and switch back to the initial uh

688
00:38:50.840 --> 00:38:54.699
box that they had chosen. Um, COMPARED to when

689
00:38:54.699 --> 00:38:57.219
we didn't defeat this evidence, so in a controlled

690
00:38:57.219 --> 00:38:59.300
condition, we also took a screen out of this

691
00:38:59.300 --> 00:39:01.570
box, but there was no picture of, of the

692
00:39:01.570 --> 00:39:04.100
apple on it, and then most of the chimpanzees

693
00:39:04.100 --> 00:39:07.659
stuck to their strong visual evidence and chose the

694
00:39:07.659 --> 00:39:09.439
box where they had seen the apple.

695
00:39:10.969 --> 00:39:14.639
So would one of the goals here be to

696
00:39:14.639 --> 00:39:21.120
understand the phylogenetic roots of this kind of reasoning

697
00:39:21.120 --> 00:39:25.800
and perhaps trying to establish a link between chimpanzees

698
00:39:25.800 --> 00:39:28.800
and humans when it when it comes to the

699
00:39:28.800 --> 00:39:31.120
evolution of this kind of reason.

700
00:39:32.479 --> 00:39:37.280
Yeah, certainly. Um, SO, I think the important question

701
00:39:37.280 --> 00:39:40.469
here in the background is like about rationality. So,

702
00:39:40.479 --> 00:39:45.439
rationality is one of these like features that many

703
00:39:45.439 --> 00:39:48.919
philosophers, like, I guess, like starting or maybe even

704
00:39:48.919 --> 00:39:52.639
before Aristotle, um say that rationality is really just

705
00:39:52.639 --> 00:39:57.090
what makes us human. And, The question is, uh,

706
00:39:57.139 --> 00:39:59.939
is that really the case? So, it's really rationality

707
00:39:59.939 --> 00:40:03.500
one of these defining features that only humans possess.

708
00:40:03.820 --> 00:40:06.699
And if you look at, um, rationality also has

709
00:40:06.699 --> 00:40:10.600
many definitions, um, but the definition that we here,

710
00:40:10.610 --> 00:40:14.040
um, looked at was really um responding to reasons.

711
00:40:14.419 --> 00:40:17.979
So are we a rational agent responds to reasons

712
00:40:17.979 --> 00:40:21.120
and how can you test whether a rational agent

713
00:40:21.120 --> 00:40:24.419
responds to reasons? And the idea was you can

714
00:40:24.419 --> 00:40:27.370
pretty much test that if somebody follows a reason,

715
00:40:27.540 --> 00:40:30.260
yes, that is something that we've already known that

716
00:40:30.260 --> 00:40:34.050
chimpanzees also follow evidence, for example, they Um, can

717
00:40:34.050 --> 00:40:37.340
follow like yogurt traces and know, OK, that, that

718
00:40:37.350 --> 00:40:39.810
that's the trace that leads to, to the cup,

719
00:40:39.820 --> 00:40:41.969
um, where I can actually find the yogurt so

720
00:40:41.969 --> 00:40:44.929
they can use evidence, but the question was, can

721
00:40:44.929 --> 00:40:49.729
they also understand that evidence can be defeated? And

722
00:40:49.729 --> 00:40:52.889
this really shows that they understand pretty much a

723
00:40:52.889 --> 00:40:56.250
reason as a reason, because when they know that

724
00:40:56.250 --> 00:40:59.209
this reason is not valid anymore, they don't use

725
00:40:59.209 --> 00:40:59.489
it.

726
00:41:00.780 --> 00:41:05.780
Right. OK, so Hannah, uh, what kinds of work

727
00:41:05.780 --> 00:41:09.060
are you going to be doing in the near

728
00:41:09.060 --> 00:41:12.100
future? I mean, what kinds of topics are you

729
00:41:12.100 --> 00:41:13.739
expecting to explore?

730
00:41:14.750 --> 00:41:17.790
Yeah, I'm super curious to keep on working on

731
00:41:17.790 --> 00:41:22.149
um the cross-species comparison um that is related to

732
00:41:22.149 --> 00:41:27.350
rationality. And I'm currently planning a study where we

733
00:41:27.350 --> 00:41:30.469
look at the social aspect of rationality. So for

734
00:41:30.469 --> 00:41:36.610
example, do we consider what um What evidence another

735
00:41:36.610 --> 00:41:39.830
person bases their beliefs on, and then do we

736
00:41:39.830 --> 00:41:42.120
like consider this and also like compare this with

737
00:41:42.120 --> 00:41:44.489
our own evidence, and that is something that we

738
00:41:44.489 --> 00:41:47.969
could also like do with chimpanzees and see whether

739
00:41:47.969 --> 00:41:51.020
they consider if they get a clue from another

740
00:41:51.020 --> 00:41:54.290
individual where the food is, do they consider whether

741
00:41:54.290 --> 00:41:57.550
this individual had evidence for their beliefs or not.

742
00:41:58.169 --> 00:42:00.689
Um, SO this is something that I'm very interested

743
00:42:00.689 --> 00:42:03.610
in. But more recently, even though that is not

744
00:42:03.610 --> 00:42:06.610
yet uh a very planned out, I'm also really

745
00:42:06.610 --> 00:42:10.879
interested in, in AI how humans use AI as

746
00:42:10.879 --> 00:42:14.909
evidence um to form their beliefs and maybe how

747
00:42:14.959 --> 00:42:18.449
and what kind of features AI would need to

748
00:42:18.449 --> 00:42:22.530
have that we evaluated maybe more critically. Um, BUT

749
00:42:22.530 --> 00:42:26.110
those are very um unbaked ideas at the moment.

750
00:42:26.300 --> 00:42:28.110
Um, BUT I would love to look in this,

751
00:42:28.129 --> 00:42:29.870
um, a little bit more in the future.

752
00:42:31.179 --> 00:42:34.699
Great, so if people are interested, where can they

753
00:42:34.699 --> 00:42:36.939
find you and your work on the internet?

754
00:42:37.889 --> 00:42:41.840
I, I don't have um like an. A website

755
00:42:41.840 --> 00:42:43.800
on my own, but they find me over the

756
00:42:43.800 --> 00:42:48.030
website of uh my university, the Utrecht University, or

757
00:42:48.030 --> 00:42:50.439
if they just Google my name, Hannah Schleihoff, there's

758
00:42:50.439 --> 00:42:52.639
not that many people with that name, so they

759
00:42:52.639 --> 00:42:55.840
should be able um to find me. I'm also

760
00:42:55.840 --> 00:42:58.679
on, um, Blue Sky. Um, THAT is also one

761
00:42:58.679 --> 00:43:01.389
of the channels, um, I think where people could

762
00:43:01.389 --> 00:43:01.760
reach me.

763
00:43:02.699 --> 00:43:05.510
OK, so thank you so much for taking the

764
00:43:05.510 --> 00:43:07.669
time to come on the show. It's been really

765
00:43:07.669 --> 00:43:12.040
fun to talk with you. Thank you. Hi guys,

766
00:43:12.100 --> 00:43:14.199
thank you for watching this interview until the end.

767
00:43:14.260 --> 00:43:16.540
If you liked it, please share it, leave a

768
00:43:16.540 --> 00:43:19.250
like and hit the subscription button. The show is

769
00:43:19.250 --> 00:43:22.010
brought to you by Enlights Learning and Development done

770
00:43:22.010 --> 00:43:26.050
differently. Check their website at enlights.com and also please

771
00:43:26.050 --> 00:43:29.969
consider supporting the show on Patreon or PayPal. I

772
00:43:29.969 --> 00:43:31.889
would also like to give a huge thank you

773
00:43:31.889 --> 00:43:35.889
to my main patrons and PayPal supporters, Perergo Larsson,

774
00:43:36.090 --> 00:43:39.639
Jerry Muller, Frederick Sundo, Bernard Seyaz Olaf, Alex, Adam

775
00:43:39.639 --> 00:43:42.810
Cassel, Matthew Whittingberrd, Arnaud Wolff, Tim Hollis, Eric Elena,

776
00:43:43.010 --> 00:43:46.820
John Connors, Philip Forst Connolly. Then Dmitri Robert Windegerru

777
00:43:46.820 --> 00:43:51.080
Inai Zu Mark Nevs, Colin Holbrookfield, Governor, Michel Stormir,

778
00:43:51.229 --> 00:43:54.919
Samuel Andrea, Francis Forti Agnun, Svergoras and Hal Herzognun,

779
00:43:55.479 --> 00:43:58.919
Machael Jonathan Labrarith, John Yardston, and Samuel Curric Hines,

780
00:43:59.000 --> 00:44:02.639
Mark Smith, John Ware, Tom Hammel, Sardusran, David Sloan

781
00:44:02.639 --> 00:44:06.959
Wilson, Yasilla Dezaraujo Romain Roach, Diego Londono Correa. Yannik

782
00:44:06.959 --> 00:44:11.340
Punteran Ruzmani, Charlotte Blis Nicole Barbaro, Adam Hunt, Pavlostazevski,

783
00:44:11.429 --> 00:44:14.790
Alekbaka Madison, Gary G. Alman, Semov, Zal Adrian Yei

784
00:44:14.790 --> 00:44:19.070
Poltonin, John Barboza, Julian Price, Edward Hall, Edin Bronner,

785
00:44:19.750 --> 00:44:24.149
Douglas Fry, Franco Bartolati, Gabriel Pancortez or Suliliski, Scott

786
00:44:24.149 --> 00:44:27.699
Zachary Fish, Tim Duffy, Sony Smith, and Wisman. Daniel

787
00:44:27.699 --> 00:44:31.850
Friedman, William Buckner, Paul Georg Jarno, Luke Lovai, Georgios

788
00:44:31.850 --> 00:44:36.500
Theophannus, Chris Williamson, Peter Wolozin, David Williams, Dio Costa,

789
00:44:36.620 --> 00:44:40.860
Anton Ericsson, Charles Murray, Alex Shaw, Marie Martinez, Coralli

790
00:44:40.860 --> 00:44:45.419
Chevalier, Bangalore atheists, Larry D. Lee Jr. Old Eringbon.

791
00:44:46.419 --> 00:44:50.010
Esterri, Michael Bailey, then Spurber, Robert Grassy, Zigoren, Jeff

792
00:44:50.010 --> 00:44:54.560
McMahon, Jake Zul, Barnabas Raddix, Mark Kempel, Thomas Dovner,

793
00:44:54.689 --> 00:44:59.120
Luke Neeson, Chris Story, Kimberly Johnson, Benjamin Galbert, Jessica

794
00:44:59.120 --> 00:45:04.689
Nowicki, Linda Brendan, Nicholas Carlson, Ismael Bensleyman. George Ekoriati,

795
00:45:04.840 --> 00:45:09.159
Valentine Steinmann, Per Crawley, Kate Van Goler, Alexander Obert,

796
00:45:10.080 --> 00:45:15.850
Liam Dunaway, BR, Massoud Ali Mohammadi, Perpendicular, Jannes Hetner,

797
00:45:15.969 --> 00:45:20.810
Ursula Guinov, Gregory Hastings, David Pinsov, Sean Nelson, Mike

798
00:45:20.810 --> 00:45:24.475
Levin, and Jos Necht. A special thanks to my

799
00:45:24.475 --> 00:45:27.754
producers Iar Webb, Jim Frank Lucas Stink, Tom Vanneden,

800
00:45:28.804 --> 00:45:32.395
Bernardine Curtis Dixon, Benedict Mueller, Thomas Trumbull, Catherine and

801
00:45:32.395 --> 00:45:35.435
Patrick Tobin, John Carlo Montenegro, Al Nick Cortiz, and

802
00:45:35.435 --> 00:45:38.754
Nick Golden, and to my executive producers, Matthew Lavender,

803
00:45:38.875 --> 00:45:42.034
Sergio Quadrian, Bogdan Kaniz and Rosie. Thank you for

804
00:45:42.034 --> 00:45:42.375
all.

